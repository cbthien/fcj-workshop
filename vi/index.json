[{"uri":"https://cbthien.github.io/fcj-workshop/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Cao Bá Thiên\nSố điện thoại: 0961161479\nEmail: thiencbse184423@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 06/09/2025 đến ngày 9/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Worklog được thực hiện trong 12 tuần thực tập tại First Cloud Journey, tập trung vào việc xây dựng ARC-Chatbot — một ứng dụng RAG Chatbot trên AWS.\nTuần 1: Tài khoản AWS và Nguyên tắc cơ bản về IAM\nTuần 2: Ngân sách AWS \u0026amp; Hỗ trợ thiết yếu\nTuần 3: Khái niệm nâng cao về IAM và mạng VPC cốt lõi\nTuần 4: Vận hành EC2 \u0026amp; Triển khai ứng dụng\nTuần 5: Kiến trúc trang web tĩnh, Cloud9 và S3\nTuần 6: Triển khai RDS MySQL \u0026amp; Lightsail\nTuần 7: Kiến trúc AWS thực tế và Dự án Text-to-SQL\nTuần 8: Ôn tập giữa kỳ và Chuẩn bị thi\nTuần 9: Tự động mở rộng, cân bằng tải và giám sát CloudWatch\nTuần 10: AWS CLI, DNS, Mạng kết hợp \u0026amp; Microsoft AD\nTuần 11: Cơ sở hạ tầng cơ bản (M0) \u0026amp; Đường ống IDP (M1)\nTuần 12: Thành phần trò chuyện RAG (M2) \u0026amp; Kiểm tra/Golive (M3)\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.1-week1/","title":"Nhật ký Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1: Hiểu cấu trúc tài khoản AWS và vai trò của Root User. Học cách tạo và bảo mật tài khoản AWS. Thiết lập IAM User, IAM Group và gán chính sách quyền. Kích hoạt MFA và cấu hình cảnh báo chi phí. Làm quen với giao diện AWS Management Console. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tổng quan về tài khoản AWS và trách nhiệm của Root User - Hiểu các khái niệm IAM (User, Group, Policy) 08/09/2025 08/09/2025 https://000001.awsstudygroup.com/ 2 - Tạo tài khoản AWS - Thêm phương thức thanh toán - Xác thực email \u0026amp; số điện thoại - Đăng nhập lần đầu và khám phá AWS Console 09/09/2025 09/09/2025 https://000001.awsstudygroup.com/ 3 - Bảo mật tài khoản Root + Kích hoạt MFA + Cấu hình password policy + Giảm thiểu việc sử dụng Root User - Thiết lập Billing Preferences \u0026amp; theo dõi Free Tier 10/09/2025 10/09/2025 https://000001.awsstudygroup.com/ 4 - Tạo IAM Group (Administrators) - Gắn AdministratorAccess policy - Tạo IAM User - Cấu hình đăng nhập cho user và bật MFA 11/09/2025 11/09/2025 https://000001.awsstudygroup.com/ 5 - Tạo Budget và Billing Alerts - Kiểm tra danh sách bảo mật tài khoản - Thực hành đăng nhập bằng IAM User - Khám phá giao diện AWS Console - Tổng kết bài học \u0026amp; các vấn đề phát sinh 12/09/2025 12/09/2025 https://000001.awsstudygroup.com/ Kết quả đạt được Tuần 1 Tuần 1 là giai đoạn mình “đặt nền móng” cho toàn bộ hành trình với AWS, nên mình cố gắng làm mọi thứ thật chỉnh chu và có hệ thống:\nNắm vững cấu trúc tài khoản AWS\nMình đã hiểu được sự khác biệt rõ ràng giữa:\nRoot User – chỉ dùng cho các tác vụ quản trị cấp cao, nhạy cảm. IAM User / IAM Group / Policy – dùng cho việc phân quyền hằng ngày theo best practice.\nNhờ đó, mình không còn suy nghĩ đơn giản kiểu “cứ đăng nhập root là xong” như trước nữa, mà ý thức được vấn đề bảo mật lâu dài. Tạo và bảo mật tài khoản AWS một cách có quy trình\nMình không chỉ dừng lại ở việc tạo được tài khoản AWS, mà còn:\nThiết lập đầy đủ thông tin thanh toán, xác thực email và số điện thoại. Kiểm tra lại từng bước để đảm bảo tài khoản hoạt động ổn định.\nĐiều này giúp mình tự tin hơn khi sử dụng tài khoản cho các bài lab và dự án sau này. Bảo vệ tài khoản Root và IAM User đúng chuẩn best practices\nKích hoạt MFA cho Root User và cho IAM User chính mà mình sử dụng hằng ngày. Thiết lập password policy ở mức chặt chẽ (độ dài, ký tự đặc biệt, vòng đời mật khẩu…). Hạn chế tối đa việc đăng nhập bằng Root, chỉ dùng IAM User để thao tác.\nQua đó, mình nhận ra tầm quan trọng của bảo mật ngay từ bước đầu, thay vì chỉ quan tâm đến “chạy được dịch vụ”. Thiết lập quản lý chi phí và cảnh báo sớm\nCấu hình Billing Preferences để nhận email khi có thay đổi. Tạo Budget và Billing Alerts để tránh vượt quá Free Tier.\nNhờ những bước này, mình yên tâm hơn khi thực hiện các bài thực hành vì biết rằng nếu có phát sinh chi phí bất thường, mình sẽ được cảnh báo sớm. Áp dụng IAM theo best practices thay vì làm cho có\nTạo IAM Group (Administrators) và gán AdministratorAccess đúng cách. Tạo IAM User riêng và thêm vào group thay vì gán policy trực tiếp vào user. Thử đăng nhập bằng IAM User, kiểm tra quyền hạn và thử bật MFA.\nNhững thao tác này giúp mình hiểu IAM không chỉ là lý thuyết, mà là công cụ quan trọng để vận hành hệ thống an toàn. Làm quen với AWS Management Console và cách tư duy dịch vụ\nDành thời gian khám phá giao diện, tìm kiếm dịch vụ qua thanh search. Ghi chú lại những dịch vụ xuất hiện nhiều trong tài liệu (EC2, S3, IAM, CloudWatch, v.v.).\nSau tuần 1, cảm giác “choáng ngợp” ban đầu với giao diện AWS giảm đi khá nhiều, thay vào đó là sự quen tay và dễ hình dung hơn khi đọc tài liệu / kiến trúc. Đánh giá bản thân và khó khăn gặp phải trong Tuần 1 Tuần 1 tuy chưa đụng nhiều vào phần “xây hệ thống”, nhưng lại là tuần mình phải thay đổi cách suy nghĩ về việc sử dụng tài khoản cloud một cách chuyên nghiệp.\n1. Đánh giá bản thân Tích cực, chủ động làm tới cùng từng bước\nMình không chỉ làm cho xong checklist, mà cố gắng hiểu “vì sao cần làm như vậy”, đặc biệt là các bước về Root User, IAM và Billing. Khi gặp chỗ chưa rõ, mình chủ động tra tài liệu, hỏi mentor và ghi chú lại.\nTuân thủ quy trình và bảo mật ngay từ đầu\nThay vì bỏ qua các phần như MFA, Budget (thường bị xem nhẹ), mình nghiêm túc thực hiện đầy đủ. Điều này giúp mình hình thành thói quen tốt cho các tuần sau, khi hệ thống phức tạp hơn.\nBiết tự hệ thống hóa kiến thức\nSau mỗi ngày, mình đều tổng kết lại: hôm nay học được gì, đã làm bước nào, còn vướng gì. Việc ghi lại như vậy giúp mình không bị “quên ngang” và có thể quay lại ôn nhanh khi cần.\n2. Khó khăn gặp phải Bỡ ngỡ với khái niệm tài khoản \u0026amp; quyền hạn\nBan đầu mình khá lúng túng trong việc phân biệt:\nKhi nào dùng Root, khi nào dùng IAM User? Gán quyền cho Group khác gì với gán thẳng cho User?\nSau khi học thêm tài liệu AWS và làm thử vài lần, mình mới hiểu rõ hơn mô hình phân quyền. Lo lắng về chi phí và thanh toán\nVì phải thêm phương thức thanh toán (thẻ/bank), mình khá lo việc bị trừ tiền ngoài ý muốn. Điều này khiến mình cẩn trọng hơn, nhưng cũng làm mình mất thêm thời gian để:\nĐọc kỹ phần Billing \u0026amp; Free Tier. Tìm hiểu cách tạo Budget và Alerts.\nVề lâu dài, đây là khó khăn “tốt”, vì nhờ vậy mình hiểu sâu hơn về kiểm soát chi phí. Quá nhiều thông tin mới trong thời gian ngắn\nNgay từ tuần đầu đã phải làm quen với:\nKhái niệm tài khoản, bảo mật, thanh toán. Giao diện Console với rất nhiều dịch vụ.\nCó lúc mình cảm thấy hơi quá tải, nhưng mình giải quyết bằng cách: Chia nhỏ nội dung theo từng ngày (như trong bảng nhiệm vụ). Chỉ tập trung sâu vào những gì liên quan trực tiếp đến tài khoản \u0026amp; bảo mật trong tuần 1. Nhìn chung, Tuần 1 tuy chủ yếu là “thiết lập nền”, nhưng mình đã cố gắng làm một cách cẩn thận và có suy nghĩ, thay vì làm cho đủ. Đây là nền tảng quan trọng để tuần 2, tuần 3 mình có thể tập trung hơn vào dịch vụ và kiến trúc mà không phải quay lại sửa các lỗi cơ bản về tài khoản và bảo mật.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/3-blogstranslated/3.1-blog1/","title":"FotMob cung cấp cập nhật bóng đá gần như theo thời gian thực cho hàng triệu người dùng nhờ AWS","tags":[],"description":"","content":"by Emily McKinzie | vào ngày 25 MAR 2025 | trong Amazon Aurora, Amazon Bedrock, Amazon CloudFront, Amazon EC2,Amazon Elastic Kubernetes Service, Amazon ElastiCache, Amazon Machine Learning, Amazon Simple Storage Service (S3), Artificial Intelligence, AWS Lambdak,Compute, Database, Game Development, Games, Generative AI, Industries, Networking \u0026amp; Content Delivery, Storage\nMôn thể thao được xem nhiều nhất thế giới, bóng đá chuyên nghiệp, thu hút lượng người hâm mộ toàn cầu lên đến năm tỷ người. Với hàng trăm nghìn cầu thủ thi đấu trên khắp thế giới, môn thể thao này tạo ra một lượng dữ liệu khổng lồ, từ bàn thắng đến cứu thua, kiến tạo, và nhiều hơn thế nữa. Trong thế giới kết nối ngày nay, người hâm mộ muốn truy cập thời gian thực vào tất cả thống kê trận đấu, cầu thủ và đội bóng, thúc đẩy nhu cầu đối với các ứng dụng cập nhật trận đấu như FotMob. Ứng dụng có hơn 17 triệu người dùng, cung cấp cập nhật theo thời gian thực và tin tức từ 500 giải đấu quốc tế gần như 24/7.\nVới hạ tầng được xây dựng trên Amazon Web Services (AWS), công ty Na Uy đứng sau ứng dụng có thể mở rộng và đổi mới để liên tục nâng cao trải nghiệm người hâm mộ. Gần đây, đội ngũ đã phát triển hệ thống thông báo đẩy nội bộ giúp cải thiện cập nhật gần như theo thời gian thực cho người dùng và tiết kiệm hơn 130.000 USD mỗi năm.\nKhoản tiết kiệm này sẽ đóng vai trò quan trọng trong việc phát triển các tính năng mới, khi tổ chức đặt mục tiêu tăng gấp đôi lượng người dùng trong những năm tới. Nhận thấy cá nhân hóa là chìa khóa của chiến lược tăng trưởng này, đội ngũ FotMob cũng đang thử nghiệm tính năng tóm tắt đội bóng bằng generative AI được xây dựng trên Amazon Bedrock.\nTừ khởi đầu giản dị đến ứng dụng bóng đá hàng đầu FotMob bắt đầu vào năm 2004 như một dự án đam mê được dẫn dắt bởi hai anh em Christer và Tommy Nordvik. Họ làm việc vào buổi tối và cuối tuần, vừa duy trì công việc toàn thời gian vừa chăm sóc gia đình, để xây dựng công ty từ con số 0. Tuy nhiên, phải đến năm 2008 khi điện thoại thông minh trở nên phổ biến, FotMob mới thực sự cất cánh. Kể từ đó, đội ngũ đã mở rộng dịch vụ để bao gồm các thống kê trận đấu sâu hơn, thông báo cá nhân hóa, và các tóm tắt tin tức đội bóng và trận đấu trên nhiều khu vực.\n“Chúng tôi xây dựng ứng dụng phục vụ mọi kiểu người dùng — từ fan bình thường chỉ muốn xem tỉ số, đến những người đam mê muốn phân tích dữ liệu sâu. Với machine learning, chúng tôi đã biến các thống kê từ nhà cung cấp dữ liệu như Stats Perform thành các hình ảnh dễ hiểu, như biểu đồ động lực trận đấu hoặc hệ thống đánh giá cầu thủ,” nhà sáng lập FotMob Christer Nordvik giải thích. “Hệ thống đánh giá cầu thủ thậm chí còn được một số tuyển trạch viên sử dụng.”\nNâng cấp hệ thống thông báo đẩy để mở rộng theo lượng người dùng tăng trưởng Khi FotMob bắt đầu gửi thông báo đẩy cho người dùng, họ sử dụng các nhà cung cấp bên thứ ba. Tuy nhiên, họ nhanh chóng nhận ra rằng các dịch vụ này không thể xử lý lượng thông báo cần gửi và thường bị sập trong giờ cao điểm. Vì vậy, Christer và Tommy đã bắt tay vào xây dựng giải pháp nội bộ và tìm đến AWS.\n“Người hâm mộ rất trung thành, nhưng FotMob là dịch vụ thể thao trực tiếp — ứng dụng phải ổn định; downtime là điều không thể,” Christer giải thích. “Nếu có gì đó hỏng hoặc ứng dụng bị tắt trong vài phút, người dùng sẽ chuyển sang nơi khác. Chúng tôi biết AWS có thể mang lại sự yên tâm đó, và điều đó đã đúng.”\nTrung bình mỗi tuần, hệ thống của FotMob gửi hơn ba tỷ thông báo đẩy, và chỉ trong một ngày, họ có thể xử lý năm tỷ yêu cầu HTTP mỗi giờ — tương đương 1,6 triệu yêu cầu mỗi giây. Với hạ tầng được AWS hỗ trợ, FotMob có thể phân phối thông báo gần như tức thì trên toàn cầu, ngay cả trong thời điểm cao điểm. Amazon Simple Storage Service (S3) và Amazon Aurora giúp lưu trữ dữ liệu trận đấu và highlight theo mô hình đa vùng. Amazon Elastic Cloud Compute (EC2) xử lý và phân phối cập nhật theo thời gian thực, trong khi Amazon Elastic Kubernetes Service (EKS) và Amazon ElastiCache hỗ trợ phân phối thông báo đẩy.\nFotMob cũng sử dụng Amazon CloudFront để đảm bảo phân phối nhanh nội dung tĩnh cho người dùng, AWS Lambda cho API mở rộng linh hoạt, và AWS Cloud Development Kit (AWS CDK) để triển khai hạ tầng bằng mã. Christer chia sẻ thêm: “Nhờ AWS, chúng tôi không bị vướng vào các thách thức hạ tầng, vì thế chúng tôi đổi mới nhanh hơn để mang đến tính năng mà người hâm mộ quan tâm. Người dùng nhận được cập nhật nhanh, đáng tin cậy và không bị gián đoạn.”\nĐịnh hướng tương lai Với tầm nhìn mở rộng lượng người dùng lên 30 triệu, FotMob hiểu rằng cá nhân hóa sẽ là chìa khóa. Họ gần đây đã thử nghiệm generative AI thông qua Amazon Bedrock để tạo tóm tắt tin tức và đội bóng được cá nhân hóa hơn, cùng với các báo cáo trận đấu sinh động hơn cho người hâm mộ.\nCho đến nay, FotMob đã thử nghiệm nhiều mô hình ngôn ngữ lớn, trong đó Claude của Anthropic cho kết quả tối ưu nhất về chi phí và chất lượng. Với mô hình này, FotMob đã triển khai tính năng tóm tắt đội bóng bằng tiếng Anh và đang có kế hoạch mở rộng thêm ngôn ngữ trong tương lai.\n“Amazon Bedrock mang lại cho chúng tôi một nền tảng linh hoạt và có khả năng mở rộng để cung cấp các bản tóm tắt được AI tạo ra mà người dùng mong muốn,” Christer nói. “Nó tích hợp mượt mà với các dịch vụ AWS hiện có và cho phép chúng tôi thử nghiệm mô hình nhanh chóng để đảm bảo độ chính xác và giảm chi phí.”\nÔng tin rằng việc FotMob tập trung vào trải nghiệm người dùng và đổi mới chính là điểm khác biệt so với các ứng dụng thể thao khác, và AWS là yếu tố quan trọng giúp duy trì lợi thế này. Christer kết luận: “Một trong những lợi ích lớn nhất của AWS là chúng tôi có mọi thứ từ một nhà cung cấp. Khi khám phá công nghệ mới, chúng tôi thường xem AWS trước vì dễ dàng có mọi thứ ở một nơi.”\nDownload FotMob để xem công nghệ AWS hoạt động trong thực tế và trải nghiệm cập nhật bóng đá gần như theo thời gian thực. Khám phá cách bạn có thể xây dựng, vận hành và phát triển ứng dụng với AWS hoặc liên hệ đội ngũ AWS for Games để biết thêm thông tin.\nTài liệu tham khảo - Bundesliga powered by AWS - NFL on AWS\n- Cách DAZN sử dụng AWS Step Functions để điều phối phát video theo sự kiện\n- Hudl mở rộng xử lý video và tăng độ tin cậy bằng việc tối ưu hóa trên Amazon EC2 Spot Instances\nSource:\nhttps://aws.amazon.com/blogs/gametech/fotmob-delivers-near-real-time-football-updates-to-millions-of-fans-with-aws/\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #1 – AI/ML/GenAI trên AWS” Mục Đích Của Sự Kiện Giới thiệu hệ sinh thái AI/ML/GenAI trên AWS và cách áp dụng trong các bài toán thực tế. Hướng dẫn triển khai ML end-to-end bằng Amazon SageMaker. Xây dựng ứng dụng Generative AI thông qua Amazon Bedrock, RAG, Agents, AgentCore. Làm quen với MLOps, IaC, CICD, container workflows phục vụ AI/ML. Xây dựng tư duy vận hành và thiết kế kiến trúc AI trong môi trường doanh nghiệp. Danh Sách Diễn Giả Lâm Tuấn Kiệt – Sr DevOps Engineer, FPT Software Danh Hoàng Hiếu Nghị – AI Engineer, Renova Cloud Đinh Lê Hoàng Anh – Cloud Engineer Trainee, First Cloud AI Journey Văn Hoàng Kha – Community Builder Nội Dung Nổi Bật AWS AI/ML Services Overview Amazon SageMaker — nền tảng ML end-to-end Data preparation:\nSageMaker Data Wrangler Ground Truth (data labeling) Feature Store (quản lý feature tái sử dụng) Training \u0026amp; Tuning:\nTraining jobs với autoscaling GPU/CPU Hỗ trợ distributed training Hyperparameter tuning (Auto-tuning, Bayesian Optimization) Deployment Options:\nReal-time endpoint Serverless inference Multi-model endpoint Asynchronous (async) inference MLOps:\nModel registry CI/CD pipelines bằng SageMaker Pipelines Monitoring drift: data drift, feature drift, model drift Live demo:\nTrải nghiệm SageMaker Studio: notebook, xử lý dữ liệu, training và deploy model. Generative AI với Amazon Bedrock Foundation Models (FMs) AWS cung cấp thư viện mô hình nền tảng được quản lý hoàn toàn từ nhiều nhà cung cấp hàng đầu (Anthropic, Meta, Amazon, v.v.):\nClaude 3.5 – reasoning mạnh, context dài, phù hợp coding. Llama 3 – open-weight, dễ fine-tuning, chi phí tối ưu. Titan – embedding chất lượng cao cho RAG. Mistral – nhanh, nhẹ, phù hợp ứng dụng realtime. → Giúp người dùng tùy chỉnh và tích hợp nhanh mà không cần tự huấn luyện mô hình từ đầu.\nPrompt Engineering Techniques Hiểu cách “hướng dẫn” mô hình qua nhiều chiến lược prompt:\nZero-shot – mô hình chỉ nhận mô tả nhiệm vụ. Few-shot – mô hình được cung cấp một vài ví dụ mẫu. Chain-of-Thought – yêu cầu trình bày từng bước suy luận để tăng độ chính xác. Role prompting – gán vai trò cụ thể cho mô hình. Multi-step reasoning \u0026amp; Prompt templates – chia nhỏ suy luận, chuẩn hóa format. Retrieval Augmented Generation (RAG) Tăng chất lượng câu trả lời bằng cách bổ sung kiến thức bên ngoài:\nR – Retrieval: truy xuất thông tin liên quan từ knowledge base / data store. A – Augmentation: đưa thông tin truy xuất vào prompt làm ngữ cảnh. G – Generation: mô hình tạo câu trả lời chính xác và có căn cứ hơn. Use cases:\nChatbot doanh nghiệp theo ngữ cảnh Tìm kiếm thông minh (contextual / semantic search) Tóm tắt tài liệu, log, dữ liệu thời gian thực Amazon Titan Embeddings Mô hình embedding nhẹ, chuyển văn bản thành vector dense. Dùng trong similarity search, semantic search và RAG workflows. Hỗ trợ đa ngôn ngữ, tối ưu cho các bài toán tri thức doanh nghiệp. AWS AI Services – Dịch vụ AI dựng sẵn Rekognition – phân tích hình ảnh/video Translate – dịch ngôn ngữ Textract – trích xuất văn bản \u0026amp; layout từ tài liệu Transcribe – chuyển giọng nói thành văn bản Polly – chuyển văn bản thành giọng nói Comprehend – phân tích ngôn ngữ tự nhiên Kendra – tìm kiếm doanh nghiệp thông minh Lookout – phát hiện bất thường Personalize – gợi ý cá nhân hóa Demo nổi bật:\nỨng dụng nhận diện khuôn mặt AMZPhoto, minh họa việc tích hợp AI/ML vào sản phẩm thực tế trên AWS.\nBedrock Agents \u0026amp; AgentCore Bedrock Agents Agents có thể tự thực thi multi-step workflows. Kích hoạt Lambda để gọi API, database và các workflow bên ngoài. Có thể thay thế một phần backend business logic trong nhiều use case. Kết hợp chặt chẽ với EventBridge và Step Functions trong pipeline AI để orchestrate và retry. Amazon Bedrock AgentCore Framework mới hỗ trợ xây dựng AI Agents sẵn sàng cho môi trường production:\nThực thi và mở rộng workflows của agent một cách an toàn. Quản lý bộ nhớ dài hạn (long-term memory). Thiết lập identity \u0026amp; access control chi tiết. Tích hợp với các công cụ như Browser Tool, Code Interpreter, Memory Store. Cung cấp khả năng observability \u0026amp; auditing. Hỗ trợ nhiều agent framework phổ biến: CrewAI, LangGraph, LlamaIndex, OpenAI Agents SDK, v.v. CICD Workflow cho Containers (ECR + ECS) Quy trình chuẩn AWS DevSecOps cho AI/ML containers:\nDeveloper commit code → CodeCommit CodeBuild build image + chạy tests Push image lên ECR ECS pull image để deploy (Fargate / EC2) CloudWatch giám sát logs \u0026amp; metrics CodePipeline orchestrate toàn bộ quy trình DevSecOps (bảo mật trong pipeline):\nValidation trong CodeBuild (unit tests, static analysis) Image scanning trong ECR (vulnerability scan) Deployment policies / IAM controls để kiểm soát việc deploy → Đây là DevSecOps chuẩn AWS.\nNhững Gì Học Được Kiến Thức AI/ML Nền Tảng \u0026amp; GenAI Hiểu rõ ML lifecycle. Nắm được feature engineering, model deployment \u0026amp; monitoring. Biết cách tối ưu chi phí training/inference. Cách chọn Foundation Model phù hợp với từng use case. Kỹ thuật prompt engineering nâng cao (CoT, role, multi-step, RAG-aware prompting). Thiết kế RAG architecture theo chuẩn production. Xây dựng Agents để tự động thực thi workflows phức tạp. Kiến Trúc Kỹ Thuật Quan Trọng IaC (Infrastructure as Code): Terraform vs CloudFormation vs CDK. Container inference workflow: ECS / ECR cho AI inference container. Monitoring \u0026amp; Observability: giám sát AI workloads bằng CloudWatch + X-Ray. Ứng Dụng Vào Công Việc Build chatbot doanh nghiệp với Bedrock + RAG (retrieval-augmented generation). Thiết kế kiến trúc AI end-to-end (data → ML → app). Dùng Lambda + Step Functions để điều phối RAG pipeline. Dùng Terraform / CDK để xây dựng hạ tầng GenAI chuẩn enterprise. Triển khai inference containers qua ECS / Fargate. Áp dụng kiến thức về AgentCore và Agents cho các dự án GenAI nội bộ trong tương lai. Trải Nghiệm Trong Event Tham gia workshop “AWS Cloud Mastery Series #1” giúp tôi thấy rõ cách AWS triển khai AI/ML thực tế, hiểu sự khác nhau giữa ML truyền thống và GenAI, và nâng cao tư duy thiết kế AI architecture.\nHọc hỏi từ các diễn giả có chuyên môn cao, hiểu chi tiết cách AWS xây dựng hệ sinh thái AI/ML/GenAI toàn diện.\nThực hành sử dụng các công cụ hiện đại:\nSageMaker: từ chuẩn bị dữ liệu → training → tuning → deployment → MLOps. Bedrock: dùng Claude, Llama, Titan, RAG + Agents để xây chatbot và workflow AI nhanh. IaC \u0026amp; DevOps: CloudFormation, CDK, Terraform, CodePipeline để triển khai AI/ML có kiểm soát và tự động. Data \u0026amp; ETL Tools: Glue, S3 (Data Lake), EventBridge, Step Functions cho data pipeline. Monitoring: CloudWatch cho logging \u0026amp; drift detection. Về networking và tư duy:\nHọc cách suy nghĩ theo hướng AI system thay vì chỉ tập trung vào một mô hình ML. Nắm bắt xu hướng AI/ML tại Việt Nam và cách doanh nghiệp đang ứng dụng. Bài học rút ra GenAI và ML truyền thống kết hợp để tạo nên các giải pháp AI mạnh trong thực tế. Bedrock là nền tảng GenAI doanh nghiệp: an toàn, triển khai nhanh, không cần tự train model. MLOps + IaC là bắt buộc để hệ thống AI chạy ổn định trong production. RAG là cách hiệu quả nhất để “đưa kiến thức doanh nghiệp vào mô hình”. Tổng thể, sự kiện không chỉ mang lại kiến thức kỹ thuật mà còn giúp tôi xây dựng tư duy kiến trúc hệ thống AI/ML hoàn chỉnh, từ dữ liệu → mô hình → triển khai → vận hành, tạo nền tảng vững chắc cho các dự án AI/GenAI thực tế trong tương lai.\nMột số hình ảnh khi tham gia sự kiện "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch: “AWS Cloud Mastery Series #2 – DevOps on AWS” Mục Đích Của Sự Kiện Giới thiệu về các dịch vụ DevOps trên AWS và cách thiết kế pipeline CI/CD. Trang bị tư duy DevOps hiện đại và cách áp dụng trên hệ sinh thái AWS. Khám phá các khái niệm về Infrastructure as Code (IaC) và các công cụ liên quan (CloudFormation, CDK, Terraform). Trình bày tổng quan về các workload dạng container trên AWS (ECR, ECS, EKS, App Runner). Minh họa cách đạt được giám sát và quan sát (monitoring \u0026amp; observability) hiệu quả bằng các dịch vụ gốc của AWS. Tối ưu tốc độ phát triển, chất lượng release và độ tin cậy của hệ thống. Danh Sách Diễn Giả Trương Quang Tình – AWS Community Builder, Platform Engineer (TymeX) Bảo Huỳnh – AWS Community Builder Nguyễn Khánh Phúc Thịnh – AWS Community Builder Trần Đại Vĩ – AWS Community Builder Huỳnh Hoàng Long – AWS Community Builder Phạm Hoàng Quý – AWS Community Builder Nghiêm Lê – AWS Community Builder Đinh Lê Hoàng Anh – Cloud Engineer Trainee, First Cloud AI Journey (Cùng với các anh/chị trong FCJ Team, AWS Developer Advocate Team và khách mời cộng đồng.)\nNội Dung Nổi Bật Xây dựng nền tảng tư duy DevOps Các diễn giả nhấn mạnh: DevOps không chỉ là job title mà là tư duy + thói quen làm việc:\nTự động hóa (automation) các tác vụ lặp đi lặp lại. Chia sẻ kiến thức giữa các vai trò (Dev, Ops, QA, Security…). Liên tục thử nghiệm, học hỏi và cải tiến (continuous learning). Quyết định dựa trên số liệu đo lường được, không chỉ dựa vào cảm tính. Những lỗi phổ biến của người mới:\nChỉ “đi theo tutorial” mà không tự làm dự án thực tế. Quá so sánh bản thân với người khác thay vì tập trung vào tiến bộ nhỏ nhưng đều đặn. Thông điệp lặp lại nhiều lần:\nKhông có CI/CD → không có DevOps.\nKhông IaC → không DevOps.\nInfrastructure as Code (IaC) Các công cụ/approach được so sánh và phân tích:\nCloudFormation\nDịch vụ gốc của AWS, mô hình khai báo (declarative). Phù hợp cho nhiều team enterprise, muốn sử dụng dịch vụ native. AWS CDK\nCho phép định nghĩa hạ tầng bằng ngôn ngữ lập trình (TypeScript, Python, Java,…). Mô hình: Constructs → Stacks → Apps. Dễ modular hóa, tái sử dụng, test, phù hợp Agile teams / developer-friendly. Terraform\nPhù hợp multi-cloud / hybrid. Quản lý state file, hỗ trợ nhiều provider. Các khái niệm được giải thích bằng ví dụ thực tế:\nStack, Construct, State file, template YAML (Resources, Parameters, Outputs, Mappings)… Thông điệp quan trọng:\nHạ tầng được định nghĩa bằng IaC sẽ nhất quán, có version control, dễ review, dễ rollback hơn rất nhiều so với cấu hình thủ công bằng click-ops. AWS DevOps Services – CI/CD Pipeline Nội dung xoay quanh cách xây dựng pipeline chuẩn AWS:\nCI/CD với AWS:\nCodePipeline – orchestration cho toàn bộ pipeline. CodeBuild – build, test, lint, static analysis (buildspec.yml, build caching, parallel tests). CodeDeploy – triển khai ứng dụng (blue/green, canary, rolling). Demo pipeline end-to-end:\nCommit → Build → Test → Deploy → Monitor. Nhấn mạnh: deployment phải tự động hóa 100%, không “click deploy” thủ công trên console. Chiến lược DevOps:\nBắt đầu từ small pipeline, sau đó mở rộng dần. Dùng blue/green và canary deployment để giảm rủi ro. Kết hợp IaC + GitOps cho môi trường nhiều team. Container và mô hình triển khai trên AWS Docker fundamentals Dockerfile → Build → Image → Registry → Run container Registry: Docker Hub hoặc Amazon ECR Amazon ECR Lưu trữ container image. Hỗ trợ image scanning, lifecycle policies, phân quyền theo repository. Amazon ECS Orchestrate container với Fargate hoặc EC2. Tích hợp Application Load Balancer, autoscaling theo CPU, memory, queue length. Amazon EKS Managed Kubernetes service trên AWS. Phù hợp với large-scale, multi-team, yêu cầu portability, cần K8s ecosystem. AWS App Runner Dịch vụ “deploy container như deploy lên Vercel/Netlify” cho backend/web. Phù hợp team muốn giảm tối đa việc quản lý hạ tầng / cluster. Case study \u0026amp; so sánh ECS, EKS, App Runner:\nECS: dễ dùng, native AWS, phù hợp đa số workload container trên AWS. EKS: tối ưu khi đã dùng K8s hoặc cần multi-cloud portability. App Runner: phù hợp team nhỏ, startup, feature team muốn tập trung vào code. Monitoring \u0026amp; Observability Phần này tập trung vào CloudWatch và X-Ray:\nAmazon CloudWatch Thu thập Metrics, Logs, Dashboards. Composite alarms, log filters, custom metrics cho business KPIs. AWS X-Ray Distributed tracing: vẽ service map, trace end-to-end request. Rất hữu ích để debug latency, bottlenecks trong microservices. Best practices:\nThiết kế alert hợp lý để tránh “alert noise”. Xây dựng on-call workflow và runbook rõ ràng. Dựa vào Golden Signals: Latency, Traffic, Errors, Saturation. Thông điệp được nhấn mạnh:\nKhông observability = không biết hệ thống đang chết như thế nào.\nNhững Gì Học Được DevOps không chỉ là chức danh mà là tư duy + tập hợp thói quen: automation, sharing, measurable outcomes. IaC giúp hạ tầng: Nhất quán Có thể lặp lại Dễ bảo trì, dễ audit, dễ rollback Lựa chọn công cụ IaC (CloudFormation / CDK / Terraform) phải dựa trên: Nhu cầu đội nhóm Yêu cầu dự án Mức độ phức tạp \u0026amp; môi trường (AWS-only hay multi-cloud). Hiểu rõ sự khác biệt giữa các dịch vụ container (ECR, ECS, EKS, App Runner) giúp: Chọn đúng dịch vụ cho đúng loại workload. Monitoring \u0026amp; Observability không phải “add-on cuối cùng” mà phải được thiết kế ngay từ đầu. Nắm thêm nhiều khái niệm như: DORA metrics, CI → CD → Continuous Learning Blue/green, canary deployment GitOps, incident workflow, MTTR… Ứng Dụng Vào Công Việc Ví dụ: Dự án Chatbot AI trên AWS Nếu có cơ hội xây dựng một Chatbot AI trên AWS, tôi dự định áp dụng:\nThiết kế pipeline CI/CD:\nDùng CodePipeline + CodeBuild + CodeDeploy để tự động hóa build, test, deploy. Mỗi lần commit code cho chatbot (backend, Lambda, API) đều được test và deploy tự động. Infrastructure as Code:\nDùng AWS CDK để định nghĩa toàn bộ hạ tầng: Lambda, API Gateway, DynamoDB, S3, IAM, EventBridge,… Mọi thứ được version control trên Git, dễ tái sử dụng và mở rộng. Container hóa \u0026amp; triển khai:\nĐóng gói một số service (ví dụ: RAG API, vector DB interface) thành Docker image. Deploy lên ECS (Fargate) hoặc App Runner tùy nhu cầu scale. Monitoring \u0026amp; Incident handling:\nDùng CloudWatch metrics + logs + dashboards để quan sát chatbot. Áp dụng X-Ray nếu kiến trúc là microservices. Thiết lập incident workflow: alert → investigate → fix → postmortem (runbook, on-call). Nhờ áp dụng DevOps + AWS, hệ thống chatbot AI có thể:\nPhát triển nhanh hơn (dev velocity cao). Triển khai thường xuyên nhưng vẫn an toàn. Dễ bảo trì, dễ mở rộng khi lượng người dùng tăng. Trải Nghiệm Sự Kiện Sự kiện giúp tôi có cái nhìn thực tế hơn về cách các tổ chức hiện đại triển khai DevOps trên AWS. Các diễn giả không chỉ nói lý thuyết mà còn chia sẻ rất nhiều ví dụ thật, từ IaC, CI/CD đến container orchestration. Được xem demo: Pipeline từ commit → deploy live. Drift detection, cdk synth/deploy. Triển khai container real-time trên ECS/ECR. Cơ hội kết nối với các bạn cùng chí hướng, trao đổi kinh nghiệm học DevOps, AWS, Cloud. Bài học rút ra Không có CI/CD → không có DevOps. IaC là điều kiện tiên quyết để automation thực sự hiệu quả. Containers = scalability + portability + speed. Observability = reliability – nếu không quan sát được, không thể tin hệ thống sẽ sống khỏe trong production. Tổng kết lại, “AWS Cloud Mastery Series #2 – DevOps on AWS” không chỉ giúp tôi nắm vững khái niệm DevOps trên lý thuyết, mà còn định hình rõ hơn cách xây dựng hệ thống tự động hóa – có thể mở rộng – dễ quan sát trên AWS, từ đó tạo nền tảng vững chắc cho các dự án Cloud \u0026amp; DevOps trong tương lai.\nMột số hình ảnh khi tham gia sự kiện "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch: “AWS Cloud Mastery Series #3 – AWS Well-Architected Security Pillar Workshop” Mục Tiêu Sự Kiện Chia sẻ và củng cố kiến thức cốt lõi trong AWS Well-Architected Framework – Security Pillar.\nTrang bị tư duy và kỹ năng xây dựng hệ thống an toàn, bền vững, tuân thủ chuẩn AWS.\nĐi sâu vào 5 trụ cột bảo mật chính:\nIdentity \u0026amp; Access Management (IAM) Detection \u0026amp; Continuous Monitoring Infrastructure Protection Data Protection Incident Response Giới thiệu sáng kiến AWS Cloud Clubs và các hoạt động cộng đồng hỗ trợ sinh viên học cloud tại trường đại học.\nDiễn Giả Lê Vũ Xuân An – AWS Cloud Club Captain HCMUTE Trần Đức Anh – AWS Cloud Club Captain SGU Trần Đoàn Công Lý – AWS Cloud Club Captain PTIT Danh Hoàng Hiếu Nghị – AWS Cloud Club Captain HUFLIT Huỳnh Hoàng Long – AWS Community Builder Đinh Lê Hoàng Anh – AWS Community Builder / Cloud Engineer Trainee Nguyễn Tuấn Thịnh – Cloud Engineer Trainee Nguyễn Đỗ Thành Đạt – Cloud Engineer Trainee Văn Hoàng Kha – Cloud Security Engineer, AWS Community Builder Thịnh Lâm – FCJ Member Việt Nguyễn – FCJ Member Mendel Grabski (Long) – Ex-Head of Security \u0026amp; DevOps, Cloud Security Solution Architect Trịnh Trương – Platform Engineer tại TymeX, AWS Community Builder (Cùng với các anh/chị trong FCJ Team và cộng đồng AWS.)\nCác Điểm Nổi Bật Giới Thiệu AWS Cloud Club \u0026amp; Security Foundation Sự kiện mở đầu với:\nGiới thiệu về AWS Cloud Club:\nNền tảng giúp sinh viên phát triển kỹ năng cloud qua tình huống thực tế. Cơ hội nhận mentorship từ chuyên gia AWS \u0026amp; cộng đồng. Xây dựng cộng đồng, kết nối sinh viên từ nhiều trường: HCMUTE, SGU, PTIT, HUFLIT… Security Foundation – Nền tảng bảo mật AWS:\nLeast Privilege – Zero Trust – Defense in Depth: 3 nguyên tắc nền tảng cho hệ thống bảo mật hiện đại. Shared Responsibility Model: AWS bảo mật của cloud. Khách hàng bảo mật trong cloud. Top Cloud Threats tại Việt Nam:\nPublic S3 / databases / Redis Lộ access key IAM cấu hình sai EC2 nhiễm malware (đào coin) Thiếu logging hoặc không bật GuardDuty Thông điệp chính: Security = culture, not a feature – bảo mật là văn hóa, không phải tính năng gắn thêm.\nTrụ cột 1 – Identity \u0026amp; Access Management (IAM) IAM là trọng tâm của Security Pillar:\nÁp dụng Least Privilege triệt để. Xóa root access keys sau khi thiết lập ban đầu. Tránh dùng wildcard permission (*). Modern IAM Practices IAM Users: gần như không còn phù hợp → ưu tiên:\nRoles \u0026gt; Users SSO \u0026gt; Local credentials OIDC \u0026gt; Access Keys IAM Identity Center (SSO):\nQuản lý người dùng \u0026amp; quyền trong multi-account environment. Quyền tổ chức (Organizational controls):\nDùng SCP (Service Control Policies) để giới hạn quyền ở mức organization. Sử dụng Permission Boundaries để giới hạn phạm vi quyền của user/role. Xác thực \u0026amp; giám sát:\nBắt buộc credential rotation \u0026amp; MFA. Dùng IAM Access Analyzer để phát hiện policy quá rộng, public, sharing ngoài ý muốn. MFA với TOTP vs FIDO2: so sánh về bảo mật \u0026amp; khả năng phục hồi. Secrets Management:\nDùng AWS Secrets Manager với vòng đời xoay vòng:\ncreate → set → test → finalize Không hard-code secrets trong code / môi trường. Trụ cột 2 – Detection \u0026amp; Continuous Monitoring Multi-layer Observability CloudTrail:\nManagement Events: API calls, thay đổi cấu hình. Data Events: activity chi tiết trên S3 object, Lambda execution. Triển khai organization-level CloudTrail cho toàn bộ accounts. Logging sources:\nVPC Flow Logs, S3 access logs, ALB logs để truy vết network \u0026amp; access patterns. Amazon GuardDuty:\nDịch vụ phát hiện mối đe dọa liên tục, phân tích: CloudTrail events VPC Flow Logs DNS queries Phát hiện: Tắt logging Lưu lượng bất thường Truy cập domain độc hại Malware scanning trên S3 EKS audit logs RDS anomaly detection Lambda network behavior, runtime protection Liên hệ với AWS Foundational Security Best Practices \u0026amp; CIS Benchmarks. Security Hub:\nTổng hợp findings từ GuardDuty, IAM Access Analyzer, Config, v.v. vào một dashboard trung tâm. Alerting \u0026amp; Automation Dùng EventBridge để:\nGửi cảnh báo (SNS, email, chat…). Trigger Lambda / Step Functions cho tự động remediation. Hỗ trợ cross-account event routing cho mô hình security tập trung. Detection-as-Code:\nQuản lý detection logic như IaC: CloudTrail Lake queries Event patterns trên EventBridge Giúp review, test, deploy detection rules có kiểm soát. Case study: Nếu không có logs → không có bằng chứng → không thể điều tra incident.\nTrụ cột 3 – Infrastructure Protection VPC Segmentation:\nGiảm blast radius khi hệ thống bị tấn công bằng cách chia nhỏ \u0026amp; cô lập môi trường. Subnet placement (Public vs Private):\nPublic: ALB, NAT Gateway, public bastion (nếu có). Private: EC2 app, databases, internal services. Security Group (SG) vs Network ACL (NACL):\nSG: stateful, gắn vào instance, là “tường chính”. NACL: stateless, gắn vào subnet, là lớp bổ trợ. Edge Protection:\nAWS WAF, Shield Advanced, AWS Network Firewall cho lớp phòng thủ biên. Tích hợp threat intel từ GuardDuty để tự động chặn. Workload Hardening:\nPatching thường xuyên EC2/ECS/EKS. Giảm thiểu quyền IAM cho workload. Image scanning trước khi deploy. Runtime protections. Case study: Rất nhiều lỗi bảo mật đến từ việc đặt nhầm tài nguyên vào public subnet – luôn check placement trước khi deploy.\nTrụ cột 4 – Data Protection Encryption everywhere:\nBật mã hóa at-rest cho S3, EBS, RDS, DynamoDB. Bắt buộc TLS/HTTPS khi truy cập S3, DynamoDB, RDS… AWS KMS:\nQuản lý CMK → Data Key. Key policies, Grants, rotation. Dùng IAM conditions để kiểm soát hoạt động mã hóa/giải mã. Secrets Management:\nSecrets Manager / SSM Parameter Store: Secret rotation tự động. Tách biệt config \u0026amp; secret khỏi code. ACM (AWS Certificate Manager):\nCung cấp chứng chỉ miễn phí + auto-renew cho ALB, CloudFront, API Gateway. Data classification \u0026amp; guardrails:\nPhân loại dữ liệu theo sensitivity (Public / Internal / Confidential / Restricted). Áp dụng guardrails tương ứng: IAM, encryption, network controls. Case study: Encrypt từ đầu giúp giảm đáng kể rủi ro khi xảy ra data breach.\nTrụ cột 5 – Incident Response (IR) AWS IR Lifecycle:\nPrepare → Detect → Investigate → Respond → Recover Playbooks (ví dụ) IAM key bị compromise S3 bucket bị public EC2 dính malware / mining Công cụ \u0026amp; kỹ thuật xử lý Tạo Snapshot (EBS / instance) để lưu evidence. Isolation: thay đổi SG / NACL để cô lập instance. Thu thập evidence phục vụ forensics \u0026amp; audit. IR Automation Lambda: chạy remediation nhỏ (revert policy, block IP, disable key…). Step Functions: điều phối quy trình IR phức tạp nhiều bước. EventBridge: trigger playbooks dựa trên sự kiện từ GuardDuty, CloudTrail, Security Hub… Kết luận: Incident Response không thể phụ thuộc 100% vào con người – cần tự động hóa càng nhiều càng tốt.\nNhững Gì Học Được Tư Duy Bảo Mật Hiện Đại Zero Trust \u0026amp; Least Privilege: không tin mặc định, mọi quyền đều tối thiểu. Defense in Depth: nhiều lớp phòng thủ để giảm rủi ro khi một lớp bị vượt qua. Traceability \u0026amp; IaC: Mọi thay đổi phải traceable. Hạ tầng nên được triển khai bằng IaC để giảm misconfiguration. Không tin vào cấu hình tay → ưu tiên automation + IaC + review. Kiến Trúc Kỹ Thuật Quan Trọng IAM:\nRoles \u0026gt; Users SSO \u0026gt; Local credentials OIDC \u0026gt; Long-lived Access Keys Network:\nPrivate-first: mặc định đặt tài nguyên vào private subnet. SG là “tường chính” (stateful), NACL là lớp hỗ trợ (stateless). Outbound filtering quan trọng không kém inbound. Data:\nEncrypt by default (S3, EBS, RDS, DynamoDB). Secret rotation theo policies. Giảm tối đa exposure cho S3/DB. Detection:\nCloudTrail ON GuardDuty ON Logging đầy đủ để phục vụ điều tra sự cố. Incident Response:\nCó playbook rõ ràng. Có automation cho remediation \u0026amp; rollback. Có snapshot/backup để phục hồi nhanh. Chiến Lược Hiện Đại Hóa Không làm ồ ạt, mà đi theo phased approach. Dùng multi-account architecture để giảm blast radius và tách biệt môi trường. Ứng Dụng Vào Công Việc Trong dự án AI Chatbot của nhóm:\nThiết kế IAM dựa trên Roles + Permission Sets thay vì user trực tiếp. Áp dụng VPC segmentation và private-first design cho backend, DB, vector store. Bật GuardDuty + CloudTrail ở org-level cho toàn bộ môi trường dev/prod. Thiết lập Alerting \u0026amp; IR automation: EventBridge → Lambda / Step Functions cho auto-remediation. Dùng Secrets Manager + rotation thay vì hard-code secret trong code/ENV. Triển khai hạ tầng bằng Terraform/CDK để giảm drift và sai sót cấu hình. Kết quả kỳ vọng: hệ thống chatbot ổn định hơn, an toàn hơn, dễ audit và dễ mở rộng.\nTrải Nghiệm Sự Kiện Sự kiện được tổ chức tốt, giúp tôi có cái nhìn toàn diện về Security Pillar trong AWS Well-Architected. Học hỏi được cách AWS và các doanh nghiệp lớn: Tổ chức mô hình multi-account. Xử lý incident \u0026amp; detection trong môi trường production thực tế. Trải nghiệm kỹ thuật Thực hành phân tích policy bằng IAM Simulator. Thấy được flow thực tế của S3 public exposure → auto-remediation. Quan sát IR automation xử lý EC2 bị compromise. Tư duy \u0026amp; kết nối Nhận ra cách doanh nghiệp lớn tổ chức bảo mật theo kiến trúc multi-account. Thấm nhuần tư duy “secure by design” – không chờ bị tấn công mới vá. Kết nối với các bạn cùng đam mê security/cloud, tạo nền tảng cho học tập \u0026amp; làm việc lâu dài. Bài học rút ra Security = culture, not a feature. Misconfiguration là nguyên nhân lớn nhất → IaC là cứu cánh. Không thể vận hành cloud an toàn nếu thiếu: IAM tốt + Logging đầy đủ + IR rõ ràng. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.1-introduction/","title":"Giới thiệu","tags":[],"description":"","content":"Tuyên bố vấn đề Các hệ thống chatbot truyền thống gặp khó khăn khi không có khả năng truy cập thông tin cụ thể từ tài liệu nội bộ, dẫn đến trả lời không chính xác hoặc không liên quan. Workshop này giải quyết vấn đề bằng cách xây dựng một kiến trúc có khả năng:\nTự động hóa: Xử lý và đánh chỉ mục tài liệu PDF tự động Hỏi nội dung: Nhận truy vấn và điều hướng người dùng đến nội dung liên quan Truy xuất tài liệu: Trả lời các câu hỏi phức tạp với trích dẫn nguồn chính xác từ tài liệu Kiến trúc giải pháp Hệ thống được thiết kế theo mô hình RAG (Retrieval-Augmented Generation) kết hợp với AWS Serverless để đảm bảo khả năng mở rộng:\nFrontend Interface: Người dùng tương tác qua React Web Application\nAmazon API Gateway nhận requests từ Frontend AWS Amplify hosting với CloudFront CDN Amazon Cognito xử lý authentication Request Handling:\nApplication Load Balancer định tuyến traffic đến EC2 FastAPI Backend xử lý REST API requests Amazon SQS (FIFO) đảm bảo thứ tự xử lý documents Backend Processing:\nChatHandler: Quản lý hội thoại, lưu session vào Amazon DynamoDB RAG Service: Orchestrate vector search và LLM generation Qdrant Vector Database: Self-hosted trên EC2 cho vector search AI \u0026amp; Data Layer:\nAmazon Bedrock: Sử dụng Claude 3.5 Sonnet (LLM) và Cohere Embed Multilingual v3 (Embeddings) Amazon Textract: OCR và trích xuất text từ PDF Amazon S3: Lưu trữ documents Amazon DynamoDB: Metadata và chat history Admin Dashboard:\nReact-based interface hosted trên AWS Amplify Upload và quản lý documents Monitor processing status View chat history Architect Key Technologies Trong workshop này, bạn sẽ làm việc với các dịch vụ AWS chính sau:\nAmazon Bedrock: Trái tim của AI, cung cấp các Foundation Models (Claude, Cohere) để xử lý ngôn ngữ và sinh embeddings Amazon Textract: Xây dựng IDP pipeline để trích xuất text từ PDF documents Amazon EC2 \u0026amp; VPC: Cơ sở hạ tầng compute và network cho backend services Amazon S3: Lưu trữ documents và static assets Amazon DynamoDB: Lưu trữ metadata, chat history và document status Amazon Cognito: Authentication và user management AWS Amplify: Hosting frontend application với CI/CD tích hợp Amazon SQS: Message queue cho document processing pipeline Qdrant (Self-hosted): Vector database cho semantic search Terraform (IaC): Triển khai toàn bộ hạ tầng dưới dạng mã "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.2-week2/","title":"Nhật ký Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Hiểu AWS Budgets và cách sử dụng để quản lý, giám sát chi phí AWS. Tìm hiểu các loại AWS Budgets khác nhau: Cost Budget, Usage Budget, RI Budget, Savings Plans Budget. Thực hành tạo budgets bằng template và thiết lập tùy chỉnh, cũng như dọn dẹp tài nguyên sau khi sử dụng. Hiểu về AWS Support: các gói hỗ trợ, cách truy cập AWS Support, và cách tạo, quản lý yêu cầu hỗ trợ (support request). Nâng cao nhận thức về kiểm soát chi phí và cách nhận hỗ trợ từ AWS khi có sự cố xảy ra. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu tổng quan về AWS Budgets + AWS Budgets là gì? + Tại sao sử dụng budgets để kiểm soát chi phí? + Các loại budgets (Cost, Usage, RI, Savings Plans) 15/09/2025 15/09/2025 https://000007.awsstudygroup.com/ 2 - Thực hành với Budgets (1): + Tạo Budget bằng Template + Tạo Cost Budget với các ngưỡng cảnh báo (alert thresholds) + Xem chi tiết budget và cấu hình thông báo 16/09/2025 16/09/2025 https://000007.awsstudygroup.com/ 3 - Thực hành với Budgets (2): + Tạo Usage Budget cho một dịch vụ cụ thể (ví dụ: EC2) + Tạo RI Budget + Hiểu khi nào nên sử dụng từng loại budget 17/09/2025 17/09/2025 https://000007.awsstudygroup.com/ 4 - Thực hành với Budgets (3): + Tạo Savings Plans Budget + Xem các cảnh báo và ví dụ về kịch bản vượt chi phí (cost overrun) + Dọn dẹp budgets và các tài nguyên liên quan sau khi hoàn thành lab 18/09/2025 18/09/2025 https://000007.awsstudygroup.com/ 5 - Tìm hiểu AWS Support: + Các gói AWS Support và sự khác nhau giữa chúng + Cách truy cập AWS Support Center - Thực hành: + Điều hướng đến Support Center + Tạo một support case + Xem / cập nhật / đóng yêu cầu hỗ trợ 19/09/2025 19/09/2025 https://000009.awsstudygroup.com/ Thành tựu Tuần 2 Tuần 2 tập trung vào việc xây dựng nền tảng vững chắc về quản lý chi phí và quy trình hỗ trợ (support) trên AWS. Thay vì chỉ học về các dịch vụ, mình học cách giữ cho môi trường AWS vận hành bền vững và có kiểm soát.\nHiểu vai trò của AWS Budgets trong quản lý chi phí\nMình đã hiểu rõ hơn về:\nAWS Budgets là gì và khác gì so với chỉ xem Billing dashboard. Tại sao việc cấu hình budgets một cách chủ động lại quan trọng để tránh các đợt tăng chi phí đột ngột. Cách budgets phù hợp trong bức tranh tổng thể chiến lược quản lý chi phí cho các workload trên AWS. Phân biệt các loại budget khác nhau\nMình đã học cách phân biệt các trường hợp sử dụng và điểm mạnh của từng loại budget:\nCost Budget – kiểm soát tổng chi tiêu (ví dụ: tất cả dịch vụ trong một tháng). Usage Budget – theo dõi mức sử dụng của các tài nguyên cụ thể (ví dụ: số giờ EC2, dung lượng S3). RI Budget – giám sát mức sử dụng và độ bao phủ (coverage) của Reserved Instances. Savings Plans Budget – theo dõi chi tiêu Savings Plans và giúp đảm bảo cam kết được sử dụng hiệu quả.\nĐiều này giúp mình hiểu rằng “một loại budget không phù hợp cho mọi trường hợp” và mỗi workload có thể cần một tổ hợp budget khác nhau. Trải nghiệm thực hành tạo và cấu hình budgets\nMình không chỉ đọc tài liệu – mà còn thực hành:\nTạo budgets bằng templates để thiết lập nhanh hơn. Tạo Cost Budget tùy chỉnh với các ngưỡng và chu kỳ cụ thể. Xem chi tiết cấu hình budget, bao gồm phạm vi (scope), chu kỳ (period) và bộ lọc (filters).\nThông qua đó, mình tự tin hơn khi làm việc trong Billing \u0026amp; Cost Management console, thay vì ngại đụng vào vì sợ “liên quan đến tiền”. Thiết lập cảnh báo (alerts) và kênh thông báo cho budgets\nMình cấu hình gửi email thông báo sao cho:\nGửi thông báo khi chi phí thực tế (actual costs) vượt ngưỡng đã đặt. Gửi thông báo khi dự đoán (forecasted costs) cho thấy chi phí có thể vượt quá budget.\nĐiều này giúp mình có góc nhìn thực tế về cách sử dụng budgets trong môi trường thật để phát hiện sớm vấn đề trước khi chúng trở thành khoản chi vượt kiểm soát. Dọn dẹp budgets và các tài nguyên còn sót lại sau khi làm lab\nSau khi hoàn thành phần thực hành:\nMình rà soát lại các budgets đang tồn tại và xóa những budget không còn cần thiết. Kiểm tra lại để đảm bảo không còn các cảnh báo hoặc cấu hình test dư thừa.\nThói quen này giúp tài khoản gọn gàng hơn và dễ quản lý hơn về lâu dài. Hiểu AWS Support và khi nào nên sử dụng\nMình đã học:\nSự khác nhau giữa các gói AWS Support Plans (Basic, Developer, Business, Enterprise). Những tính năng nào có trong gói Basic (ví dụ: tài liệu, diễn đàn) và những gì cần gói trả phí. Các kịch bản thực tế mà trong đó việc mở một AWS support case là lựa chọn đúng đắn, thay vì cố gắng tự xử lý mọi thứ. Thực hành sử dụng AWS Support Center\nMình đã thực hành:\nĐiều hướng đến AWS Support Center từ console. Tạo một support case, chọn đúng loại (category) và mức độ ưu tiên (severity). Xem, cập nhật và đóng các yêu cầu hỗ trợ.\nĐiều này giúp mình “gỡ bỏ sự mơ hồ” về quy trình support và cảm thấy thoải mái hơn khi cần nhờ AWS hỗ trợ một cách bài bản. Xây dựng nhận thức rõ hơn về kiểm soát chi phí và quy trình hỗ trợ\nNhìn chung, Tuần 2 giúp mình nhận ra rằng:\nSử dụng AWS một cách có trách nhiệm không chỉ là triển khai tài nguyên, mà còn là chủ động theo dõi chi phí. Biết khi nào và làm thế nào để liên hệ AWS Support là một kỹ năng quan trọng, đặc biệt trong môi trường gần với production.\nTư duy này sẽ rất hữu ích khi các tuần sau bắt đầu làm việc với kiến trúc và dịch vụ phức tạp hơn. 1. Đánh giá bản thân Tự tin hơn khi làm việc với Billing console\nLúc đầu, mình vẫn hơi ngại vào mục Billing vì sợ cấu hình sai gây phát sinh chi phí. Đến cuối tuần, sau khi đã tạo, chỉnh sửa và xóa nhiều budgets khác nhau, mình tự tin hơn khi điều hướng và đọc các thông tin liên quan đến chi phí.\nHiểu rõ hơn về khả năng quan sát chi phí và cảnh báo\nMình bắt đầu suy nghĩ theo hướng:\n“Nếu mình quên tắt một số tài nguyên thì chuyện gì sẽ xảy ra?” “Làm sao mình biết trước là chi phí sắp vượt mức cho phép?”\nĐây là một bước tiến lớn so với việc chỉ nghĩ về chức năng kỹ thuật thuần túy. Cách học có quy trình rõ ràng hơn\nMình tuân theo một chu trình:\nHọc khái niệm → làm lab thực hành → xem lại kết quả → dọn dẹp tài nguyên.\nCách này giúp mình ghi nhớ lâu hơn và tránh tình trạng chỉ “click cho xong” mà không hiểu gì. 2. Khó khăn gặp phải Khó phân biệt lúc đầu nên dùng loại budget nào\nBan đầu mình khá rối khi:\nKhi nào dùng Cost Budget và khi nào dùng Usage Budget? Trong trường hợp nào RI và Savings Plans Budget mới thực sự cần thiết?\nMình vượt qua bằng cách gắn mỗi loại budget với các tình huống sử dụng thực tế (ví dụ: sử dụng EC2 lâu dài, có cam kết dùng Savings Plans, hay môi trường sinh viên/Free Tier). Khó hiểu sự khác nhau giữa số liệu dự đoán và số liệu thực tế\nMình mất một khoảng thời gian để hiểu:\nSự khác nhau giữa actual và forecasted cost/usage. Tại sao alert có thể bật lên dù chi tiêu hiện tại vẫn chưa vượt budget (do dự đoán sẽ vượt).\nĐiều này đòi hỏi mình phải đọc kỹ thông tin trên console và thử nghiệm với nhiều ngưỡng khác nhau. Làm quen với quy trình tạo support case\nLần đầu tạo support case, mình gặp khó khăn trong việc:\nChọn đúng category và mức độ ưu tiên (severity). Viết mô tả vấn đề sao cho rõ ràng, ngắn gọn.\nSau vài lần thực hành, mình dần biết cách mô tả sự cố hiệu quả hơn – đây là kỹ năng quan trọng trong các dự án thực tế. Nhìn chung, Tuần 2 giúp mình củng cố hiểu biết về quản lý chi phí và quy trình hỗ trợ trên AWS. Đây là những kỹ năng thiết yếu để vận hành workload thực tế trên cloud, chứ không chỉ để hoàn thành lab hay bài thực hành. Kiến thức học được sẽ giúp mình tránh các tình huống thường gặp như hóa đơn bất ngờ tăng cao hoặc cảm giác “bí” khi hệ thống gặp sự cố trên môi trường đám mây.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/3-blogstranslated/3.2-blog2/","title":"Thúc đẩy làn sóng khởi nghiệp Generative AI tiếp theo","tags":[],"description":"","content":"by Swami Sivasubramanian | vào 13 THÁNG 6 2024 | trong AWS for Startups, Featured, Startup, Startup Spotlight\nNgay từ ngày đầu tiên, AWS đã giúp các startup biến ý tưởng thành hiện thực bằng cách dân chủ hóa quyền truy cập vào các công nghệ đang vận hành những doanh nghiệp lớn nhất thế giới, bao gồm cả Amazon. Kể từ năm 2020 đến nay, mỗi năm chúng tôi đã cung cấp cho các startup gần 1 tỷ USD AWS Promotional Credits. Không có gì ngạc nhiên khi 80% kỳ lân trên thế giới sử dụng AWS. Tôi may mắn được chứng kiến sự phát triển của rất nhiều startup trong suốt thời gian làm việc tại AWS—những công ty như Netflix, Wiz và Airtasker. Và tôi cảm thấy đầy hào hứng trước tốc độ mà các startup đang áp dụng trí tuệ nhân tạo tạo sinh (generative AI) và cách công nghệ này đang tạo ra một thế hệ startup hoàn toàn mới.\nNhững startup generative AI này có khả năng biến đổi các ngành công nghiệp và định hình tương lai, đó là lý do hôm nay chúng tôi công bố khoản đầu tư 230 triệu USD để thúc đẩy việc tạo ra các ứng dụng generative AI cho các startup trên toàn thế giới. Chúng tôi rất vui mừng được hợp tác với những startup có tầm nhìn, nuôi dưỡng sự phát triển của họ và mở ra những khả năng mới. Bên cạnh khoản đầu tư tài chính này, hôm nay chúng tôi cũng công bố chương trình AWS Generative AI Accelerator lần thứ hai hợp tác với NVIDIA. Đây là chương trình toàn cầu kéo dài 10 tuần (kết hợp trực tuyến và trực tiếp), được thiết kế để thúc đẩy làn sóng startup generative AI tiếp theo. Năm nay, chúng tôi mở rộng chương trình lên gấp 4 lần, hỗ trợ 80 startup trên toàn cầu. Các startup được lựa chọn sẽ nhận tới 1 triệu USD AWS Promotional Credits để phục vụ nhu cầu phát triển và mở rộng. Chương trình cũng cung cấp hỗ trợ go-to-market, cố vấn kinh doanh và kỹ thuật, và kết nối với chuyên gia từ AWS cũng như các đối tác quan trọng như NVIDIA, Meta, Mistral AI và các quỹ đầu tư mạo hiểm.\nXây dựng dịch vụ đám mây với Generative AI Bên cạnh các chương trình này, AWS cam kết giúp các startup ở mọi quy mô và các nhà phát triển ở mọi trình độ kỹ năng có thể xây dựng và mở rộng ứng dụng generative AI với bộ năng lực toàn diện nhất trên ba tầng của generative AI stack.\nỞ tầng dưới cùng, chúng tôi cung cấp hạ tầng để huấn luyện large language models (LLMs) và foundation models (FMs) và tạo ra suy luận hoặc dự đoán. Điều này bao gồm GPU NVIDIA tốt nhất và phần mềm tối ưu cho GPU, các chip machine learning tùy chỉnh như AWS Trainium và AWS Inferentia, cũng như Amazon SageMaker, giúp đơn giản hóa quy trình phát triển ML.\nỞ tầng giữa, Amazon Bedrock giúp startup dễ dàng xây dựng ứng dụng generative AI an toàn, tùy chỉnh và có trách nhiệm bằng cách sử dụng LLMs và các FMs từ những công ty AI hàng đầu.\nỞ tầng trên cùng, chúng tôi có Amazon Q, trợ lý AI mạnh mẽ nhất giúp tăng tốc phát triển phần mềm và khai thác dữ liệu nội bộ của doanh nghiệp.\nKhách hàng đang đổi mới bằng cách sử dụng công nghệ trên toàn bộ stack. Ví dụ, trong thời gian tôi tham dự hội nghị VivaTech ở Paris tháng trước, tôi đã trò chuyện với Michael Chen, VP of Strategic Alliances tại PolyAI, công ty cung cấp giải pháp giọng nói AI tùy chỉnh cho doanh nghiệp. PolyAI phát triển các mô hình chuyển văn bản thành giọng nói tự nhiên bằng Amazon SageMaker. Và họ xây dựng trên Amazon Bedrock để đảm bảo AI được vận hành một cách có trách nhiệm và đạo đức. Họ sử dụng Amazon Connect để tích hợp AI giọng nói vào hoạt động chăm sóc khách hàng.\nỞ tầng dưới cùng của stack, NinjaTech sử dụng chip Trainium và Inferentia2 cùng với Amazon SageMaker để xây dựng, huấn luyện và mở rộng các AI agents tùy chỉnh. Từ nghiên cứu đến lên lịch họp, các AI agent này giúp tiết kiệm thời gian và tiền bạc cho khách hàng bằng cách đưa generative AI vào quy trình làm việc hằng ngày. Gần đây tôi đã trò chuyện cùng Sam Naghshineh, đồng sáng lập và CTO, để thảo luận về cách tiếp cận này giúp khách hàng tiết kiệm thời gian và tài nguyên như thế nào.\nLeonardo.AI, một startup từ chương trình AWS Generative AI Accelerator 2023, cũng đang tận dụng AWS Inferentia2 để giúp nghệ sĩ và chuyên gia tạo ra tài sản hình ảnh chất lượng cao với tốc độ và sự nhất quán vượt trội. Bằng cách giảm chi phí suy luận mà không làm giảm hiệu suất, Leonardo.AI có thể cung cấp các tính năng generative AI tiên tiến nhất với mức giá dễ tiếp cận hơn.\nCác startup generative AI hàng đầu như Perplexity, Hugging Face, AI21 Labs, Articul8, Luma AI, Hippocratic AI, Recursal AI và DatologyAI đang xây dựng, huấn luyện và triển khai mô hình trên Amazon SageMaker. Chẳng hạn, Hugging Face đã sử dụng Amazon SageMaker HyperPod, một tính năng giúp tăng tốc huấn luyện lên đến 40%, để tạo ra các FMs mã nguồn mở mới. Tính năng tự động khôi phục job giúp giảm thiểu gián đoạn trong quá trình huấn luyện FM, tiết kiệm cho họ hàng trăm giờ mỗi năm.\nỞ tầng giữa, Perplexity tận dụng Amazon Bedrock với Anthropic Claude 3 để xây dựng công cụ tìm kiếm AI. Bedrock đảm bảo bảo vệ dữ liệu, căn chỉnh đạo đức thông qua lọc nội dung và triển khai Claude 3 ở quy mô lớn. Trong khi đó, Nexxiot—một công ty đổi mới trong lĩnh vực vận tải và logistics—nhanh chóng triển khai trợ lý Scope AI trên Amazon Bedrock với Anthropic Claude nhằm mang đến cho khách hàng khả năng phân tích hội thoại thời gian thực tốt nhất về tài sản vận tải của họ.\nỞ tầng trên cùng, Amazon Q Developer giúp các nhà phát triển tại startup xây dựng, kiểm thử và triển khai ứng dụng nhanh hơn và hiệu quả hơn, cho phép họ tập trung vào đổi mới. Ancileo, nhà cung cấp SaaS trong lĩnh vực bảo hiểm, sử dụng Amazon Q Developer để giảm 30% thời gian xử lý sự cố liên quan đến code, và đang tích hợp ticketing và tài liệu vào Amazon Q để tăng tốc onboarding, cho phép mọi người trong công ty nhanh chóng tìm ra câu trả lời.\nAmazon Q Business cho phép mọi thành viên trong startup đưa ra quyết định tốt hơn, nhanh hơn bằng cách tận dụng tri thức tập thể của tổ chức. Brightcove, nhà cung cấp dịch vụ video đám mây hàng đầu, triển khai Amazon Q Business để tối ưu hóa quy trình hỗ trợ khách hàng, giúp nhóm đẩy nhanh phản hồi, cung cấp dịch vụ cá nhân hóa hơn và nâng cao trải nghiệm khách hàng.\nTài nguyên dành cho các startup generative AI Tương lai của generative AI thuộc về những ai hành động ngay bây giờ. Cửa sổ đăng ký chương trình AWS Generative AI Accelerator mở từ ngày 13 tháng 6 đến ngày 19 tháng 7 năm 2024, và chúng tôi sẽ lựa chọn một nhóm global gồm các startup generative AI triển vọng nhất. Đừng bỏ lỡ cơ hội để định nghĩa lại điều gì là khả thi với generative AI — hãy đăng ký ngay!\nCác tài nguyên hữu ích khác bao gồm:\nBạn có thể sử dụng AWS Activate Credits của mình cho Amazon Bedrock để thử nghiệm FMs và xây dựng ứng dụng generative AI có trách nhiệm. Tìm hiểu sâu hơn bằng cách khám phá Generative AI Community để tiếp cận nội dung kỹ thuật, thông tin chuyên sâu và kết nối với các nhà xây dựng khác. AWS cũng cung cấp khóa đào tạo miễn phí giúp lực lượng lao động hiện tại và tương lai tận dụng công cụ generative AI của Amazon. Đối với những ai muốn học cách xây dựng với generative AI trên AWS, hãy xem Generative AI Learning Plan for Developers để có kỹ năng cần thiết. NVIDIA cung cấp chương trình miễn phí NVIDIA Inception, được thiết kế để hỗ trợ startup phát triển nhanh hơn thông qua công nghệ tiên tiến, kết nối với nhà đầu tư và truy cập tài nguyên kỹ thuật mới nhất từ NVIDIA. Hãy đăng ký ngay, khám phá các tài nguyên và tham gia vào cuộc cách mạng generative AI cùng AWS.\nTài nguyên bổ sung Twitch series: Let’s Ship It – with AWS! Generative AI\nAWS Generative AI Accelerator Program: đăng ký ngay!\nTAGS: Accelerators , AWS Startups\nSource:\nhttps://aws.amazon.com/blogs/startups/accelerating-the-next-wave-of-generative-ai-startups/\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Academic Research Chatbot Giải pháp AWS RAG-based hỗ trợ học thuật và nghiên cứu học tập thông minh 1. Tóm tắt điều hành Academic Research Chatbot là trợ lý AI hỗ trợ nghiên cứu học thuật, giúp sinh viên và giảng viên tra cứu, tóm tắt và phân tích tài liệu khoa học (PDF, bài báo) thông qua hội thoại tự nhiên có trích dẫn nguồn chính xác.\nĐiểm nổi bật của giải pháp:\nCông nghệ lõi: Kết hợp IDP (Amazon Textract) để xử lý tài liệu (kể cả bản scan) và RAG (Amazon Bedrock - Claude 3.5 Sonnet) để sinh câu trả lời thông minh. Kiến trúc tối ưu: Mô hình Hybrid sử dụng 1 EC2 t3.small kết hợp các dịch vụ Serverless (Amplify, Cognito, S3, DynamoDB) để cân bằng hiệu năng và chi phí. Tính khả thi: Phục vụ ~50 người dùng nội bộ với chi phí vận hành ~60 USD/tháng, thời gian triển khai nhanh (20 ngày) và tận dụng tối đa AWS Free Tier. 2. Tuyên bố vấn đề Vấn đề hiện tại Sinh viên và researcher phải làm việc với số lượng lớn tài liệu học thuật (paper hội nghị, journal, luận văn, báo cáo kỹ thuật). Nhiều tài liệu là scan PDF cũ (trước năm 2000), không có text layer, khiến việc tìm kiếm nội dung, số liệu, bảng biểu rất tốn thời gian. Các công cụ AI công cộng (ChatGPT, Perplexity, NotebookLM, v.v.) không được kết nối trực tiếp với kho tài liệu nội bộ của trường/khoa, khó đảm bảo bảo mật và quyền truy cập theo môn học hoặc nhóm nghiên cứu. Hạ tầng hiện tại không có một điểm truy cập thống nhất để:\nQuản lý tài liệu nghiên cứu theo bộ môn/đề tài. Cho phép researcher đặt câu hỏi trực tiếp trên chính các paper của mình. Đảm bảo câu trả lời có trích dẫn rõ ràng (paper, trang, bảng, mục). Hệ quả: nghiên cứu viên phải đọc thủ công, note tay, copy số liệu từ nhiều paper; giảng viên khó tổng hợp nhanh thông tin khi chuẩn bị bài giảng hoặc đề tài; dữ liệu học thuật phân tán trên nhiều máy cá nhân, khó chuẩn hóa và tái sử dụng. Giải pháp Academic Research Chatbot đề xuất xây dựng một nền tảng hỏi – đáp học thuật nội bộ dựa trên AWS, nơi:\nDev/Admin nạp kho tài liệu nghiên cứu: Upload PDF vào Amazon S3, metadata được lưu trong Amazon DynamoDB. Một EC2 worker tiêu thụ hàng đợi Amazon SQS, gọi Amazon Textract để OCR, trích xuất text, bảng, biểu mẫu, kể cả tài liệu scan. Worker chuẩn hóa/chunk nội dung, gửi sang Amazon Bedrock Titan Text Embeddings v2 để sinh embedding, và index vào Qdrant trên EC2. Researchers đặt câu hỏi qua giao diện web (Amplify + CloudFront): Câu hỏi được embed, truy vấn Qdrant để lấy các đoạn liên quan nhất (Retrieval). Các đoạn này được chuyển vào Claude 3.5 Sonnet trên Amazon Bedrock để sinh câu trả lời có citation chính xác (paper, page, section, table) và giải thích theo ngữ cảnh học thuật. Toàn bộ truy cập được bảo vệ bởi Amazon Cognito (phân quyền researcher vs admin), log \u0026amp; metric được giám sát qua Amazon CloudWatch + SNS (cảnh báo khi có lỗi worker, queue backlog, CPU EC2 cao). Lợi ích và hoàn vốn đầu tư (ROI) Hiệu quả học thuật:\nGiảm 40–60% thời gian researcher phải bỏ ra để tìm số liệu, F1-score, p-value, sample size, thiết bị thí nghiệm hoặc mô tả phương pháp từ nhiều paper khác nhau. Giảm sai sót khi trích dẫn do quên trang/bảng, vì chatbot luôn trả kèm nguồn và vị trí. Quản lý tri thức nội bộ: Tài liệu nghiên cứu được tập trung về một kho S3 + DynamoDB, dễ backup, phân quyền, và mở rộng. Có thể tái sử dụng cho nhiều khoá học, đề tài và lab khác nhau mà không phải xây hệ thống mới. Chi phí hạ tầng thấp \u0026amp; dễ kiểm soát: Mô hình hybrid 1 EC2 + managed AI services giúp chi phí vận hành cho 50 users nội bộ giữ ở mức khoảng \u0026lt; 50 USD/tháng, chủ yếu trả cho EC2, 2–3 VPC endpoint interface và phần sử dụng Bedrock/Textract. Hệ thống được thiết kế để triển khai trong khoảng 20 ngày bởi team 4 người, phù hợp làm dự án nghiên cứu/thực tập nhưng vẫn có chất lượng kiến trúc sản phẩm. Giá trị dài hạn: Tạo nền tảng để sau này tích hợp thêm dashboard phân tích hành vi học tập, module recommend paper, hoặc mở rộng sang trợ lý học tập đa ngôn ngữ và đa lĩnh vực. 3. Kiến trúc giải pháp Academic Research Chatbot áp dụng mô hình AWS Hybrid RAG Architecture với IDP (Intelligent Document Processing), kết hợp một EC2 duy nhất (FastAPI + Qdrant + Worker) với các dịch vụ AI managed (Textract, Bedrock) để vừa tối ưu chi phí, vừa đảm bảo hiệu năng cho khoảng 50 người dùng nội bộ.\nLuồng xử lý dữ liệu và hội thoại\nDịch vụ AWS sử dụng\nFrontend: Route 53, CloudFront, Amplify (DNS, CDN, Host React App). Auth: Cognito (Xác thực \u0026amp; phân quyền researcher/admin). Compute: EC2 t3.small (FastAPI + Qdrant + Worker). AI/ML: Bedrock (Claude 3.5 Sonnet, Titan Embeddings v2). IDP: Textract (OCR cho PDF scan). Storage: S3, DynamoDB (File PDF gốc + Metadata/Status). Queue: SQS (Hàng đợi xử lý tài liệu). Network: VPC, ALB, VPC Endpoints (Bảo mật, routing, kết nối AWS Services). Monitoring: CloudWatch, SNS (Logs, Metrics, Alerts). CI/CD: CodePipeline, CodeBuild (Auto deploy backend). Thiết kế thành phần\nNgười dùng: Researchers: hỏi – đáp, tra cứu nội dung học thuật. Dev/Admin: upload, quản lý và re-index tài liệu. Xử lý tài liệu (IDP): PDF được Dev/Admin upload lên S3. Worker trên EC2 gọi Textract để OCR và trích xuất text/bảng. Lập chỉ mục (Indexing \u0026amp; Vector DB): Worker chuẩn hoá, chia chunk nội dung. Gọi Bedrock Titan Embeddings v2 tạo embedding. Lưu embedding + metadata vào Qdrant trên EC2. Hội thoại AI (RAG): FastAPI embed câu hỏi, truy vấn Qdrant lấy top-k đoạn liên quan. Gửi context + câu hỏi vào Claude 3.5 Sonnet (Bedrock) để sinh câu trả lời kèm citation. Quản lý người dùng: Cognito xác thực và phân quyền researcher / admin. Lưu trữ \u0026amp; trạng thái: DynamoDB lưu metadata tài liệu (doc_id, status, owner, …) và (tuỳ chọn) lịch sử chat. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần chính — nền tảng web (UI + auth) và backend RAG + IDP — triển khai qua 4 giai đoạn:\nNghiên cứu \u0026amp; chốt kiến trúc: Rà soát yêu cầu (50 researcher, 1 EC2, IDP + RAG). Chốt kiến trúc VPC, EC2 (FastAPI + Qdrant + Worker), Amplify, Cognito, S3, SQS, DynamoDB, Textract, Bedrock. POC \u0026amp; kiểm tra kết nối: Tạo EC2, VPC endpoints, thử gọi Textract, Titan Embeddings, Claude 3.5 Sonnet. Chạy Qdrant đơn giản trên EC2, test insert/search vector. Tạo skeleton FastAPI + một màn hình Chat UI tối giản trên Amplify. Hoàn thiện tính năng chính: Xây /api/chat (FastAPI) + RAG pipeline: embed query → Qdrant → Claude + citation. Xây /api/admin/: upload PDF, lưu S3 + DynamoDB, đưa message vào SQS. Viết Worker trên EC2: SQS → Textract → normalize/chunk → Titan → Qdrant → update DynamoDB. Hoàn thiện Chat UI và Admin UI (upload + xem trạng thái tài liệu). Kiểm thử, tối ưu, triển khai demo nội bộ: Test end-to-end với một tập ~50–100 paper. Thêm CloudWatch Logs/Alarms, SNS notify khi lỗi hoặc queue backlog. Điều chỉnh cấu hình EC2, Qdrant, batch size để tối ưu thời gian và chi phí. Chuẩn bị tài liệu hướng dẫn sử dụng và demo cho nhóm 50 researcher. Yêu cầu kỹ thuật Frontend \u0026amp; Auth: React/Next.js host trên AWS Amplify, CDN CloudFront, DNS Route 53. Amazon Cognito quản lý định danh và phân quyền (Researcher/Admin). Backend \u0026amp; Compute: EC2 t3.small (Private Subnet) chạy All-in-one: FastAPI, Qdrant Vector DB và Worker. Xử lý bất đồng bộ: Worker đọc SQS, kích hoạt Textract và Bedrock để index dữ liệu. IDP \u0026amp; RAG: Lưu trữ: S3 (File gốc), DynamoDB (Metadata \u0026amp; Trạng thái). AI Core: Textract (OCR tài liệu scan), Bedrock Titan (Embedding), Claude 3.5 Sonnet (Trả lời câu hỏi). Mạng \u0026amp; Observability: Network: VPC Private Subnet, VPC Endpoints để kết nối bảo mật tới AWS Services. Monitoring: CloudWatch Logs/Metrics + SNS cảnh báo sự cố (CPU cao, lỗi Worker). 5. Lộ trình \u0026amp; Mốc triển khai Dự án được thực hiện trong khoảng 6 tuần với các giai đoạn cụ thể:\nTuần 1-2 (Ngày 1-10): Nghiên cứu \u0026amp; Thiết kế Thiết kế kiến trúc chi tiết, xác định scope, dịch vụ sử dụng. Lên kế hoạch tối ưu chi phí vận hành và triển khai. Tuần 3 (Ngày 11-15): Thiết lập hạ tầng AWS Cấu hình VPC, Subnets, Security Groups, IAM Roles. Triển khai EC2 t3.small, S3 bucket, DynamoDB tables. Thiết lập VPC Endpoints (Gateway + Interface). Tuần 4 (Ngày 16-20): Backend APIs \u0026amp; IDP Pipeline Xây dựng FastAPI endpoints (/api/chat, /api/admin/upload). Tích hợp IDP pipeline: SQS → Worker → Textract → Embeddings → Qdrant. Kết nối Bedrock (Titan Embeddings + Claude 3.5 Sonnet). Tuần 5 (Ngày 21-25): Testing \u0026amp; Error Handling Kiểm thử end-to-end với tập ~50-100 papers. Xử lý edge cases, retry logic, error handling. Tối ưu chunking strategy và retrieval accuracy. Tuần 6 (Ngày 26-30): Deployment \u0026amp; Documentation Hoàn thiện UI/UX cho Admin và Researcher. Thiết lập CloudWatch Alarms + SNS notifications. Chuẩn bị tài liệu hướng dẫn và demo cho nhóm 50 researcher. 6. Ước tính ngân sách Chi phí hạ tầng (ước tính theo tháng)\nCompute \u0026amp; Storage: EC2 t3.small: $10.08 (720h). EBS gp3: $2.40 (30GB). Network: NAT Gateway: $21.60. VPC Interface Endpoints: $14.60 (2 endpoints cho Textract, Bedrock). VPC Gateway Endpoints: FREE (S3, DynamoDB). AI \u0026amp; Operations: Bedrock Claude 3.5 Sonnet: $25.00 (50 users). Bedrock Titan Embeddings: $0.75 (750 papers). CloudWatch + Data Transfer: $1.90. Free Tier (12 tháng đầu)\nWeb \u0026amp; Auth: S3, CloudFront, Cognito, Amplify (FREE). Serverless: DynamoDB, SQS, SNS (Always FREE). IDP: Textract AnalyzeDocument (100 pages/month trong 3 tháng đầu). Tổng cộng: ~$60-76/tháng (tùy mức sử dụng Bedrock).\n7. Đánh giá rủi ro Ma trận rủi ro\nHallucination (AI bịa đặt): Ảnh hưởng cao, xác suất trung bình. Vượt ngân sách (AI Services): Ảnh hưởng trung bình, xác suất trung bình. Sự cố hạ tầng (EC2/Qdrant): Ảnh hưởng cao, xác suất thấp. Chiến lược giảm thiểu\nChất lượng AI: Bắt buộc trích dẫn nguồn (citation), giới hạn context đầu vào từ Qdrant. Chi phí: Thiết lập AWS Budgets/Alarms, kiểm soát số lượng tài liệu ingest. Hạ tầng \u0026amp; Bảo mật: Backup EBS định kỳ, mã hóa dữ liệu (S3/DynamoDB), phân quyền chặt chẽ qua Cognito/IAM. Kế hoạch dự phòng\nSự cố hệ thống: Khôi phục từ Snapshot, tạm dừng ingestion (buffer qua SQS). Vượt chi phí: Tạm khóa tính năng upload mới, giới hạn hạn ngạch truy vấn trong ngày. 8. Kết quả kỳ vọng Cải tiến kỹ thuật\nChuyển đổi kho tài liệu rời rạc (PDF/Scan) thành tri thức số có thể truy vấn và trích dẫn tự động. Giảm đáng kể thời gian tra cứu thủ công nhờ công nghệ RAG + IDP. Giá trị dài hạn Xây dựng nền tảng nghiên cứu số hóa cho 50+ researcher, dễ dàng mở rộng quy mô. Tạo tiền đề phát triển các tính năng nâng cao: Gợi ý tài liệu, phân tích xu hướng nghiên cứu và hỗ trợ viết tổng quan (Literature Review). "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.2-preparation/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"Yêu cầu Tiên quyết Các yêu cầu cần có để thực hiện workshop này:\nMáy tính khách AWS: Được cấu hình với quyền truy cập vào các dịch vụ AWS cần thiết Môi trường phát triển: Windows, macOS hoặc Linux với các công cụ development cơ bản Kiến thức cơ bản: Hiểu biết về AWS, Python, JavaScript và Docker Tài khoản GitHub: Để clone source code và theo dõi changes Ngân sách AWS: Khoảng $65/tháng cho các resources (EC2, Bedrock, NAT Gateway) Cài đặt công cụ 1. AWS CLI AWS Command Line Interface (AWS CLI) là công cụ để tương tác với AWS services.\nWindows:\n# Download và cài đặt MSI installer msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi macOS:\nbrew install awscli Linux:\ncurl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Verify installation:\naws --version # aws-cli/2.x.x Python/3.x.x 2. Terraform Terraform là công cụ Infrastructure as Code để provision AWS resources.\nWindows:\nchoco install terraform macOS:\nbrew tap hashicorp/tap brew install hashicorp/tap/terraform Linux:\nwget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg echo \u0026#34;deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\u0026#34; | sudo tee /etc/apt/sources.list.d/hashicorp.list sudo apt update \u0026amp;\u0026amp; sudo apt install terraform Verify:\nterraform --version 3. Docker Docker để chạy Qdrant vector database locally và trên EC2.\nWindows/macOS: Download Docker Desktop\nLinux:\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo usermod -aG docker $USER Verify:\ndocker --version docker run hello-world 4. Node.js (\u0026gt;= 18) Node.js cho frontend development với React + Vite.\nSử dụng nvm (khuyến nghị):\n# Install nvm curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash # Install Node.js 18 nvm install 18 nvm use 18 Verify:\nnode --version # v18.x.x npm --version # 9.x.x 5. Python (\u0026gt;= 3.11) Python cho backend FastAPI application.\nWindows: Download từ python.org (chọn \u0026ldquo;Add to PATH\u0026rdquo;)\nmacOS:\nbrew install python@3.11 Linux:\nsudo apt update sudo apt install python3.11 python3.11-venv python3-pip Verify:\npython --version # Python 3.11.x pip --version 6. Git Git cho version control.\nWindows: Download từ git-scm.com\nmacOS:\nbrew install git Linux:\nsudo apt install git Verify:\ngit --version Clone Repository git clone https://github.com/CrystalJohn/ARC-project.git cd ARC-project Cấu hình AWS Credentials Tạo IAM User Đăng nhập AWS Console Navigate to IAM → Users → Create user User name: arc-workshop-user Attach policies: AmazonEC2FullAccess AmazonS3FullAccess AmazonDynamoDBFullAccess AmazonCognitoPowerUser AmazonSQSFullAccess AmazonTextractFullAccess AmazonBedrockFullAccess CloudWatchFullAccess IAMFullAccess Create access key → Download credentials Configure AWS CLI aws configure Nhập thông tin:\nAWS Access Key ID: AKIAXXXXXXXXXXXXXXXX AWS Secret Access Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default region name: ap-southeast-1 Default output format: json Verify:\naws sts get-caller-identity Kích hoạt Amazon Bedrock Models Request Model Access AWS Console → Amazon Bedrock → Model access Click Manage model access Chọn models: Anthropic - Claude 3.5 Sonnet (anthropic.claude-3-5-sonnet-20241022-v2:0) Cohere - Embed Multilingual v3 (cohere.embed-multilingual-v3) Click Request model access → Accept Terms → Submit Verify Access # Test Claude aws bedrock get-foundation-model \\ --model-identifier anthropic.claude-3-5-sonnet-20241022-v2:0 \\ --region ap-southeast-1 # Test Cohere aws bedrock get-foundation-model \\ --model-identifier cohere.embed-multilingual-v3 \\ --region ap-southeast-1 Expected: Status Access granted\nChuẩn bị Sample Documents Project có sẵn sample PDFs trong samples/:\nls samples/ # data-structures-sample.pdf # test-sample.pdf Yêu cầu documents Limit Value Format PDF (text-based hoặc scanned) Max size 50 MB Max pages 500 pages Recommended 10-100 pages Checklist Trước khi tiếp tục, đảm bảo:\nAWS CLI installed và configured Terraform installed Docker installed và running Node.js 18+ installed Python 3.11+ installed Git installed Repository cloned IAM user created với đủ permissions Bedrock models được approve (Claude + Cohere) Sample documents sẵn sàng "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.3-week3/","title":"Nhật ký Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Hiểu sâu hơn về kiểm soát truy cập với AWS IAM: User, Group, Policy, Role. Biết cách thiết kế mô hình phân quyền an toàn dựa trên IAM Role và nguyên tắc “least privilege”. Thực hành tạo IAM Group, IAM User, IAM Role và kịch bản Switch Role. Nắm các khái niệm mạng cơ bản trong Amazon VPC: Subnet, Route Table, Internet Gateway, NAT Gateway. Thực hành xây dựng VPC, cấu hình Security Group, Network ACL và làm quen với Site-to-Site VPN. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu tổng quan về IAM Access Control + IAM User \u0026amp; IAM Group + IAM Policy + IAM Role - Ôn lại mục tiêu bảo mật và nguyên tắc least privilege 23/09/2025 23/09/2025 https://000002.awsstudygroup.com/ 2 - Thực hành IAM (1): + Tạo Admin IAM Group + Tạo Admin User và thêm vào group + Đăng nhập bằng Admin User và kiểm tra quyền 24/09/2025 24/09/2025 https://000002.awsstudygroup.com/ 3 - Thực hành IAM (2): + Tạo Admin Role + Tạo OperatorUser + Cấu hình trust relationship cho Switch Role + Test Switch Role từ OperatorUser + Rà soát \u0026amp; dọn dẹp cấu hình không cần thiết 25/09/2025 25/09/2025 https://000002.awsstudygroup.com/ 4 - Học lý thuyết về Amazon VPC: + Subnet + Route Table + Internet Gateway + NAT Gateway - So sánh và hiểu vai trò: + Security Group + Network ACL 26/09/2025 26/09/2025 https://000003.awsstudygroup.com/ 5 - Thực hành VPC \u0026amp; Networking: + Tạo VPC, Subnet, Internet Gateway, Route Table, Security Group + Bật VPC Flow Logs + Tạo EC2 trong VPC và test kết nối + Đọc và hiểu các bước cấu hình Site-to-Site VPN 27/09/2025 27/09/2025 https://000003.awsstudygroup.com/ Thành tựu Tuần 3: Hiểu rõ hơn về các thành phần IAM trong kiểm soát truy cập:\nIAM User, IAM Group IAM Policy và cách gán quyền IAM Role và trust relationship Xây dựng được cấu trúc IAM cơ bản cho quản trị:\nTạo Admin Group, Admin User Kiểm tra quyền dựa trên group thay vì gán trực tiếp Thực hành mô hình phân quyền nâng cao:\nTạo Admin Role và OperatorUser Cấu hình và test Switch Role trong Console Áp dụng nguyên tắc least privilege khi phân quyền Nắm được các khái niệm chính của Amazon VPC:\nSubnet, Route Table, Internet Gateway, NAT Gateway Phân biệt Security Group và Network ACL Tự tay xây dựng một môi trường VPC nhỏ:\nTạo VPC, subnet, routing, lớp bảo mật Khởi tạo EC2 trong VPC và kiểm tra kết nối Bật VPC Flow Logs để quan sát traffic Nắm được luồng tổng quát để thiết lập AWS Site-to-Site VPN cho môi trường hybrid.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - FotMob cung cấp cập nhật bóng đá gần như theo thời gian thực cho hàng triệu người dùng nhờ AWS Bài viết mô tả cách FotMob – ứng dụng bóng đá với hơn 17 triệu người dùng trên 500 giải đấu – dùng hạ tầng AWS để cung cấp cập nhật gần thời gian thực cho người hâm mộ. Hệ thống của FotMob phải xử lý khối lượng cực lớn, với hàng tỷ thông báo đẩy mỗi tuần và tới 1,6 triệu HTTP request mỗi giây trong giờ cao điểm. Trước đây họ dùng bên thứ ba cho push notification nhưng không chịu nổi tải, nên đã xây dựng hệ thống thông báo in-house trên AWS, vừa ổn định vừa tiết kiệm hơn 130.000 USD mỗi năm.\nBlog 2 - Thúc đẩy làn sóng khởi nghiệp Generative AI tiếp theo AWS đã công bố cam kết đầu tư 230 triệu USD để thúc đẩy làn sóng startup phát triển ứng dụng Generative AI toàn cầu. Amazon Web Services, Inc. Cùng với đó, họ giới thiệu lại chương trình AWS Generative AI Accelerator — một chương trình 10-tuần (hybrid), hợp tác với NVIDIA, nhằm hỗ trợ các startup tiềm năng: năm nay chương trình mở rộng gấp 4 lần, phục vụ đến 80 startup toàn cầu, mỗi startup được nhận tối đa 1 triệu USD credits AWS để phát triển, mở rộng quy mô và sáng tạo.\nBlog 3 - Cách các climate tech startup xây dựng mô hình nền tảng với Amazon SageMaker HyperPod Climate-tech startups are leveraging Amazon SageMaker HyperPod to build specialized foundation models using large, multimodal environmental datasets từ ảnh vệ tinh, dữ liệu khí hậu, tới số liệu địa chất nhằm giải quyết các vấn đề như thu giữ carbon, thiết kế vật liệu bền vững, dự báo thời tiết \u0026amp; khí hậu cục bộ, bảo tồn hệ sinh thái và lập bản đồ địa chất. HyperPod cung cấp hạ tầng AI mạnh mẽ: tự động provisioning cluster GPU hàng nghìn đơn vị, giám sát, fault-tolerance, checkpointing và autoscaling giúp khối lượng tính toán lớn được xử lý nhanh, ổn định và tiết kiệm chi phí. Nhờ đó các startup như Orbital Materials và Hum.AI đã phát triển thành công mô hình riêng để thiết kế vật liệu carbon-capture và phân tích hệ sinh thái minh chứng rõ ràng rằng HyperPod đang mở rộng khả năng của AI môi trường, biến dữ liệu phức tạp thành giải pháp bền vững.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/3-blogstranslated/3.3-blog3/","title":"Cách các climate tech startup xây dựng mô hình nền tảng với Amazon SageMaker HyperPod","tags":[],"description":"","content":"by Ilan Gleiser, Aman Shanbhag, Ankit Anand, Lisbeth Kaufman, and Rohit Talluri | vào 04 THÁNG 06 2025 | trong Best Practices , Responsible AI, Startup, Sustainability\nCác climate tech startup là những công ty sử dụng công nghệ và đổi mới để đối mặt với khủng hoảng khí hậu, tập trung chủ yếu vào việc giảm phát thải khí nhà kính hoặc giúp xã hội thích ứng với các tác động của biến đổi khí hậu. Sứ mệnh chung của họ là tạo ra các giải pháp có thể mở rộng, đẩy nhanh quá trình chuyển dịch sang một tương lai bền vững với lượng carbon thấp. Nhu cầu về các giải pháp cho khủng hoảng khí hậu ngày càng trở nên cấp thiết khi các thảm họa thời tiết cực đoan do khí hậu thúc đẩy gia tăng trên toàn cầu. Năm 2024, các thảm họa khí hậu gây thiệt hại hơn 417 tỷ USD trên toàn thế giới, và tình hình không hề “giảm nhiệt” trong năm 2025 với cháy rừng ở LA gây thiệt hại hơn 135 tỷ USD chỉ trong tháng đầu tiên của năm. Các climate tech startup đang ở tuyến đầu trong việc xây dựng những giải pháp tạo tác động thực sự lên khủng hoảng khí hậu, và họ đang sử dụng generative AI để xây dựng nhanh nhất có thể.\nTrong bài viết này, chúng tôi trình bày cách các climate tech startup phát triển các foundation model (FMs) dựa trên những bộ dữ liệu môi trường quy mô lớn để giải quyết các bài toán như thu giữ carbon, nhiên liệu âm carbon, thiết kế vật liệu mới để phá hủy vi nhựa, và bảo tồn hệ sinh thái. Các mô hình chuyên biệt này đòi hỏi năng lực tính toán tiên tiến để xử lý và phân tích hiệu quả khối lượng dữ liệu khổng lồ.\nAmazon Web Services (AWS) cung cấp hạ tầng tính toán thiết yếu để hỗ trợ các nỗ lực này, với tài nguyên mạnh mẽ và có khả năng mở rộng thông qua Amazon SageMaker HyperPod. SageMaker HyperPod là một dịch vụ hạ tầng được xây dựng chuyên biệt, tự động quản lý các cụm huấn luyện AI quy mô lớn để nhà phát triển có thể hiệu quả xây dựng và huấn luyện các mô hình phức tạp như large language models (LLMs) bằng cách tự động xử lý việc khởi tạo cụm, giám sát và chịu lỗi trên hàng nghìn GPU. Với SageMaker HyperPod, các startup có thể huấn luyện các mô hình AI phức tạp trên những bộ dữ liệu môi trường đa dạng, bao gồm ảnh vệ tinh và số liệu đo đạc khí quyển, với tốc độ và hiệu suất cao hơn. Nền tảng tính toán này cực kỳ quan trọng đối với các startup đang nỗ lực tạo ra những giải pháp không chỉ mang tính đổi mới mà còn có thể mở rộng và tạo tác động thực sự.\nĐộ phức tạp ngày càng tăng của dữ liệu môi trường đòi hỏi hạ tầng dữ liệu vững chắc và kiến trúc mô hình tinh vi. Việc tích hợp dữ liệu đa phương thức, áp dụng các cơ chế attention chuyên biệt cho dữ liệu không gian–thời gian, và sử dụng reinforcement learning là những yếu tố then chốt để xây dựng các mô hình tập trung vào khí hậu một cách hiệu quả. Cụm GPU được tối ưu hóa và tài nguyên có khả năng mở rộng của SageMaker HyperPod giúp startup tiết kiệm thời gian và chi phí trong khi vẫn đáp ứng các yêu cầu kỹ thuật nâng cao, nghĩa là họ có thể tập trung nhiều hơn cho đổi mới. Khi nhu cầu công nghệ khí hậu tiếp tục tăng, những khả năng này cho phép startup phát triển các giải pháp môi trường mang tính chuyển hóa với Amazon SageMaker HyperPod.\nXu hướng trong các climate tech startup xây dựng với generative AI Các climate tech startup đang áp dụng generative AI để tối ưu hóa vận hành. Ví dụ, các startup như BrainBox AI và Pendulum đã sử dụng Amazon Bedrock và tinh chỉnh các LLM hiện có trên AWS Trainium bằng Amazon SageMaker để tự động nhập tài liệu và trích xuất dữ liệu, qua đó tăng tốc quá trình onboarding khách hàng mới. Đến giữa năm 2023, chúng tôi chứng kiến làn sóng tiếp theo khi các climate tech startup bắt đầu xây dựng các trợ lý thông minh tinh vi bằng cách tinh chỉnh các LLM hiện có cho từng trường hợp sử dụng cụ thể. Chẳng hạn, NET2GRID đã sử dụng Amazon SageMaker để tinh chỉnh và triển khai các LLM quy mô lớn dựa trên Llama 7B nhằm xây dựng EnergyAI, một trợ lý cung cấp phản hồi nhanh chóng và cá nhân hóa cho các câu hỏi liên quan đến năng lượng của khách hàng ngành tiện ích.\nTrong 6 tháng qua, chúng tôi đã chứng kiến làn sóng các climate tech startup xây dựng các FMs để giải quyết những thách thức cụ thể về khí hậu và môi trường. Không giống các mô hình ngôn ngữ thuần túy, các startup này xây dựng mô hình dựa trên dữ liệu thế giới thực như thời tiết hoặc dữ liệu địa không gian của Trái đất. Trong khi các LLM như Claude của Anthropic hay Nova của Amazon có hàng trăm tỷ tham số, các climate tech startup lại xây dựng những mô hình nhỏ hơn, chỉ vài tỷ tham số. Điều này khiến các mô hình đó nhanh hơn và ít tốn chi phí huấn luyện hơn. Chúng tôi đang thấy một số xu hướng nổi bật về các trường hợp sử dụng hoặc thách thức khí hậu mà startup đang giải quyết bằng cách xây dựng FMs. Dưới đây là các use case hàng đầu theo thứ tự phổ biến:\nThời tiết – Được huấn luyện trên dữ liệu thời tiết lịch sử, các mô hình này cung cấp dự báo thời tiết và khí hậu ngắn hạn và dài hạn với độ chính xác cao ở mức siêu cục bộ, một số tập trung vào các yếu tố thời tiết cụ thể như gió, nhiệt hoặc ánh nắng.\nKhám phá vật liệu bền vững – Được huấn luyện trên dữ liệu khoa học, các mô hình này tạo ra những vật liệu bền vững mới nhằm giải quyết các vấn đề chuyên biệt, chẳng hạn như chất hấp thụ trực tiếp CO₂ trong không khí hiệu quả hơn để giảm chi phí loại bỏ carbon, hoặc những phân tử có khả năng phá hủy vi nhựa trong môi trường.\nHệ sinh thái tự nhiên – Được huấn luyện trên tổ hợp dữ liệu từ vệ tinh, lidar và cảm biến mặt đất, các mô hình này mang lại hiểu biết sâu sắc về hệ sinh thái tự nhiên, đa dạng sinh học và dự đoán cháy rừng.\nMô hình địa chất – Được huấn luyện trên dữ liệu địa chất, các mô hình này giúp xác định vị trí tối ưu cho các hoạt động địa nhiệt hoặc khai thác mỏ nhằm giảm lãng phí và tiết kiệm chi phí.\nĐể hiểu rõ hơn về các xu hướng này, những phần tiếp theo sẽ phân tích sâu cách các climate startup đang xây dựng foundation model trên AWS.\nOrbital Materials: Foundation models cho khám phá vật liệu bền vững Orbital Materials đã xây dựng một nền tảng AI độc quyền để thiết kế, tổng hợp và kiểm thử các vật liệu bền vững mới. Việc phát triển vật liệu tiên tiến truyền thống vốn là một quy trình chậm chạp dựa trên thử–sai trong phòng thí nghiệm. Orbital thay thế cách làm này bằng thiết kế dựa trên generative AI, tăng tốc mạnh mẽ quá trình khám phá vật liệu và thương mại hóa công nghệ mới. Họ đã phát triển một mô hình generative AI có tên “Orb”, mô hình này đề xuất các thiết kế vật liệu mới, sau đó đội ngũ sẽ kiểm chứng và hoàn thiện trong phòng lab.\nOrb là một diffusion model mà Orbital Materials đã huấn luyện từ đầu bằng SageMaker HyperPod. Sản phẩm đầu tiên mà startup thiết kế với Orb là vật liệu hấp thụ dùng cho thu giữ carbon tại các cơ sở thu giữ trực tiếp từ không khí. Kể từ khi thành lập phòng thí nghiệm vào quý đầu năm 2024, Orbital đã đạt được mức cải thiện hiệu suất vật liệu gấp 10 lần nhờ nền tảng AI của họ—nhanh hơn một bậc so với cách phát triển truyền thống và mở ra những giới hạn mới về hiệu quả loại bỏ carbon. Bằng cách cải thiện hiệu suất vật liệu, công ty có thể giúp giảm chi phí loại bỏ carbon, qua đó mở ra khả năng mở rộng nhanh chóng. Họ chọn sử dụng SageMaker HyperPod vì “thích mô hình một điểm đến (one-stop shop) cho cả kiểm soát và giám sát,” theo lời giải thích của Jonathan Godwin, CEO Orbital Materials. Orbital đã có thể giảm tổng chi phí sở hữu (TCO) cho cụm GPU của mình nhờ các deep health check của Amazon SageMaker HyperPod để kiểm tra sức chịu tải của các instance GPU và thay thế các node bị lỗi. Bên cạnh đó, Orbital có thể sử dụng SageMaker HyperPod để tự động thay thế các node gặp sự cố và khởi động lại việc huấn luyện mô hình từ checkpoint được lưu gần nhất, giúp tiết kiệm thời gian cho đội ngũ Orbital Materials. Tác nhân giám sát (monitoring agent) của SageMaker HyperPod liên tục theo dõi và phát hiện các vấn đề tiềm ẩn, bao gồm hết bộ nhớ, lỗi đĩa, bất thường GPU, deadlock kernel, lỗi container runtime và crash do out-of-memory (OOM). Tùy vào nguyên nhân, tác nhân giám sát sẽ thay thế hoặc khởi động lại node.\nVới việc ra mắt SageMaker HyperPod trên Amazon Elastic Kubernetes Service (Amazon EKS), Orbital có thể thiết lập một mặt phẳng điều khiển thống nhất bao gồm cả workload dựa trên CPU và các tác vụ tăng tốc bằng GPU trong cùng một cụm Kubernetes. Cách tiếp cận kiến trúc này loại bỏ sự phức tạp truyền thống khi phải quản lý các cụm riêng biệt cho từng loại tài nguyên tính toán khác nhau, qua đó giảm đáng kể chi phí vận hành. Orbital cũng có thể giám sát trạng thái sức khỏe của các node SageMaker HyperPod thông qua Amazon CloudWatch Container Insights với enhanced observability cho Amazon EKS. Amazon CloudWatch Container Insights thu thập, tổng hợp và tóm tắt các metric và log từ các ứng dụng dạng container và microservices, cung cấp cái nhìn chi tiết về hiệu năng, sức khỏe và trạng thái cho CPU, GPU, Trainium hoặc Elastic Fabric Adapter (EFA) và hệ thống file đến tận cấp độ container.\nAWS và Orbital Materials đã thiết lập một quan hệ đối tác sâu rộng cho phép tạo “fly-wheel” tăng trưởng. Hai bên đã ký kết một thỏa thuận hợp tác nhiều năm, trong đó Orbital Materials xây dựng các FMs của mình với SageMaker HyperPod và các dịch vụ AWS khác. Đổi lại, Orbital Materials sử dụng AI để phát triển các công nghệ khử carbon và nâng cao hiệu quả cho trung tâm dữ liệu. Để tiếp tục quay “bánh đà”, Orbital sẽ đưa Orb—mô hình AI mã nguồn mở dẫn đầu thị trường cho mô phỏng vật liệu tiên tiến—ra mắt rộng rãi cho khách hàng AWS thông qua Amazon SageMaker JumpStart và AWS Marketplace. Đây là mô hình AI dành cho vật liệu đầu tiên xuất hiện trên các nền tảng AWS. Với Orb, các khách hàng AWS đang làm việc với vật liệu và công nghệ tiên tiến như bán dẫn, pin và điện tử có thể truy cập năng lực R\u0026amp;D tăng tốc hàng đầu trên một môi trường đám mây bảo mật và thống nhất.\nLợi thế kiến trúc của SageMaker HyperPod trên Amazon EKS được minh họa trong sơ đồ sau. Sơ đồ cho thấy Orbital có thể thiết lập một mặt phẳng điều khiển thống nhất để quản lý cả workload dựa trên CPU và các tác vụ tăng tốc bằng GPU trong một cụm Kubernetes duy nhất. Kiến trúc hợp lý này loại bỏ sự phức tạp truyền thống của việc quản lý các cụm riêng biệt cho từng loại tài nguyên tính toán, mang lại một mô hình quản lý tài nguyên tích hợp và hiệu quả hơn. Hình minh họa cho thấy cách hạ tầng hợp nhất này cho phép Orbital điều phối mượt mà các nhu cầu tính toán đa dạng thông qua một giao diện điều khiển duy nhất.\nHum.AI: Foundation models cho quan sát Trái đất Hum.AI đang xây dựng các generative AI FMs nhằm cung cấp trí tuệ tổng quát về thế giới tự nhiên. Khách hàng có thể sử dụng nền tảng này để theo dõi và dự đoán hệ sinh thái cũng như đa dạng sinh học nhằm hiểu rõ tác động kinh doanh và bảo vệ môi trường tốt hơn. Ví dụ, họ làm việc với các cộng đồng ven biển, những nơi sử dụng nền tảng và insight để phục hồi hệ sinh thái ven biển và cải thiện đa dạng sinh học.\nFoundation model của Hum.AI khai thác dữ liệu về thế giới tự nhiên và học cách biểu diễn dữ liệu đó một cách trực quan. Họ đang huấn luyện trên 50 năm dữ liệu lịch sử do vệ tinh thu thập, với khối lượng lên tới hàng nghìn petabyte. Để xử lý khối dữ liệu khổng lồ này, họ đã chọn SageMaker HyperPod vì hạ tầng có khả năng mở rộng. Nhờ kiến trúc mô hình sáng tạo, công ty đã lần đầu tiên đạt được khả năng “nhìn xuyên mặt nước từ không gian”, vượt qua những thách thức vốn có do hiện tượng phản chiếu ánh sáng trên mặt nước.\nKiến trúc FM của Hum.AI sử dụng thiết kế lai giữa variational autoencoder (VAE) và generative adversarial network (GAN), được tối ưu hóa đặc biệt cho phân tích ảnh vệ tinh. Đây là mô hình encoder–decoder, trong đó encoder chuyển đổi dữ liệu vệ tinh vào không gian tiềm ẩn (latent space) đã học, trong khi decoder tái tạo lại hình ảnh (sau khi được xử lý trong không gian tiềm ẩn) và duy trì sự nhất quán giữa các nguồn vệ tinh khác nhau. Mạng discriminator cung cấp cả tín hiệu huấn luyện đối kháng và các metric tái tạo dựa trên đặc trưng đã học. Cách tiếp cận này giúp bảo toàn các chi tiết hệ sinh thái quan trọng vốn dễ bị mất đi với các phương pháp so sánh pixel truyền thống, đặc biệt trong môi trường dưới nước nơi phản chiếu mặt nước thường làm suy giảm khả năng quan sát.\nViệc sử dụng SageMaker HyperPod để huấn luyện một mô hình phức tạp như vậy cho phép Hum.AI xử lý hiệu quả bộ dữ liệu SeeFar được họ tự xây dựng thông qua huấn luyện phân tán trên nhiều instance GPU. Mô hình đồng thời tối ưu cả mục tiêu VAE lẫn GAN trên nhiều GPU. Kết hợp với tính năng auto-resume của SageMaker HyperPod, hệ thống có thể tự động tiếp tục một phiên huấn luyện từ checkpoint mới nhất, đảm bảo tính liên tục cho quá trình huấn luyện ngay cả khi node gặp sự cố.\nHum.AI cũng sử dụng các tính năng quan sát toàn diện “out-of-the-box” của SageMaker HyperPod thông qua Amazon Managed Service for Prometheus và Amazon Managed Service for Grafana để theo dõi các metric. Đối với nhu cầu huấn luyện phân tán, họ dùng dashboard để giám sát hiệu năng cụm, metric GPU, lưu lượng mạng và hoạt động lưu trữ. Hạ tầng giám sát toàn diện này cho phép Hum.AI tối ưu hóa quy trình huấn luyện và duy trì mức sử dụng tài nguyên cao trong suốt vòng đời phát triển mô hình.\n\u0026ldquo;Quyết định sử dụng SageMaker HyperPod của chúng tôi rất đơn giản; đây là dịch vụ duy nhất ngoài kia cho phép bạn tiếp tục huấn luyện ngay cả khi có lỗi xảy ra. Chúng tôi có thể huấn luyện các mô hình lớn nhanh hơn bằng cách tận dụng các cụm quy mô lớn và khả năng dự phòng (redundancy) mà SageMaker HyperPod cung cấp. Chúng tôi có thể thực thi các thí nghiệm nhanh hơn và lặp mô hình ở tốc độ mà trước đây là bất khả thi. SageMaker HyperPod đã loại bỏ hoàn toàn nỗi lo về những thất bại trong huấn luyện quy mô lớn. Họ đã xây dựng hạ tầng để có thể hot swap GPU nếu có sự cố, giúp tiết kiệm hàng nghìn giờ tiến trình bị mất giữa các checkpoint. Đội ngũ SageMaker HyperPod đã trực tiếp hỗ trợ chúng tôi thiết lập và vận hành các phiên huấn luyện lớn một cách nhanh chóng và dễ dàng.\u0026rdquo;\n— Kelly Zheng, CEO Hum.AI\nCách tiếp cận sáng tạo của Hum.AI đối với việc huấn luyện mô hình được minh họa trong hình dưới đây. Sơ đồ cho thấy mô hình của họ đồng thời tối ưu cả mục tiêu VAE và GAN trên nhiều GPU như thế nào. Chiến lược huấn luyện phân tán này được bổ sung bởi tính năng auto-resume của SageMaker HyperPod, tính năng này tự động khởi động lại các phiên huấn luyện từ checkpoint mới nhất. Kết hợp lại, những khả năng này mang đến quá trình huấn luyện liên tục và hiệu quả, ngay cả trong trường hợp có lỗi node. Hình ảnh cung cấp cái nhìn trực quan về quy trình huấn luyện bền vững này, nhấn mạnh sự tích hợp mượt mà giữa kiến trúc mô hình của Hum.AI và hạ tầng hỗ trợ của SageMaker HyperPod.\nCách tiết kiệm thời gian và chi phí khi xây dựng với Amazon SageMaker HyperPod Amazon SageMaker HyperPod loại bỏ phần “nặng nhọc nhưng không tạo khác biệt” (undifferentiated heavy lifting) cho các climate tech startup khi xây dựng FMs, giúp họ tiết kiệm thời gian và chi phí. Để biết thêm chi tiết về cách khả năng chịu lỗi (resiliency) của SageMaker HyperPod giúp giảm chi phí trong quá trình huấn luyện, hãy xem Reduce ML training costs with Amazon SageMaker HyperPod.\nỞ lõi, HyperPod cung cấp khả năng kiểm soát hạ tầng sâu, được tối ưu để xử lý các bộ dữ liệu môi trường phức tạp, với quyền truy cập bảo mật vào các instance Amazon Elastic Compute Cloud (Amazon EC2) và tích hợp liền mạch với các công cụ điều phối như Slurm và Amazon EKS. Hạ tầng này đặc biệt mạnh trong việc xử lý các đầu vào môi trường đa phương thức, từ ảnh vệ tinh đến dữ liệu mạng cảm biến, thông qua huấn luyện phân tán trên hàng nghìn bộ tăng tốc (accelerators).\nKhả năng quản lý tài nguyên thông minh của SageMaker HyperPod đặc biệt hữu ích cho mô hình khí hậu, nhờ khả năng tự động điều phối độ ưu tiên tác vụ và phân bổ tài nguyên, đồng thời giảm chi phí vận hành lên đến 40%. Điều này rất quan trọng đối với các climate tech startup đang xử lý khối lượng dữ liệu môi trường khổng lồ, vì hệ thống vừa duy trì tiến độ thông qua checkpointing, vừa đảm bảo rằng các workload mô hình khí hậu quan trọng luôn được cấp đủ tài nguyên cần thiết.\nĐối với các nhà đổi mới công nghệ khí hậu, thư viện SageMaker HyperPod với hơn 30 training recipes được chọn lọc giúp tăng tốc phát triển, cho phép các đội ngũ bắt đầu huấn luyện mô hình môi trường chỉ trong vài phút thay vì vài tuần. Nền tảng này tích hợp với Amazon EKS, cung cấp khả năng chịu lỗi mạnh mẽ và tính sẵn sàng cao—những yếu tố thiết yếu để duy trì liên tục các tác vụ giám sát và phân tích môi trường.\nCác kế hoạch huấn luyện linh hoạt của SageMaker HyperPod đặc biệt có lợi cho những dự án công nghệ khí hậu, cho phép tổ chức chỉ định thời hạn hoàn thành và yêu cầu tài nguyên, đồng thời tự động tối ưu năng lực xử lý cho các workload dữ liệu môi trường phức tạp. Khả năng gợi ý các phương án thay thế giúp tối ưu hóa việc sử dụng tài nguyên cho các tác vụ mô hình khí hậu có cường độ tính toán cao. Với sự hỗ trợ của các bộ tăng tốc AI thế hệ mới như chip AWS Trainium và bộ công cụ giám sát toàn diện, SageMaker HyperPod mang đến cho các climate tech startup một nền tảng bền vững và hiệu quả để phát triển các giải pháp môi trường tinh vi. Hạ tầng này cho phép các tổ chức tập trung vào sứ mệnh cốt lõi là giải quyết các thách thức khí hậu, đồng thời duy trì hiệu quả vận hành và trách nhiệm môi trường.\nThực hành cho điện toán bền vững Các công ty công nghệ khí hậu đặc biệt ý thức về tầm quan trọng của những thực hành điện toán bền vững. Một cách tiếp cận then chốt là giám sát cẩn trọng và tối ưu hóa mức tiêu thụ năng lượng trong suốt các quy trình tính toán. Bằng việc áp dụng các chiến lược huấn luyện hiệu quả—chẳng hạn giảm số vòng huấn luyện không cần thiết và sử dụng các thuật toán tiết kiệm năng lượng—các startup có thể giảm đáng kể lượng khí thải carbon.\nBên cạnh đó, tích hợp các nguồn năng lượng tái tạo để vận hành trung tâm dữ liệu cũng đóng vai trò quan trọng trong việc giảm thiểu tác động môi trường. AWS quyết tâm biến đám mây trở thành cách thức sạch nhất và hiệu quả năng lượng nhất để vận hành hạ tầng và hoạt động kinh doanh của khách hàng. Trong nhiều năm qua, chúng tôi đã đạt được những bước tiến rõ rệt. Ví dụ, Amazon là doanh nghiệp mua năng lượng tái tạo lớn nhất thế giới mỗi năm kể từ 2020. Chúng tôi đã đạt mục tiêu năng lượng tái tạo là “match” toàn bộ lượng điện tiêu thụ trên toàn bộ hoạt động—bao gồm cả trung tâm dữ liệu—bằng 100% năng lượng tái tạo, và chúng tôi hoàn thành mục tiêu này sớm hơn 7 năm so với mốc 2030 đã đề ra ban đầu.\nCác công ty cũng đang áp dụng nguyên tắc điện toán theo dõi carbon (carbon-aware computing), nghĩa là sắp xếp các tác vụ tính toán trùng với những khoảng thời gian mà cường độ carbon của lưới điện thấp. Cách làm này giúp năng lượng dùng cho tính toán có dấu chân môi trường nhỏ hơn. Việc triển khai những chiến lược như vậy không chỉ phù hợp với các mục tiêu phát triển bền vững rộng hơn mà còn thúc đẩy hiệu quả chi phí và bảo tồn tài nguyên. Khi nhu cầu về năng lực tính toán tiên tiến ngày càng tăng, các climate tech startup đang thể hiện cam kết mạnh mẽ với thực hành bền vững, bảo đảm rằng đổi mới của họ vừa thúc đẩy tiến bộ công nghệ, vừa đóng góp tích cực cho việc bảo vệ môi trường.\nKết luận Amazon SageMaker HyperPod đang nổi lên như một công cụ then chốt cho các climate tech startup trong hành trình phát triển các giải pháp sáng tạo nhằm giải quyết những thách thức môi trường cấp bách. Bằng cách cung cấp hạ tầng có khả năng mở rộng, hiệu quả và tiết kiệm chi phí để huấn luyện các kiến trúc mô hình đa phương thức và đa mô hình phức tạp, SageMaker HyperPod cho phép các công ty này xử lý khối lượng dữ liệu môi trường khổng lồ và xây dựng những mô hình dự đoán tinh vi. Từ nỗ lực khám phá vật liệu bền vững của Orbital Materials đến khả năng quan sát Trái đất tiên tiến của Hum.AI, SageMaker HyperPod đang hỗ trợ những bước đột phá mà trước đây khó có thể đạt được. Khi biến đổi khí hậu tiếp tục đặt ra các thách thức cấp bách trên toàn cầu, khả năng tự động quản lý các cụm huấn luyện AI quy mô lớn của SageMaker HyperPod, cùng với các tính năng chịu lỗi và tối ưu chi phí, cho phép những nhà đổi mới công nghệ khí hậu tập trung vào sứ mệnh cốt lõi thay vì lo lắng về hạ tầng. Bằng việc sử dụng SageMaker HyperPod, các climate tech startup không chỉ xây dựng được những mô hình hiệu quả hơn mà còn đang tăng tốc phát triển những công cụ mạnh mẽ mới, đóng góp vào nỗ lực chung trong việc giải quyết khủng hoảng khí hậu toàn cầu.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.3-bedrock-models/","title":"Kích hoạt Bedrock Models","tags":[],"description":"","content":"Trước khi triển khai giải pháp, bạn cần kích hoạt các mô hình Amazon Bedrock cần thiết trong tài khoản AWS của mình.\nCác bước Kích hoạt Mô hình Tìm kiếm Amazon Bedrock trong AWS Console Truy cập Model catalog từ menu điều hướng bên trái Chọn tên mô hình tương ứng: Anthropic Claude 3.5 Sonnet Anthropic Claude 3 Sonnet Anthropic Claude 3 Haiku Cohere - Embed Multilingual v3 Chọn \u0026ldquo;Open in playground\u0026rdquo; và gửi một tin nhắn thử nghiệm để kích hoạt từng mô hình Lưu ý: Đảm bảo bạn kích hoạt tất cả bốn mô hình trong khu vực ap-southeast-1 (Singapore) vì giải pháp được triển khai trong khu vực này.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.4-week4/","title":"Nhật ký Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Hiểu cách khởi tạo và quản lý EC2 Windows và Linux. Thực hành triển khai ứng dụng trên EC2 (Node.js \u0026amp; AWS User Management App). Hiểu IAM governance và quản lý chi phí EC2 thông qua IAM. Hiểu cách ứng dụng truy cập dịch vụ AWS qua IAM Role thay cho Access Key. Thực hành gán IAM Role cho EC2 và kiểm tra quyền truy cập của ứng dụng. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu giới thiệu EC2 \u0026amp; bước chuẩn bị + Khái niệm EC2 + Các tài nguyên cần thiết + Yêu cầu IAM \u0026amp; networking 30/09/2025 30/09/2025 https://000004.awsstudygroup.com/ 2 - Khởi tạo EC2: + Tạo Windows Server 2022 instance + Tạo Amazon Linux instance + Kết nối và kiểm tra truy cập 01/10/2025 01/10/2025 https://000004.awsstudygroup.com/ 3 - Triển khai ứng dụng: + Triển khai AWS User Management App trên Amazon Linux 2 + Triển khai Node.js App trên Windows EC2 02/10/2025 02/10/2025 https://000004.awsstudygroup.com/ 4 - IAM Governance \u0026amp; Authorization: + Hiểu governance chi phí \u0026amp; sử dụng với IAM + So sánh Access Key vs IAM Role + Rủi ro của việc dùng Access Key lâu dài 03/10/2025 03/10/2025 https://000048.awsstudygroup.com/ 5 - Thực hành IAM Role cho EC2: + Tạo IAM Role cho EC2 + Gán Role vào EC2 instance + Kiểm tra ứng dụng truy cập AWS qua Role + Clean up resource sau bài học 04/10/2025 04/10/2025 https://000048.awsstudygroup.com/ Thành tựu Tuần 4: Khởi tạo thành công EC2 Windows và Linux. Hiểu cách chuẩn bị môi trường EC2 để triển khai ứng dụng. Triển khai thành công 2 ứng dụng: AWS User Management App (Linux) Node.js App (Windows) Hiểu rõ IAM governance \u0026amp; ảnh hưởng của IAM tới chi phí và bảo mật. Nắm được lý do không nên dùng Access Key cho ứng dụng. Tạo và gán IAM Role cho EC2, giúp ứng dụng truy cập AWS service an toàn. Kiểm tra thành công quyền truy cập dựa trên IAM Role. Dọn dẹp tài nguyên để tránh phát sinh chi phí. "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Event 1 Tên sự kiện: AWS Cloud Mastery Series #1 workshop (AI/ML/GenAI)\nThời gian: 15/11/2025\nĐịa điểm: Bitexco Financial Tower, 26th Floor, 2 Hải Triều, Quận 1, TP.HCM\nVai trò trong sự kiện: Người tham dự\nNội dung chính: Amazon SageMaker, Generative AI with Amazon Bedrock, Bedrock Agents, MLOps, CI/CD workflow for containers\nEvent 2 Tên sự kiện: AWS Cloud Mastery Series #2 workshop (DevOps)\nThời gian: 17/11/2025\nĐịa điểm: Bitexco Financial Tower, 26th Floor, 2 Hải Triều, Quận 1, TP.HCM\nVai trò trong sự kiện: Người tham dự\nNội dung chính: Tư duy DevOps hiện đại, CI/CD Pipeline, Infrastructure as Code (IaC), Container Services (ECS/EKS/App Runner), Monitoring \u0026amp; Observability\nEvent 3 Tên sự kiện: AWS Cloud Mastery Series #3 workshop (Security Pillar)\nThời gian: 29/11/2025\nĐịa điểm: Bitexco Financial Tower, 26th Floor, 2 Hải Triều, Quận 1, TP.HCM\nVai trò trong sự kiện: Người tham dự\nNội dung chính: AWS Well-Architected Framework – Security Pillar, IAM, Detection \u0026amp; Monitoring, Infrastructure Protection, Data Protection, Incident Response\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.4-aws-cli/","title":"Cấu hình AWS CLI","tags":[],"description":"","content":"Cấu hình AWS CLI Để triển khai và quản lý giải pháp, bạn cần cấu hình AWS Command Line Interface (AWS CLI) với thông tin xác thực của mình.\nCác bước Bước 1: Kiểm tra AWS CLI đã cài đặt aws --version Nếu chưa có, cài đặt:\n# Download và cài đặt MSI installer msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi Bước 2: Tạo IAM User (nếu chưa có) Đăng nhập AWS Console Tìm kiếm \u0026ldquo;IAM\u0026rdquo; → Click IAM Sidebar trái → Users → Create user User name: arc-workshop-user Click Next Attach policies directly, chọn các policies: AmazonEC2FullAccess AmazonS3FullAccess AmazonDynamoDBFullAccess AmazonCognitoPowerUser AmazonSQSFullAccess AmazonTextractFullAccess AmazonBedrockFullAccess CloudWatchFullAccess IAMFullAccess Click Create user Bước 3: Tạo Access Key Vào user vừa tạo → Tab Security credentials Scroll xuống Access keys → Click Create access key Chọn Command Line Interface (CLI) Tick \u0026ldquo;I understand\u0026hellip;\u0026rdquo; → Next Description: ARC Workshop CLI Click Create access key ⚠️ QUAN TRỌNG: Copy hoặc download .csv file\nAccess key ID: AKIAXXXXXXXXXXXXXXXX Secret access key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Bước 4: Configure AWS CLI Mở PowerShell và chạy:\naws configure Nhập thông tin:\nAWS Access Key ID [None]: AKIAXXXXXXXXXXXXXXXX AWS Secret Access Key [None]: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default region name [None]: ap-southeast-1 Default output format [None]: json Bước 5: Verify Configuration Kiểm tra identity:\naws sts get-caller-identity Output mong đợi:\n{ \u0026#34;UserId\u0026#34;: \u0026#34;AIDAXXXXXXXXXXXXXXXXX\u0026#34;, \u0026#34;Account\u0026#34;: \u0026#34;123456789012\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::123456789012:user/arc-workshop-user\u0026#34; } "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.5-week5/","title":"Nhật ký Tuần 5","tags":[],"description":"","content":"Mục tiêu Tuần 5: Tìm hiểu cách tạo và sử dụng môi trường phát triển AWS Cloud9. Thực hành các tính năng của Cloud9 IDE và sử dụng AWS CLI ngay trong Cloud9. Hiểu các khái niệm quan trọng của Amazon S3 và cách host website tĩnh trên S3. Cấu hình bảo mật cho S3: Public Access Block và quyền truy cập đối tượng. Thực hành các tính năng nâng cao của S3: Versioning, Move Objects, Cross-Region Replication. Tích hợp S3 với CloudFront để tăng tốc độ phân phối nội dung. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Giới thiệu về AWS Cloud9 + Tạo Cloud9 instance + Khám phá giao diện và các tính năng của IDE 06/10/2025 06/10/2025 https://000049.awsstudygroup.com/ 2 - Thực hành Cloud9: + Sử dụng terminal \u0026amp; editor + Chạy AWS CLI trong Cloud9 + Thực hành các lệnh CLI cơ bản 07/10/2025 07/10/2025 https://000049.awsstudygroup.com/ 3 - Bắt đầu workshop Amazon S3: + Tìm hiểu S3 fundamentals + Bật Static Website Hosting + Cấu hình Public Access Block \u0026amp; phân quyền public object 08/10/2025 08/10/2025 https://000057.awsstudygroup.com/ 4 - Kiểm tra website tĩnh trên S3 + Tích hợp CloudFront để tăng tốc độ + Bật Versioning + Di chuyển object trong S3 09/10/2025 09/10/2025 https://000057.awsstudygroup.com/ 5 - Cấu hình S3 Cross-Region Replication (CRR) + Điều kiện \u0026amp; yêu cầu IAM + Thiết lập replication rule - Dọn dẹp toàn bộ tài nguyên S3 và Cloud9 10/10/2025 10/10/2025 https://000057.awsstudygroup.com/ Thành tựu Tuần 5: Tạo và sử dụng thành công môi trường Cloud9. Nắm được các thao tác cơ bản của Cloud9 IDE và chạy AWS CLI trong IDE. Hiểu cách host website tĩnh trên S3 và cấu hình quyền truy cập công khai. Kiểm tra hoạt động website và sử dụng CloudFront để tăng tốc phân phối. Thực hiện Versioning và di chuyển object trong bucket. Cấu hình Cross-Region Replication và hiểu ứng dụng thực tế. Dọn dẹp toàn bộ tài nguyên để tránh phát sinh chi phí không cần thiết. "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.5-data-preparation/","title":"Chuẩn bị Dữ liệu","tags":[],"description":"","content":"Chuẩn bị Dữ liệu Trước khi tạo AWS resources, bạn cần tải xuống tập dữ liệu mẫu để test hệ thống.\nBước 1: Tải Xuống Tập Dữ liệu Truy cập ARC Sample Data Tải dữ liệu về máy tính của bạn Giải nén file, sẽ tạo ra một thư mục có tên DATA Yêu cầu Documents Limit Value Format PDF (text-based hoặc scanned) Max size 50 MB Max pages 500 pages Recommended 10-100 pages Chuẩn bị AWS Resources Bước 2: Tạo S3 Bucket S3 Bucket dùng để lưu trữ documents PDF được upload.\nTìm kiếm S3 trong AWS Console Click Create bucket Cấu hình bucket: Bucket name: arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; (thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn) AWS Region: Asia Pacific (Singapore) ap-southeast-1 Giữ các settings khác mặc định Click Create bucket 💡 Tip: Để lấy AWS Account ID, chạy:\naws sts get-caller-identity --query Account --output text Hoặc tạo bằng CLI:\naws s3 mb s3://arc-documents-$(aws sts get-caller-identity --query Account --output text) --region ap-southeast-1 Bước 3: Tạo DynamoDB Table DynamoDB Table dùng để lưu metadata của documents.\nTìm kiếm DynamoDB trong AWS Console Click Create table Cấu hình table: Table name: arc-documents Partition key: doc_id (String) Sort key: sk (String) Table settings: Default settings Click Create table Hoặc tạo bằng CLI:\naws dynamodb create-table \\ --table-name arc-documents \\ --attribute-definitions \\ AttributeName=doc_id,AttributeType=S \\ AttributeName=sk,AttributeType=S \\ --key-schema \\ AttributeName=doc_id,KeyType=HASH \\ AttributeName=sk,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --region ap-southeast-1 Bước 4: Tạo SQS Queue SQS Queue dùng cho IDP pipeline xử lý documents.\nTìm kiếm SQS trong AWS Console Click Create queue Cấu hình queue: Type: Standard Name: arc-document-queue Giữ các settings khác mặc định Click Create queue Hoặc tạo bằng CLI:\naws sqs create-queue --queue-name arc-document-queue --region ap-southeast-1 Bước 5: Verify Resources Kiểm tra tất cả resources đã được tạo:\n# S3 Bucket aws s3 ls | grep arc-documents # DynamoDB Table aws dynamodb describe-table --table-name arc-documents --region ap-southeast-1 --query \u0026#34;Table.TableName\u0026#34; # SQS Queue aws sqs get-queue-url --queue-name arc-document-queue --region ap-southeast-1 Bước 6: Upload Dữ liệu lên S3 Upload các file PDF từ thư mục DATA đã tải về ở Bước 1:\n# Upload tất cả files từ thư mục DATA aws s3 cp DATA/ s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ --recursive # Hoặc upload từng file aws s3 cp DATA/sample-document.pdf s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ 💡 Tip: Thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn\nVerify upload:\naws s3 ls s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ Checklist Trước khi tiếp tục, đảm bảo:\nAWS CLI installed và configured Terraform installed Docker installed và running Node.js 18+ installed Python 3.11+ installed Git installed Repository cloned IAM user created với đủ permissions Bedrock models được approve (Claude + Cohere) S3 Bucket created DynamoDB Table created SQS Queue created Sample documents uploaded to S3 Cấu hình bucket: Bucket name: arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt; (thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn) AWS Region: Asia Pacific (Singapore) ap-southeast-1 Giữ các settings khác mặc định Click Create bucket 💡 Tip: Để lấy AWS Account ID, chạy: aws sts get-caller-identity --query Account --output text\nHoặc tạo bằng CLI:\naws s3 mb s3://arc-documents-$(aws sts get-caller-identity --query Account --output text) --region ap-southeast-1 Bước 3: Tạo DynamoDB Table DynamoDB Table dùng để lưu metadata của documents.\nTìm kiếm DynamoDB trong AWS Console Click Create table Cấu hình table: Table name: arc-documents Partition key: doc_id (String) Sort key: sk (String) Table settings: Default settings Click Create table Hoặc tạo bằng CLI:\naws dynamodb create-table \\ --table-name arc-documents \\ --attribute-definitions \\ AttributeName=doc_id,AttributeType=S \\ AttributeName=sk,AttributeType=S \\ --key-schema \\ AttributeName=doc_id,KeyType=HASH \\ AttributeName=sk,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --region ap-southeast-1 Bước 4: Tạo SQS Queue SQS Queue dùng cho IDP pipeline xử lý documents.\nTìm kiếm SQS trong AWS Console Click Create queue Cấu hình queue: Type: Standard Name: arc-document-queue Giữ các settings khác mặc định Click Create queue Hoặc tạo bằng CLI:\naws sqs create-queue --queue-name arc-document-queue --region ap-southeast-1 Bước 5: Verify Resources Kiểm tra tất cả resources đã được tạo:\n# S3 Bucket aws s3 ls | grep arc-documents # DynamoDB Table aws dynamodb describe-table --table-name arc-documents --region ap-southeast-1 --query \u0026#34;Table.TableName\u0026#34; # SQS Queue aws sqs get-queue-url --queue-name arc-document-queue --region ap-southeast-1 Bước 6: Upload Dữ liệu lên S3 Upload các file PDF từ thư mục DATA đã tải về ở Bước 1:\n# Upload tất cả files từ thư mục DATA aws s3 cp DATA/ s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ --recursive # Hoặc upload từng file aws s3 cp DATA/sample-document.pdf s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ 💡 Tip: Thay \u0026lt;YOUR-ACCOUNT-ID\u0026gt; bằng AWS Account ID của bạn\nVerify upload:\naws s3 ls s3://arc-documents-\u0026lt;YOUR-ACCOUNT-ID\u0026gt;/uploads/ Checklist Trước khi tiếp tục, đảm bảo:\nAWS CLI installed và configured Terraform installed Docker installed và running Node.js 18+ installed Python 3.11+ installed Git installed Repository cloned IAM user created với đủ permissions Bedrock models được approve (Claude + Cohere) Sample documents sẵn sàng "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Tổng quan Trong workshop này, chúng ta sẽ xây dựng ARC (Academic Research Chatbot) - một hệ thống chatbot thông minh hoạt động trên nền tảng AWS Serverless. Giải pháp này ứng dụng Generative AI và RAG (Retrieval-Augmented Generation) để hỗ trợ nghiên cứu học thuật, truy vấn tài liệu và trả lời câu hỏi một cách linh hoạt.\nThay vì trả lời các câu hỏi dựa trên kịch bản cố định (rule-based), hệ thống sử dụng mô hình Claude 3.5 Sonnet để hiểu ngôn ngữ tự nhiên, truy vấn dữ liệu từ cơ sở vector database và phản hồi người dùng một cách chính xác.\nMục tiêu Workshop Sau khi hoàn thành workshop, bạn sẽ:\nHiểu kiến trúc RAG và cách áp dụng vào thực tế Triển khai hệ thống chatbot hoàn chỉnh trên AWS Sử dụng Amazon Bedrock (Claude 3.5 Sonnet + Cohere Embed) Xây dựng IDP pipeline với Amazon Textract Implement vector search với Qdrant Deploy infrastructure với Terraform Tích hợp authentication với Amazon Cognito Nội dung Giới thiệu Các bước chuẩn bị Kích hoạt Bedrock Models Cấu hình AWS CLI Chuẩn bị Dữ liệu Triển khai Infrastructure Thiết lập Backend API Thiết lập IDP Pipeline Thiết lập Frontend Sử dụng Chatbot Sử dụng Admin Dashboard Dọn dẹp Tài nguyên "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.6-week6/","title":"Nhật ký Tuần 6","tags":[],"description":"","content":"Mục tiêu Tuần 6: Tìm hiểu cách triển khai và quản lý Amazon RDS MySQL trong kiến trúc VPC bảo mật. Hiểu kết nối giữa EC2 (public subnet) và RDS (private subnet). Triển khai ứng dụng tương tác với RDS và thực hành backup/restore. Tìm hiểu cách triển khai ứng dụng trên Amazon Lightsail. Thực hành tối ưu chi phí thông qua snapshot, scale-up, alarm và cleanup. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu tổng quan Amazon RDS \u0026amp; yêu cầu chuẩn bị + Các engine hỗ trợ + Thiết kế VPC cho RDS (EC2 public → RDS private) 13/10/2025 13/10/2025 https://000005.awsstudygroup.com/ 2 - Thực hành RDS: + Tạo EC2 trong public subnet + Tạo RDS MySQL trong private subnet + Cấu hình security group để EC2 kết nối RDS 14/10/2025 14/10/2025 https://000005.awsstudygroup.com/ 3 - Triển khai ứng dụng: + Deploy ứng dụng kết nối tới RDS + Kiểm tra CRUD từ EC2 lên database 15/10/2025 15/10/2025 https://000005.awsstudygroup.com/ 4 - Workshop Lightsail – Phần 1: + Deploy database trên Lightsail + Triển khai WordPress, Prestashop và Akaunting 16/10/2025 16/10/2025 https://000045.awsstudygroup.com/ 5 - Workshop Lightsail – Phần 2: + Cấu hình bảo mật ứng dụng + Tạo snapshot + Scale lên instance mạnh hơn + Tạo alarm giám sát + Cleanup tài nguyên 17/10/2025 17/10/2025 https://000045.awsstudygroup.com/ Thành tựu Tuần 6: Hiểu kiến trúc và hoạt động của RDS trong môi trường AWS. Tạo thành công EC2 và RDS MySQL với cấu hình mạng \u0026amp; bảo mật đúng chuẩn. Deploy ứng dụng truy vấn RDS và kiểm thử CRUD. Thực hành tạo snapshot và restore trên RDS. Triển khai ứng dụng WordPress, Prestashop, Akaunting trên Lightsail. Nắm được cách tăng cường bảo mật cho ứng dụng Lightsail. Thực hành tối ưu chi phí: snapshot, nâng cấp instance, tạo alarm giám sát. Cleanup toàn bộ tài nguyên để tránh tốn phí. "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.6-infrastructure/","title":"Triển khai giải pháp","tags":[],"description":"","content":"Trong phần này, chúng ta sẽ clone repository và triển khai toàn bộ hạ tầng AWS cho hệ thống ARC Chatbot.\nBước 1: Clone Repository Clone repository từ GitHub:\ngit clone https://github.com/CrystalJohn/ARC-project.git cd ARC-project Bước 2: Build Dashboard Trước khi triển khai ứng dụng, chúng ta cần build frontend dashboard.\nDi chuyển đến thư mục frontend cd frontend Cài đặt dependencies Chạy lệnh sau để cài đặt các thư viện cần thiết:\nnpm install Build Dashboard Sau khi cài đặt hoàn tất, chạy lệnh build:\nnpm run build Sau khi quá trình hoàn tất, một thư mục dist sẽ được tạo. Kiểm tra file index.html và thư mục assets:\nls dist/ # index.html assets/ Quay lại thư mục gốc của project cd .. Bước 3: Triển khai CDK Application Triển khai ứng dụng CDK. Quá trình sẽ mất khoảng 20-30 phút để triển khai tất cả các tài nguyên.\ncd terraform terraform init terraform apply --auto-approve ⚠️ Note: Nếu bạn gặp lỗi ở bước này, hãy đảm bảo Docker đang chạy trên máy tính của bạn.\n💡 Info: Thay thế \u0026lt;account_id\u0026gt; bằng AWS Account ID thực tế của bạn.\nBước 4: Xác minh Triển khai Sau khi hoàn thành tất cả các bước trên, môi trường của bạn đã được triển khai thành công.\nBạn có thể xác minh triển khai bằng cách kiểm tra:\nAWS Console: Kiểm tra các resources đã được tạo (EC2, S3, Cognito, DynamoDB, etc.) Terraform State: Chạy terraform state list để xem danh sách resources S3 Buckets: Bucket cho documents và frontend đã được tạo EC2 Instance: Instance cho backend đã được khởi tạo Kiểm tra Outputs terraform output Các outputs quan trọng:\nOutput Mô tả api_endpoint Backend API URL cognito_user_pool_id Cognito User Pool ID cognito_client_id Cognito App Client ID s3_bucket_name S3 bucket cho documents cloudfront_url Frontend URL Các Bước Tiếp Theo Bây giờ bạn có thể tiếp tục:\nThiết lập Backend Thiết lập IDP Pipeline Thiết lập Frontend "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Amazon Web Services, Inc. từ Ngày 6 tháng 9 năm 2025 đến ngày 9 tháng 12 năm 2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia Dự án chatbot cho học tập nội bộ, qua đó cải thiện kỹ năng [lập trình, phân tích, viết báo cáo,]. Về tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ☐ ✅ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Cần cải thiện Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Cơ hội phát triển Lĩnh vực Nội dung cần cải thiện Quản lý thời gian - Tối ưu việc cân bằng giữa học nhiều dịch vụ AWS và đào sâu từng chủ đề cụ thể.\n- Cải thiện khả năng ước lượng thời gian cho các tác vụ triển khai phức tạp. Giao tiếp kỹ thuật - Nâng cao khả năng giải thích kiến trúc phức tạp cho người không chuyên.\n- Luyện tập trình bày các đánh đổi kỹ thuật ngắn gọn hơn trong các buổi họp giới hạn thời gian. Chủ động phòng ngừa vấn đề - Tăng khả năng dự đoán lỗi tiềm ẩn trước khi xảy ra.\n- Cải thiện quy trình kiểm tra trước triển khai để phát hiện lỗi cấu hình sớm hơn. Mục tiêu phát triển tương lai Mục tiêu Nội dung AI/ML Mở rộng chuyên môn về SageMaker, Bedrock, Comprehend để phát triển chatbot nâng cao. DevOps Tìm hiểu CI/CD pipelines, automated testing, giám sát hệ thống với CloudWatch và X-Ray. Cộng đồng AWS Tham gia đóng góp dự án mã nguồn mở và chia sẻ kiến thức qua blog. Kiến trúc nâng cao Khám phá multi-region architecture và chiến lược disaster recovery. Kết luận Kỳ thực tập 12 tuần tại First Cloud Journey đã cung cấp kinh nghiệm thực hành quý báu với AWS và phát triển dự án thực tế. Tôi đã chuyển đổi từ người mới bắt đầu thành người có khả năng thiết kế và triển khai các giải pháp đám mây sẵn sàng cho sản xuất. Đây sẽ là nền tảng quan trọng cho sự nghiệp điện toán đám mây của tôi.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.7-week7/","title":"Nhật ký Tuần 7","tags":[],"description":"","content":"Mục tiêu Tuần 7: Học cách triển khai và tối ưu kiến trúc AWS cho một dự án thực tế. Ôn tập lại các kiến thức AWS cốt lõi. Thử nghiệm triển khai chatbot Text-to-SQL và đánh giá các hướng mở rộng. Phân tích bảo mật cơ sở dữ liệu và luồng xử lý dữ liệu trong hệ thống. Nâng cao khả năng tư duy về chi phí, độ tin cậy và bảo mật khi phát triển kiến trúc hiện có. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu cách downscale (giảm quy mô) dự án. - Học cách triển khai một kiến trúc trên AWS. - Ghi nhận một sự cố hiếm gặp: AWS outage tại us-east-1, ảnh hưởng đến nhiều hệ thống. 20/10/2025 20/10/2025 Internal AWS reports, incident reports 3 - Ôn tập lại các kiến thức AWS cốt lõi để chuẩn bị cho đánh giá. 21/10/2025 21/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Vẽ lại kiến trúc tổng thể và ước tính chi phí cho dự án. - Xác định định hướng ban đầu cho chatbot của dự án. - Tài liệu định hướng (Notion). 22/10/2025 22/10/2025 Draw.io 5 - Tìm hiểu bảo mật cơ sở dữ liệu và logic xử lý dữ liệu an toàn để tránh các thao tác sai của người dùng (update/insert/delete không hợp lệ). - Triển khai chatbot Text2SQL theo hướng dẫn trên AWS Blog. - AWS Blog: Build an AI-powered Text-to-SQL Chatbot. 23/10/2025 23/10/2025 AWS Blog 6 - Đọc và hiểu mã nguồn chatbot Text2SQL. - Ghi chú họp trên Notion. - Họp nhóm: làm rõ cách chatbot tương tác với cơ sở dữ liệu, các biện pháp bảo mật và giới hạn quyền truy cập DB. - Đề xuất thay thế RAG bằng cache DynamoDB để giảm chi phí so với OpenSearch. 24/10/2025 24/10/2025 Notion, AWS Blog Thành tựu Tuần 7 Tuần 7 đánh dấu bước chuyển từ các bài thực hành cơ bản sang làm việc với một kiến trúc gần với môi trường production hơn. Thay vì chỉ làm theo tutorial, mình phải suy nghĩ về việc hệ thống sẽ scale như thế nào, tốn bao nhiêu chi phí, và làm sao để giữ an toàn khi tích hợp chatbot Text2SQL.\nCải thiện hiểu biết về downscaling dự án và tối ưu tài nguyên\nĐầu tuần, mình tập trung vào cách giảm quy mô dự án hiện tại để phù hợp với các ràng buộc thực tế (môi trường sinh viên, ngân sách hạn chế, workload có kiểm soát).\nXem lại những thành phần nào thật sự cần chạy 24/7 và thành phần nào có thể giảm quy mô hoặc tắt khi không cần. Cân nhắc các lựa chọn như giảm kích thước instance, dùng ít AZ hơn nếu chấp nhận được, và loại bỏ các tài nguyên test không cần thiết.\nĐiều này giúp mình nhận ra tối ưu không phải lúc nào cũng là “thêm dịch vụ”, mà nhiều khi là loại bỏ hoặc đơn giản hóa những phần không cần thiết. Củng cố nền tảng kiến trúc AWS thông qua ôn tập và áp dụng\nMình ôn lại các khái niệm AWS cốt lõi (networking, compute, storage, IAM, bảo mật, fault tolerance) không chỉ để thi mà để gắn trực tiếp với dự án hiện tại:\nKiểm tra lại cách VPC, subnet, security group và routing kết nối với nhau trong thiết kế hiện tại. Liên kết lý thuyết từ tài liệu học với các quyết định kiến trúc cụ thể trong hệ thống chatbot.\nViệc ôn tập này giúp hiểu biết của mình vững hơn và bớt “màu thi cử”; mình có thể giải thích rõ hơn tại sao chọn các dịch vụ AWS đó trong kiến trúc. Thiết kế lại kiến trúc tổng thể và xây dựng phiên bản có ý thức về chi phí\nTrong nhiệm vụ vẽ lại kiến trúc, mình:\nTạo một phiên bản kiến trúc mới phản ánh phạm vi dự án hiện tại, bao gồm chatbot Text2SQL, cơ sở dữ liệu và các thành phần hỗ trợ. Thêm góc nhìn chi phí vào sơ đồ (ví dụ: thành phần nào tạo chi phí cố định hàng tháng, thành phần nào scale theo mức sử dụng, và nơi nào có thể tận dụng free tier hoặc dịch vụ serverless). Ghi lại kiến trúc và các giả định về pricing trong Notion để team cùng thảo luận và phản biện.\nĐây là bước quan trọng để chuyển từ “kiến trúc kiểu lab” sang một thiết kế gần hơn với dự án thực tế. Xác định định hướng ban đầu cho chatbot Text2SQL\nMình làm rõ cách chatbot cần hoạt động ở góc độ trải nghiệm người dùng và thiết kế hệ thống:\nMô tả flow: từ câu hỏi của người dùng → prompt gửi cho model → sinh SQL → kiểm tra/validate → thực thi → format kết quả trả về. Ghi lại các ràng buộc như độ phức tạp truy vấn tối đa, giới hạn timeout, và các bước kiểm tra an toàn trước khi chạy SQL được sinh ra. Liệt kê các câu hỏi còn mở (ví dụ: log query như thế nào, giám sát lạm dụng ra sao, giới hạn tài nguyên thế nào).\nNhờ đó, dự án có một định hướng kỹ thuật rõ hơn thay vì chỉ dừng lại ở mức “muốn làm một chatbot Text2SQL”. Triển khai chatbot Text2SQL theo hướng dẫn AWS Blog\nMình làm theo tutorial chính thức trên AWS Blog để triển khai chatbot Text-to-SQL có dùng AI:\nThiết lập các thành phần hạ tầng cần thiết (API, Lambda functions, kết nối cơ sở dữ liệu, và tích hợp Bedrock nếu áp dụng). Deploy giải pháp mẫu và kiểm tra rằng câu hỏi của người dùng được chuyển thành truy vấn SQL và thực thi đúng trên database. Xem log và trace để đảm bảo các lỗi (truy vấn không hợp lệ, timeout, lỗi cú pháp) được xử lý an toàn.\nViệc triển khai thành công chatbot giúp mình tự tin hơn trong việc tích hợp các thành phần AI vào kiến trúc cloud. Phân tích bảo mật cơ sở dữ liệu và logic xử lý dữ liệu an toàn\nĐể đảm bảo chatbot không làm hỏng hệ thống hoặc dữ liệu, mình:\nTìm hiểu các pattern safe data logic để tránh các thao tác nguy hiểm như UPDATE/DELETE/INSERT ngoài ý muốn hoặc thiếu điều kiện. Cân nhắc dùng role chỉ đọc (read-only) cho các truy vấn Text2SQL nhằm giới hạn khả năng chỉnh sửa dữ liệu. Suy nghĩ về lớp validation để kiểm tra hoặc hạn chế câu SQL được sinh ra trước khi thực thi.\nQua đó, mình nhận ra hệ thống có dùng AI càng cần kiểm soát và validate chặt chẽ hơn so với ứng dụng truyền thống. Đọc và hiểu mã nguồn chatbot Text2SQL\nMình xem chi tiết mã nguồn của giải pháp:\nPhân tích cách tạo prompt, cách sinh SQL và cách chuyển kết quả thành câu trả lời thân thiện với người dùng. Ghi chú lại cách code xử lý lỗi, logging và tích hợp với các dịch vụ AWS. Gắn từng phần code với các thành phần trong kiến trúc (ví dụ: Lambda nào đảm nhiệm bước nào trong flow).\nĐiều này giúp mình hiểu sâu hơn ở mức triển khai thay vì xem giải pháp như một “hộp đen”. Đánh giá việc thay thế RAG bằng cache dựa trên DynamoDB để giảm chi phí\nTrong buổi họp nhóm, bọn mình thảo luận trade-off giữa RAG dùng OpenSearch và cache bằng DynamoDB:\nNhận ra rằng với một số loại truy vấn, kết hợp dữ liệu có cấu trúc + cache có thể rẻ và đơn giản hơn so với giải pháp vector search đầy đủ. Đề xuất dùng DynamoDB làm cache cho các truy vấn thường gặp hoặc kết quả đã được xử lý trước để giảm cả độ trễ và chi phí OpenSearch. Cân nhắc tác động lên tính linh hoạt: DynamoDB cache “ít linh hoạt” hơn RAG, nhưng đủ dùng cho các pattern truy vấn được định hình rõ.\nQua đó, mình học được cách cân nhắc giữa chi phí và độ linh hoạt, tránh mặc định chọn giải pháp phức tạp nhất. Rút kinh nghiệm từ sự cố thật AWS outage (khu vực us-east-1)\nKhi ghi nhận sự cố AWS outage tại us-east-1, mình:\nSuy nghĩ về việc một sự cố cấp vùng có thể ảnh hưởng đồng thời rất nhiều hệ thống như thế nào. Nghĩ về cách kiến trúc hiện tại của mình sẽ ứng xử trong tình huống tương tự và những chiến lược giảm thiểu nào (multi-AZ, multi-region, fallback) có thể cân nhắc trong tương lai.\nTrải nghiệm này giúp mình nâng cao nhận thức về tính chịu lỗi và khả năng phục hồi, vượt ra khỏi phạm vi thiết kế chỉ trong một region. 1. Tự đánh giá Tự tin hơn khi thảo luận về kiến trúc và trade-off\nMình cảm thấy thoải mái hơn khi giải thích tại sao sử dụng một dịch vụ nhất định, chúng kết nối với nhau ra sao và trade-off giữa chi phí, hiệu năng, độ phức tạp là gì.\nGiỏi hơn trong việc liên kết giữa code và kiến trúc\nViệc đọc mã nguồn của chatbot Text2SQL và mapping lại với sơ đồ kiến trúc giúp mình hiểu rõ cách các quyết định thiết kế ở mức cao được triển khai thành code cụ thể.\nCải thiện nhận thức bảo mật cho hệ thống dùng AI\nGiờ đây mình chú ý nhiều hơn đến quyền truy cập dữ liệu khi có LLM hoặc cơ chế sinh SQL tự động, thay vì chỉ kiểm tra xem “nó chạy được hay không”.\n2. Khó khăn gặp phải Cân bằng giữa độ phức tạp và chi phí\nKhó khăn lớn là quyết định khi nào nên dùng các thành phần nâng cao (như RAG + OpenSearch) và khi nào một pattern đơn giản hơn (như cache bằng DynamoDB) là đủ. Điều này đòi hỏi sự phán đoán chứ không chỉ làm theo best practice.\nTư duy về outage và tính chịu lỗi\nViệc tưởng tượng các sự cố hiếm như outage cả một region không hề tự nhiên lúc đầu. Mình phải “căng não” để suy nghĩ theo kiểu “nếu cả region này không còn hoạt động thì sao?” thay vì chỉ tập trung vào trạng thái hệ thống chạy bình thường.\nHiểu toàn bộ luồng Text2SQL chi tiết\nMột số phần trong flow giữa model AI, sinh SQL và thực thi trên database khá phức tạp. Mình cần thời gian để lần theo toàn bộ đường đi của request và hiểu rõ từng bước.\nNhìn chung, Tuần 7 giúp mình tiến gần hơn tới mindset của một cloud engineer làm dự án thực: không chỉ triển khai các thành phần, mà còn tối ưu kiến trúc, kiểm soát chi phí, bảo vệ dữ liệu và chuẩn bị cho các tình huống sự cố, trong khi vẫn tích hợp các khả năng AI vào hệ thống.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc tại FCJ rất thoải mái và giàu tính hỗ trợ. Anh chị và các bạn trong nhóm luôn sẵn lòng giúp đỡ mỗi khi mình gặp khó khăn, kể cả ngoài giờ. Không gian làm việc gọn gàng, dễ chịu, giúp mình tập trung hơn trong quá trình làm việc\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất tận tâm, luôn giải thích rõ ràng mỗi khi mình chưa hiểu vấn đề và khuyến khích mình đặt câu hỏi để mở rộng tư duy. Team admin hỗ trợ nhiệt tình trong các thủ tục và cung cấp đầy đủ tài liệu cần thiết. Điều mình trân trọng nhất là mentor luôn tạo cơ hội để mình tự tìm lời giải thay vì đưa đáp án ngay, giúp mình trưởng thành hơn về kỹ năng xử lý vấn đề.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nNhững nhiệm vụ mình đảm nhận phù hợp với kiến thức chuyên ngành đã học, đồng thời mở ra nhiều lĩnh vực mới mà trước đây mình chưa có điều kiện tiếp xúc. Nhờ vậy, mình vừa củng cố nền tảng đã có, vừa học được thêm nhiều kỹ năng thực tiễn liên quan đến ngành.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nThời gian thực tập giúp mình trau dồi rất nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, phối hợp trong nhóm và giao tiếp trong môi trường chuyên nghiệp. Mentor cũng chia sẻ nhiều bài học và kinh nghiệm quý giá, giúp mình hiểu rõ hơn về định hướng nghề nghiệp sau này.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa làm việc tại FCJ rất tích cực: mọi người tôn trọng nhau, làm việc nghiêm túc nhưng không kém phần vui vẻ. Cả đội cùng hợp tác và hỗ trợ nhau hết mình. Điều đó khiến mình cảm thấy được hòa nhập và trở thành một phần của tập thể, dù mình chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp và tạo điều kiện linh hoạt về thời gian khi mình cần. Việc được tham gia các khóa đào tạo nội bộ cũng là một điểm cộng lớn, giúp mình nâng cao kỹ năng và hiểu thêm về văn hóa làm việc.\n7. Điều bạn hài lòng nhất trong thời gian thực tập?\nĐiều khiến tôi hài lòng nhất là môi trường làm việc thân thiện và cách mentor hỗ trợ rất tận tâm. Tôi luôn cảm thấy mình được trao cơ hội để thử, sai, rồi học lại từ đầu mà không áp lực. Nhờ đó, tôi tự tin hơn nhiều trong việc giải quyết vấn đề và phát triển kỹ năng chuyên môn.\n8. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nCập nhật xây dựng một tài liệu onboarding dành riêng cho thực tập sinh cũng sẽ giúp mọi người bắt nhịp nhanh hơn trong thời gian đầu.\n9. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nTôi chắc chắn sẽ giới thiệu bạn bè đến thực tập. Lý do là vì môi trường ở đây rất phù hợp cho những bạn muốn vừa học, vừa trải nghiệm thực tế. Mentor và đội ngũ FCJ rất hỗ trợ, luôn tạo điều kiện để thực tập sinh phát triển thay vì chỉ giao việc một chiều.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.7-backend/","title":"Thiết lập Backend API","tags":[],"description":"","content":"Thiết lập Backend API Trong phần này, bạn sẽ cấu hình Backend API (FastAPI) và Qdrant vector database trên EC2.\nKiến trúc Backend Internet → ALB (:80) → EC2 Private Subnet ├── FastAPI Container (:8000) ├── Qdrant Container (:6333) └── SQS Worker (background) 💡 Note: EC2 nằm trong Private Subnet, không có Public IP. Truy cập qua SSM Session Manager.\nBước 1: Truy cập EC2 qua Session Manager EC2 instance đã được tạo trong Private Subnet và không có Public IP. Sử dụng AWS Systems Manager Session Manager để truy cập.\nCách 1: AWS Console Mở AWS Console → EC2 → Instances Chọn instance arc-dev-app-server Click Connect → Session Manager → Connect Cách 2: AWS CLI # Lấy Instance ID từ Terraform output INSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id) # Kết nối qua SSM aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 ⚠️ Yêu cầu: Cài đặt Session Manager Plugin\nBước 2: Kiểm tra Services đã chạy EC2 đã được setup tự động qua user_data script khi Terraform tạo instance. Kiểm tra các services:\n# Chuyển sang ec2-user sudo su - ec2-user # Kiểm tra Docker containers docker ps Bạn sẽ thấy 2 containers đang chạy:\napp-fastapi-1 - FastAPI server (port 8000) app-qdrant-1 - Qdrant vector database (port 6333) # Kiểm tra Qdrant curl http://localhost:6333/collections # Kiểm tra FastAPI curl http://localhost:8000/health Bước 3: Deploy Backend Code Backend code sẽ được deploy qua CI/CD Pipeline (CodePipeline → CodeBuild → CodeDeploy). Tuy nhiên, để test nhanh, bạn có thể deploy thủ công:\ncd /home/ec2-user # Clone repository git clone https://github.com/CrystalJohn/ARC-project.git cd ARC-project/backend # Stop containers cũ cd /home/ec2-user/app docker-compose down # Copy backend code cp -r /home/ec2-user/ARC-project/backend/* /home/ec2-user/app/ # Start với code mới docker-compose up -d --build Bước 4: Cấu hình Environment Variables Tạo file .env với các giá trị từ Terraform outputs:\ncd /home/ec2-user/app # Lấy values từ Terraform outputs (chạy trên máy local) # terraform -chdir=terraform output cat \u0026gt; .env \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; # AWS Configuration AWS_REGION=ap-southeast-1 # S3 S3_BUCKET_NAME=arc-documents-\u0026lt;account-id\u0026gt; # DynamoDB DYNAMODB_TABLE_NAME=arc-dev-documents # SQS SQS_QUEUE_URL=https://sqs.ap-southeast-1.amazonaws.com/\u0026lt;account-id\u0026gt;/arc-dev-document-queue # Qdrant (local container) QDRANT_HOST=qdrant QDRANT_PORT=6333 # Cognito COGNITO_USER_POOL_ID=ap-southeast-1_xxxxx COGNITO_CLIENT_ID=xxxxx # Bedrock BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0 EMBEDDING_MODEL_ID=amazon.titan-embed-text-v2:0 EOF 💡 Tip: Thay \u0026lt;account-id\u0026gt; và các giá trị xxxxx bằng outputs thực tế từ Terraform.\nBước 5: Restart Services # Restart để load .env mới docker-compose down docker-compose up -d # Kiểm tra logs docker-compose logs -f fastapi Bước 6: Verify qua ALB Backend được expose qua Application Load Balancer. Kiểm tra từ máy local:\n# Lấy ALB DNS từ Terraform output ALB_DNS=$(terraform -chdir=terraform output -raw alb_dns_name) # Test health endpoint curl http://$ALB_DNS/health # {\u0026#34;status\u0026#34;:\u0026#34;healthy\u0026#34;} Bước 7: Kiểm tra Qdrant Collection # Trên EC2 curl http://localhost:6333/collections # Tạo collection cho documents (nếu chưa có) curl -X PUT http://localhost:6333/collections/documents \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;vectors\u0026#34;: { \u0026#34;size\u0026#34;: 1024, \u0026#34;distance\u0026#34;: \u0026#34;Cosine\u0026#34; } }\u0026#39; 💡 Note: Vector size 1024 tương ứng với Amazon Titan Embeddings v2.\nChecklist Truy cập EC2 qua Session Manager thành công Docker containers đang chạy (fastapi, qdrant) File .env đã được cấu hình Health check qua ALB thành công Qdrant collection đã được tạo Troubleshooting Không thể kết nối Session Manager # Kiểm tra SSM Agent trên EC2 sudo systemctl status amazon-ssm-agent # Kiểm tra IAM Role có policy AmazonSSMManagedInstanceCore Container không start # Xem logs docker-compose logs # Kiểm tra disk space df -h ALB health check fail # Kiểm tra Security Group cho phép port 8000 từ ALB # Kiểm tra FastAPI đang listen trên 0.0.0.0:8000 docker-compose logs fastapi "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.8-week8/","title":"Nhật ký Tuần 8","tags":[],"description":"","content":"Mục tiêu Tuần 8: Ôn tập kiến thức các dịch vụ AWS để chuẩn bị cho bài kiểm tra giữa kỳ. Luyện các bài quiz và đề thi mẫu để củng cố lý thuyết và kỹ năng thực hành. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tiếp tục ôn tập các dịch vụ AWS cho bài kiểm tra giữa kỳ - Thử các bài kiểm tra do AI tạo để tự đánh giá kiến thức 27/10/2025 27/10/2025 AI-generated quizzes, AWS Study Notes 2 - Tiếp tục ôn tập các dịch vụ AWS cho bài kiểm tra giữa kỳ 28/10/2025 28/10/2025 Quizlet / AWS Docs 3 - Làm các bài quiz mẫu để củng cố kiến thức 29/10/2025 29/10/2025 AWS Quiz Practice 4 - Ôn lý thuyết trên Quizlet: AWS Hotfix V10 - Làm đề thi thử: AWS Practitioner Practice Exam - Làm đề thi thử: AWS SAA-C03 - Ôn lại qua video: AWS Solutions Architect Associate Course 30/10/2025 30/10/2025 Quizlet / GitHub / YouTube 5 - Thi giữa kỳ (Midterm exam) 31/10/2025 31/10/2025 AWS FCJ Midterm Test Thành tựu Tuần 8: Ôn tập lại toàn bộ các nhóm dịch vụ AWS: Compute, Storage, Networking, Database, Security, Monitoring, v.v. Củng cố kiến thức thông qua quiz, đề thi thử và các câu hỏi luyện tập. Nắm vững các khái niệm cốt lõi phục vụ cho các kỳ thi AWS Practitioner và SAA-C03. Làm quen với cấu trúc đề thi thực tế và các dạng câu hỏi thường gặp. Hoàn thành bài kiểm tra giữa kỳ chương trình First Cloud Journey. Cải thiện khả năng lựa chọn dịch vụ AWS phù hợp cho từng bài toán cụ thể. "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.8-idp-pipeline/","title":"Thiết lập IDP Pipeline","tags":[],"description":"","content":"Trong phần này, bạn sẽ setup SQS Worker để xử lý documents qua IDP (Intelligent Document Processing) pipeline.\nIDP Flow Upload → S3 → DynamoDB (UPLOADED) → SQS ↓ EC2 Worker ↓ PyPDF2 (digital) / Textract (scanned) ↓ Chunk Text (1000 tokens) ↓ Cohere Embed Multilingual v3 (Bedrock) ↓ Qdrant (store vectors) ↓ DynamoDB (EMBEDDING_DONE) 💡 Note: Worker sử dụng PyPDF2 cho PDF digital (text-based) và Textract cho PDF scanned (image-based).\nDocument States Status Description UPLOADED File đã upload, đang chờ xử lý IDP_RUNNING Worker đang xử lý TEXTRACT_DONE OCR hoàn tất (chỉ cho scanned PDF) EMBEDDING_DONE Hoàn tất, sẵn sàng sử dụng FAILED Có lỗi xảy ra Bước 1: Truy cập EC2 qua Session Manager # Lấy Instance ID INSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id) # Kết nối aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 Sau khi kết nối:\nsudo su - ec2-user cd /home/ec2-user/backend 💡 Note: Trên EC2 có 2 folders:\napp/ - Boilerplate từ user_data script backend/ - Code thực tế được deploy qua CI/CD (chứa run_worker.py) Bước 2: Kiểm tra Worker Code Worker code nằm trong backend/run_worker.py. Kiểm tra file đã có:\nls -la # Phải có: run_worker.py, app/, requirements.txt Bước 3: Cấu hình Environment Đảm bảo file .env có đầy đủ các biến (trong folder backend/):\ncd /home/ec2-user/backend cat .env Các biến quan trọng cho IDP:\nSQS_QUEUE_URL=https://sqs.ap-southeast-1.amazonaws.com/\u0026lt;account\u0026gt;/arc-dev-document-queue S3_BUCKET=arc-documents-\u0026lt;account\u0026gt; QDRANT_HOST=localhost QDRANT_PORT=6333 AWS_REGION=ap-southeast-1 Bước 4: Start Worker Option A: Chạy trực tiếp (để debug) # Activate virtual environment (nếu có) source venv/bin/activate # Chạy worker python run_worker.py Worker sẽ hiển thị:\n============================================================ IDP Pipeline - SQS Worker ============================================================ Queue URL: https://sqs.ap-southeast-1.amazonaws.com/xxx/arc-dev-document-queue Bucket: arc-documents-xxx Region: ap-southeast-1 Qdrant: localhost:6333 ------------------------------------------------------------ Processing indefinitely (Ctrl+C to stop)... Option B: Chạy trong background với nohup nohup python run_worker.py \u0026gt; worker.log 2\u0026gt;\u0026amp;1 \u0026amp; # Kiểm tra process ps aux | grep run_worker # Xem logs tail -f worker.log Option C: Chạy trong Docker (recommended) # Thêm worker vào docker-compose.yml docker-compose up -d worker Bước 5: Test IDP Pipeline 5.1 Upload test file lên S3 # Từ máy local aws s3 cp test-sample.pdf s3://arc-documents-\u0026lt;account\u0026gt;/uploads/test-001.pdf 5.2 Tạo record trong DynamoDB aws dynamodb put-item \\ --table-name arc-dev-documents \\ --item \u0026#39;{ \u0026#34;doc_id\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;test-001\u0026#34;}, \u0026#34;sk\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;METADATA\u0026#34;}, \u0026#34;filename\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;test-sample.pdf\u0026#34;}, \u0026#34;s3_key\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;uploads/test-001.pdf\u0026#34;}, \u0026#34;status\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;UPLOADED\u0026#34;}, \u0026#34;uploaded_at\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;\u0026#39;$(date -u +%Y-%m-%dT%H:%M:%SZ)\u0026#39;\u0026#34;} }\u0026#39; 5.3 Gửi message vào SQS aws sqs send-message \\ --queue-url https://sqs.ap-southeast-1.amazonaws.com/\u0026lt;account\u0026gt;/arc-dev-document-queue \\ --message-body \u0026#39;{ \u0026#34;doc_id\u0026#34;: \u0026#34;test-001\u0026#34;, \u0026#34;s3_key\u0026#34;: \u0026#34;uploads/test-001.pdf\u0026#34;, \u0026#34;filename\u0026#34;: \u0026#34;test-sample.pdf\u0026#34; }\u0026#39; Bước 6: Monitor Processing Xem logs của worker:\n# Nếu chạy trực tiếp # Logs hiển thị trên terminal # Nếu chạy background tail -f worker.log Logs thành công sẽ như sau:\n2024-01-15 10:30:00 - INFO - Received message for doc_id: test-001 2024-01-15 10:30:01 - INFO - Downloading from S3: uploads/test-001.pdf 2024-01-15 10:30:02 - INFO - Extracting text with PyPDF2... 2024-01-15 10:30:03 - INFO - Created 8 chunks from document 2024-01-15 10:30:05 - INFO - Generating embeddings with Cohere... 2024-01-15 10:30:10 - INFO - Stored 8 vectors for test-001 2024-01-15 10:30:10 - INFO - Updated status: EMBEDDING_DONE 2024-01-15 10:30:10 - INFO - Document test-001 processed successfully Bước 7: Verify Processing 7.1 Kiểm tra DynamoDB aws dynamodb get-item \\ --table-name arc-dev-documents \\ --key \u0026#39;{\u0026#34;doc_id\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;test-001\u0026#34;},\u0026#34;sk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;METADATA\u0026#34;}}\u0026#39; \\ --query \u0026#39;Item.{status:status.S,chunks:chunk_count.N}\u0026#39; Expected output:\n{ \u0026#34;status\u0026#34;: \u0026#34;EMBEDDING_DONE\u0026#34;, \u0026#34;chunks\u0026#34;: \u0026#34;8\u0026#34; } 7.2 Kiểm tra Qdrant # Trên EC2 curl -s http://localhost:6333/collections/arc_documents/points/count | jq Expected output:\n{ \u0026#34;result\u0026#34;: { \u0026#34;count\u0026#34;: 8 } } Xử lý Lỗi Vấn đề Nguyên nhân Giải pháp Worker không nhận message SQS URL sai Kiểm tra .env Bedrock timeout Rate limit Tăng retry delay Qdrant connection refused Container chưa start docker-compose up -d qdrant FAILED status Xem error_message trong DynamoDB Fix và retry Retry Failed Document # Cập nhật status về UPLOADED để retry aws dynamodb update-item \\ --table-name arc-dev-documents \\ --key \u0026#39;{\u0026#34;doc_id\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;test-001\u0026#34;},\u0026#34;sk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;METADATA\u0026#34;}}\u0026#39; \\ --update-expression \u0026#34;SET #s = :s\u0026#34; \\ --expression-attribute-names \u0026#39;{\u0026#34;#s\u0026#34;:\u0026#34;status\u0026#34;}\u0026#39; \\ --expression-attribute-values \u0026#39;{\u0026#34;:s\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;UPLOADED\u0026#34;}}\u0026#39; # Gửi lại message vào SQS aws sqs send-message \\ --queue-url $SQS_QUEUE_URL \\ --message-body \u0026#39;{\u0026#34;doc_id\u0026#34;:\u0026#34;test-001\u0026#34;,\u0026#34;s3_key\u0026#34;:\u0026#34;uploads/test-001.pdf\u0026#34;,\u0026#34;filename\u0026#34;:\u0026#34;test-sample.pdf\u0026#34;}\u0026#39; Checklist Truy cập EC2 qua Session Manager Worker code có sẵn Environment variables configured Worker đang chạy Test document uploaded to S3 SQS message sent Worker processed document (logs) Status = EMBEDDING_DONE trong DynamoDB Vectors stored trong Qdrant "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.9-frontend/","title":"Thiết lập Frontend","tags":[],"description":"","content":"Thiết lập Frontend Cấu hình và deploy Frontend React application với AWS Amplify.\nBước 1: Lấy Terraform Outputs cd terraform terraform output Ghi lại: cognito_user_pool_id, cognito_client_id, alb_dns_name\nBước 2: Cấu hình Environment cd ARC-project cp .env.example .env Chỉnh sửa .env:\nVITE_AWS_REGION=ap-southeast-1 VITE_COGNITO_POOL_ID=ap-southeast-1_xxxxxxx VITE_COGNITO_CLIENT_ID=xxxxxxxxxxxxxxxxxxxxxxxxxx VITE_API_URL=http://arc-chatbot-dev-alb-xxxxx.ap-southeast-1.elb.amazonaws.com Bước 3: Install \u0026amp; Test Local npm install npm run dev Mở http://localhost:5173\nBước 4: Build \u0026amp; Deploy npm run build Push code lên GitHub, Amplify sẽ tự động deploy:\ngit add . git commit -m \u0026#34;Update frontend config\u0026#34; git push origin main 💡 Amplify app đã được tạo qua Terraform và connected với GitHub.\nBước 5: Cập nhật Cognito Callback URLs Sau khi có Amplify URL:\naws cognito-idp update-user-pool-client \\ --user-pool-id ap-southeast-1_xxxxxxx \\ --client-id xxxxxxxxxx \\ --callback-urls \u0026#34;http://localhost:5173\u0026#34; \u0026#34;https://main.xxxxx.amplifyapp.com\u0026#34; \\ --logout-urls \u0026#34;http://localhost:5173\u0026#34; \u0026#34;https://main.xxxxx.amplifyapp.com\u0026#34; Bước 6: Tạo Test Users # Admin user aws cognito-idp admin-create-user \\ --user-pool-id ap-southeast-1_xxxxxxx \\ --username admin@example.com \\ --user-attributes Name=email,Value=admin@example.com \\ --temporary-password \u0026#34;TempPass123!\u0026#34; aws cognito-idp admin-add-user-to-group \\ --user-pool-id ap-southeast-1_xxxxxxx \\ --username admin@example.com \\ --group-name admin Xử lý Lỗi Lỗi Giải pháp CORS error Kiểm tra FastAPI CORS config \u0026ldquo;User pool does not exist\u0026rdquo; Kiểm tra VITE_COGNITO_POOL_ID Build failed Kiểm tra Amplify environment variables Checklist .env đã cấu hình Local dev server chạy được Amplify deploy thành công Cognito callback URLs đã cập nhật Login/Register hoạt động "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu Tuần 9: Hiểu cách triển khai ứng dụng có khả năng mở rộng và chịu lỗi bằng Launch Template, Load Balancer và Auto Scaling Group. Nắm rõ cơ chế tự động mở rộng (elasticity), phân phối tải và tính sẵn sàng cao. Học cách giám sát hệ thống với CloudWatch Metrics, Logs, Alarms và Dashboards. Áp dụng các best practices về quan sát hệ thống (observability) và giám sát ứng dụng. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Tìm hiểu kiến trúc Auto Scaling + Chuẩn bị IAM, security group, AMI và mạng 03/11/2025 03/11/2025 https://000006.awsstudygroup.com/ 2 - Thực hành Phần 1: + Tạo Launch Template + Cấu hình user data, storage, instance settings 04/11/2025 04/11/2025 https://000006.awsstudygroup.com/ 3 - Thực hành Phần 2: + Tạo Application Load Balancer + Tạo target group và kiểm tra hoạt động của ứng dụng 05/11/2025 05/11/2025 https://000006.awsstudygroup.com/ 4 - Triển khai Auto Scaling Group: + Tạo ASG và policy mở rộng + Kiểm thử scaling khi tải tăng/giảm 06/11/2025 06/11/2025 https://000006.awsstudygroup.com/ 5 - Workshop CloudWatch: + Tìm hiểu Metrics + Thu thập Logs + Tạo Alarms + Tạo Dashboards + Cleanup tài nguyên 07/11/2025 07/11/2025 https://000008.awsstudygroup.com/ Thành tựu Tuần 9: Hiểu rõ cách Auto Scaling Group, Load Balancer và Launch Template kết hợp để đảm bảo tính sẵn sàng và khả năng mở rộng. Tạo thành công ASG và kiểm thử behavior của scaling policy. Tạo và triển khai ALB, kiểm tra phân phối tải và tính sẵn sàng. Thu thập và phân tích metrics \u0026amp; logs bằng CloudWatch. Tạo các cảnh báo (alarms) theo dõi sức khỏe ứng dụng và tài nguyên. Xây dựng dashboard trực quan để giám sát hệ thống. Cleanup toàn bộ tài nguyên tạo ra trong workshop để tránh phát sinh chi phí. "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.10-using-chatbot/","title":"Sử dụng Chatbot","tags":[],"description":"","content":"Hướng dẫn sử dụng ARC Chatbot để tìm kiếm thông tin từ tài liệu nghiên cứu.\nTruy cập Local: http://localhost:5173 Production: Amplify URL từ bước trước Bước 1: Đăng nhập Nhập email và password Click Login Redirect đến Chat page Bước 2: Giao diện Chat Sau khi đăng nhập, bạn sẽ thấy:\nSidebar với menu Chat, History Header với user info và dark mode toggle Chat area với welcome message Bước 3: Đặt câu hỏi Nhập câu hỏi vào input box và nhấn Enter hoặc click Send.\nCâu hỏi tốt Loại Ví dụ Định nghĩa \u0026ldquo;What is a stack data structure?\u0026rdquo; So sánh \u0026ldquo;Compare stack and queue\u0026rdquo; Giải thích \u0026ldquo;Explain binary search algorithm\u0026rdquo; Tránh ❌ Quá chung: \u0026ldquo;Tell me about programming\u0026rdquo; ❌ Ngoài tài liệu: \u0026ldquo;What\u0026rsquo;s the weather today?\u0026rdquo; Bước 4: Citations (Trích dẫn) Mỗi câu trả lời có citations hiển thị nguồn tài liệu:\n📚 Sources: [1] data-structures.pdf - Page 12 - Score: 85% [2] algorithms.pdf - Page 45 - Score: 72% Click vào citation để xem chi tiết document.\nField Mô tả [1], [2] Số thứ tự citation Filename Tên file PDF Page Số trang Score Độ liên quan (%) Bước 5: Conversation History Click History trong sidebar Xem danh sách các cuộc hội thoại trước Click vào conversation để load lại Click trash icon để xóa Bước 6: New Chat Click New Chat trong sidebar để bắt đầu cuộc hội thoại mới.\nFeatures Feature Mô tả Streaming Response hiển thị từng phần Markdown Hỗ trợ code blocks, lists, headers Dark Mode Toggle trong header History Lưu và load lại conversations Checklist Đăng nhập thành công Gửi query và nhận response Citations hiển thị đúng Click citation xem document History hoạt động New Chat hoạt động "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10 Học cách cài đặt, cấu hình và sử dụng AWS CLI để thao tác với các dịch vụ AWS. Quản lý tài nguyên AWS (S3, SNS, IAM, VPC, EC2) thông qua dòng lệnh. Tìm hiểu Route 53 Resolver và xây dựng mô hình Hybrid DNS giữa on-premises và AWS. Triển khai Microsoft AD và cấu hình DNS forwarding với Route 53 Resolver. Nhiệm vụ thực hiện trong tuần Ngày Nhiệm vụ Bắt đầu Hoàn thành Tài liệu 1 - Giới thiệu AWS CLI - Môi trường chạy CLI (Linux/macOS/Windows/Remote) - Tìm hiểu CLI Profiles - Cấu hình CLI bằng aws configure 10/11/2025 10/11/2025 https://000011.awsstudygroup.com/ 2 - Cài đặt AWS CLI - Xem tài nguyên AWS bằng CLI - Làm việc với Amazon S3 bằng CLI (list, upload, download) 11/11/2025 11/11/2025 https://000011.awsstudygroup.com/ 3 - AWS CLI với Amazon SNS (tạo topic, subscription, publish) - AWS CLI với IAM (tạo user, list policies) - AWS CLI với VPC (list VPCs, subnets, SGs) 12/11/2025 12/11/2025 https://000011.awsstudygroup.com/ 4 - Tạo EC2 bằng AWS CLI - Xử lý lỗi CLI - Dọn dẹp tài nguyên CLI Bắt đầu Lab Route 53 Hybrid DNS: - Giới thiệu Hybrid DNS và Route 53 Resolver 13/11/2025 13/11/2025 https://000011.awsstudygroup.com/ https://000010.awsstudygroup.com/ 5 - Triển khai Microsoft AD trong lab - Cấu hình Route 53 Resolver rules - Tạo inbound \u0026amp; outbound endpoints - Kiểm tra phân giải DNS giữa on-premises và AWS - Clean up resources 14/11/2025 14/11/2025 https://000010.awsstudygroup.com/ Thành tựu tuần 10 Cài đặt và cấu hình AWS CLI thành công (Access Key, Secret Key, Default Region). Thao tác S3, SNS, IAM, VPC thông qua câu lệnh CLI. Tạo EC2 instance bằng CLI và khắc phục lỗi liên quan. Hiểu rõ kiến trúc Hybrid DNS với Route 53 Resolver. Triển khai Microsoft AD và cấu hình DNS forwarding giữa on-premises và AWS. Kiểm tra hoạt động của Resolver rules, inbound/outbound endpoints. Dọn dẹp toàn bộ tài nguyên sau khi hoàn tất bài lab. "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11 Hoàn thiện base infrastructure (M0) gồm S3, DynamoDB, Cognito, ALB. Bắt đầu triển khai IDP Pipeline (M1) — SQS, PDF Detection, PyPDF2 extraction. Ổn định và tối ưu luồng Analytics trước đó: chuyển từ Glue Crawler sang Athena DDL để giảm chi phí và đơn giản hóa kiến trúc. Chuẩn hóa lại hệ thống Lambda (AdminManager, Analytics Lambda) và đảm bảo hoạt động ổn định khi thao tác với Athena và RDS. Tối ưu cấu hình Cognito để tách biệt backend và authentication logic. Kiểm thử pipeline end-to-end từ document upload → detection → extraction → DynamoDB → frontend. Các công việc cần triển khai trong tuần này Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Setup S3 bucket arc-chatbot-documents-427995028618 - Tạo DynamoDB tables (metadata, chat-history) - Cấu hình schema \u0026amp; indexes 17/11/2025 17/11/2025 https://docs.aws.amazon.com/dynamodb/ 3 - Configure Cognito User Pool ap-southeast-1_8KB4JYvsX - Setup user authentication flow - Test sign-up/sign-in 18/11/2025 18/11/2025 https://docs.aws.amazon.com/cognito/ 4 - Setup ALB arc-chatbot-dev-alb với health checks - Configure target groups \u0026amp; listeners - Test routing 19/11/2025 19/11/2025 https://docs.aws.amazon.com/elasticloadbalancing/ 5 - Tạo SQS queue arc-chatbot-dev-document-processing - Implement PDF detection (digital vs scanned) - Viết unit tests cho PDF detector 20/11/2025 20/11/2025 https://docs.aws.amazon.com/sqs/ 6 - Implement PyPDF2 extraction cho digital PDFs - Xử lý edge cases (encrypted, corrupted) - Viết tests (30 tests passed) 21/11/2025 21/11/2025 https://pypdf2.readthedocs.io/ Kết quả đạt được tuần 11 1. Hoàn thiện Base Infrastructure (M0) S3 bucket arc-chatbot-documents-427995028618 để lưu documents. DynamoDB tables: metadata: lưu thông tin mô tả tài liệu chat-history: lưu lịch sử hội thoại Cognito User Pool ap-southeast-1_8KB4JYvsX — dùng cho xác thực \u0026amp; phân quyền. ALB arc-chatbot-dev-alb — điều phối traffic API với health checks. 2. Khởi động \u0026amp; tối ưu IDP Pipeline (M1) SQS Queue arc-chatbot-dev-document-processing đảm nhiệm việc phân luồng xử lý tài liệu. PDF Detector service: phân biệt digital vs scanned (17 tests passed). PDF Extractor (PyPDF2): extract text từ digital PDF (30 tests passed). Bổ sung xử lý lỗi của file PDF: encrypted, corrupted, unsupported. 3. Ổn định \u0026amp; cải thiện luồng Analytics từ tuần trước Loại bỏ Glue Crawler → chuyển sang Athena DDL để chủ động định nghĩa schema. Xóa Glue DB, Glue endpoint → giảm chi phí \u0026amp; đơn giản hệ thống. Refactor Lambda Analytics để chạy ngoài VPC khi query Athena. AdminManager Lambda chỉ còn nhiệm vụ insert vào RDS → đơn giản hóa kiến trúc. Tối ưu Cognito để backend không phụ thuộc trực tiếp DB. 4. Progress về Frontend \u0026amp; Authentication Deploy thành công login page trên CloudFront. Hoàn thiện logic admin_handler để insert dữ liệu vào RDS ổn định hơn. Học được Thiết kế DynamoDB schema cho hệ thống RAG/Chatbot. Luồng xác thực Cognito + JWT tokens + User Pool flows. SQS message processing patterns \u0026amp; cách thiết kế IDP pipeline. Kỹ thuật đọc PDF bằng PyPDF2 và xử lý các dạng lỗi. Kiến trúc Athena DDL, sự khác biệt với Glue Crawler, best practices cho chi phí/hiệu năng. Cách tối ưu Lambda trong môi trường serverless pipeline. Tổng kết Tuần 11 đạt được các mục tiêu chính: hoàn thiện M0, khởi động M1, ổn định lại pipeline phân tích dữ liệu, chuẩn hóa hệ thống Lambda và xác thực Cognito. Nhờ đó, dự án đã có nền tảng vững chắc để tiếp tục xây dựng RAG pipeline và mở rộng các module xử lý tài liệu ở tuần tiếp theo.\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.11-admin-dashboard/","title":"Sử dụng Admin Dashboard","tags":[],"description":"","content":"Sử dụng Admin Dashboard Hướng dẫn sử dụng Admin Dashboard để quản lý documents.\nTruy cập URL: http://localhost:5173/admin (hoặc Amplify URL) Yêu cầu: Tài khoản thuộc group admin Bước 1: Đăng nhập Admin Đăng nhập với tài khoản admin (đã tạo ở bước trước).\nBước 2: Dashboard Overview Sau khi đăng nhập, bạn sẽ thấy:\nUpload section (drag \u0026amp; drop) Documents table với pagination Status filter và auto-refresh Bước 3: Upload Tài liệu 3.1. Chọn file Drag \u0026amp; drop PDF files vào vùng upload Hoặc click Browse Files để chọn 3.2. Upload Progress Mỗi file hiển thị progress bar và status:\nuploading - Đang upload success - Upload thành công error - Upload thất bại Bước 4: Document Status Sau khi upload, document sẽ được xử lý qua IDP pipeline:\nStatus Mô tả Thời gian UPLOADED Chờ xử lý - IDP_RUNNING Đang xử lý 1-5 phút EMBEDDING_DONE Sẵn sàng - FAILED Lỗi - 💡 Tip: Bật Auto-refresh (5s) để tự động cập nhật status.\nBước 5: Quản lý Documents Filter theo Status Sử dụng dropdown Status để lọc:\nAll Uploaded Processing Done Failed Pagination Documents được phân trang (5 items/page). Sử dụng pagination controls ở footer.\nView Document Click icon 👁️ để xem chi tiết document.\nDelete Document Click icon 🗑️ để xóa document.\n⚠️ Warning: Xóa document sẽ xóa khỏi S3, DynamoDB và Qdrant.\nBước 6: Processing History Click Processing History link để xem lịch sử xử lý documents.\nXử lý Lỗi Vấn đề Giải pháp Upload failed Kiểm tra file size (\u0026lt;50MB), format (PDF only) Document stuck in IDP_RUNNING Kiểm tra worker logs trên EC2 Document FAILED Xem error message trong Processing History Checklist Đăng nhập admin dashboard Upload document thành công Document processed (EMBEDDING_DONE) Filter/pagination hoạt động Auto-refresh hoạt động "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/5-workshop/5.12-cleanup/","title":"Dọn dẹp Tài nguyên","tags":[],"description":"","content":"Dọn dẹp Tài nguyên Sau khi hoàn thành workshop, dọn dẹp AWS resources để tránh phát sinh chi phí.\n⚠️ Cảnh báo: Các bước này sẽ XÓA VĨNH VIỄN tất cả data và resources!\nThứ tự Dọn dẹp Stop services trên EC2 Empty S3 buckets Terraform destroy Verify cleanup Bước 1: Stop Services trên EC2 Kết nối EC2 qua Session Manager:\nINSTANCE_ID=$(terraform -chdir=terraform output -raw ec2_instance_id) aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1 Stop Docker containers:\nsudo su - ec2-user cd /home/ec2-user/app # Stop containers docker-compose down # Remove volumes docker volume rm app_qdrant_storage Bước 2: Empty S3 Buckets S3 buckets phải empty trước khi Terraform destroy:\n# Lấy bucket name từ Terraform output BUCKET=$(terraform -chdir=terraform output -raw s3_bucket_name) # Empty bucket aws s3 rm s3://$BUCKET --recursive # Hoặc force delete aws s3 rb s3://$BUCKET --force Bước 3: Terraform Destroy cd terraform terraform plan -destroy terraform destroy Nhập yes khi được hỏi. Quá trình này mất khoảng 10-15 phút.\nBước 4: Manual Cleanup (nếu cần) Nếu còn resources chưa bị xóa:\n# CloudWatch Log Groups aws logs describe-log-groups --log-group-name-prefix /aws/arc | jq -r \u0026#39;.logGroups[].logGroupName\u0026#39; | xargs -I {} aws logs delete-log-group --log-group-name {} # EC2 Key Pair (nếu tạo manual) aws ec2 delete-key-pair --key-name arc-keypair # Amplify App (nếu tạo manual) aws amplify list-apps | jq -r \u0026#39;.apps[] | select(.name | contains(\u0026#34;arc\u0026#34;)) | .appId\u0026#39; | xargs -I {} aws amplify delete-app --app-id {} Bước 5: Verify Cleanup # Check EC2 aws ec2 describe-instances --filters \u0026#34;Name=tag:Name,Values=*arc*\u0026#34; --query \u0026#39;Reservations[].Instances[].InstanceId\u0026#39; # Check S3 aws s3 ls | grep arc # Check DynamoDB aws dynamodb list-tables --query \u0026#39;TableNames[?contains(@, `arc`)]\u0026#39; # Check Cognito aws cognito-idp list-user-pools --max-results 20 --query \u0026#39;UserPools[?contains(Name, `arc`)]\u0026#39; Tất cả commands trên không nên trả về kết quả.\nBước 6: Check Costs Mở AWS Billing Dashboard Kiểm tra Bills cho tháng hiện tại Set up Budgets alert cho tương lai Xử lý Lỗi Lỗi Giải pháp DependencyViolation Destroy theo thứ tự: terraform destroy -target=module.amplify trước BucketNotEmpty aws s3 rb s3://bucket-name --force DeleteConflict (IAM) Detach policies trước khi delete role Resource in use Đợi vài phút rồi retry Kết luận Chúc mừng bạn đã hoàn thành workshop Academic Research Chatbot (ARC)! 🎉\nNhững gì bạn đã học: Triển khai RAG chatbot trên AWS Sử dụng Amazon Bedrock (Claude 3.5 Sonnet + Cohere Embed) Xây dựng IDP pipeline với PyPDF2/Textract Vector search với Qdrant Authentication với Cognito Infrastructure as Code với Terraform Tài nguyên bổ sung: AWS Bedrock Documentation Qdrant Documentation FastAPI Documentation Checklist Stop Docker containers trên EC2 Empty S3 buckets Terraform destroy thành công Verify không còn resources Check billing Cảm ơn bạn đã tham gia workshop! 🙏\n"},{"uri":"https://cbthien.github.io/fcj-workshop/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Hoàn thiện RAG Chat Component (M2) với các chức năng quan trọng: rate limiting, fallback model, error handling \u0026amp; retry logic. Khởi động giai đoạn Testing \u0026amp; Go-live (M3) — tập trung vào login page, chat UI, admin dashboard và bắt đầu kiểm thử end-to-end toàn hệ thống. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Implement Rate Limiter (60 RPM, 100K TPM) - Tích hợp Budget Manager (giới hạn $10/day, $200/month) - Viết test cho toàn bộ rate limiting logic 24/11/2025 24/11/2025 https://docs.aws.amazon.com/bedrock/ 3 - Implement fallback sang Claude Haiku khi Sonnet bị rate limit/timeout - Xây dựng error handling pipeline và retry với exponential backoff + jitter - Viết tests (35 tests passed) 25/11/2025 25/11/2025 https://docs.aws.amazon.com/bedrock/ 4 - Xây dựng login page tích hợp Cognito Hosted UI - Implement AuthService: parse \u0026amp; validate JWT, handle refresh tokens - Test full authentication flow từ login → callback → lưu token 26/11/2025 26/11/2025 https://docs.aws.amazon.com/cognito/ 5 - Build giao diện Chat UI bằng React - Implement ChatPage: message bubbles, context display, citations renderer - Tạo component CitationCard \u0026amp; DocumentViewerModal 27/11/2025 27/11/2025 https://react.dev/ 6 - Build Admin Dashboard: drag-drop upload, document list, status tracking - Hiển thị real-time document processing status (auto-refresh mỗi 5s) - Bắt đầu integration testing E2E (Auth → Chat → Admin → Logs) 28/11/2025 28/11/2025 https://react.dev/ Kết quả đạt được tuần 12: 1. Hoàn thiện RAG Chat (M2) Rate Limiter cho toàn bộ LLM requests: giới hạn 60 requests/minute và 100K tokens/minute. Budget Manager giúp bảo vệ chi phí: Giới hạn $10/ngày, $200/tháng Ngăn spam \u0026amp; misuse trong môi trường staging/production 22 unit tests passed Retry logic với exponential backoff + jitter, giảm lỗi tạm thời từ Bedrock. Fallback model logic: Mặc định dùng Claude 3.5 Sonnet Khi gặp rate limit/timeout → tự động fallback sang Claude Haiku Tăng độ ổn định cho user trải nghiệm. 2. Bắt đầu Testing \u0026amp; Go-live (M3) AuthService hoàn chỉnh: Decode + validate Cognito JWT Lưu \u0026amp; refresh tokens an toàn Tích hợp trực tiếp vào frontend Chat UI v1.0: Message bubbles mượt, hỗ trợ streaming Citation inline + hiển thị modal chi tiết UX gần với production standard Components mới: CitationCard — hiển thị thông tin nguồn DocumentViewerModal — xem nội dung PDF đã xử lý Admin Dashboard: Drag-drop upload file Bảng liệt kê document + trạng thái real-time Auto-refresh để theo dõi pipeline Bắt đầu E2E Testing: login → chat → upload → process logs → display results. Học được: Các mô hình rate limiting cho AI APIs: token bucket, leaky bucket, request throttling. Cách quản lý chi phí với Bedrock: fallback, token budgeting, usage monitoring. Exponential backoff với jitter — tăng độ ổn định hệ thống khi API lỗi tạm thời. Xây dựng React UI phức tạp (streaming messages, citation linking, modals). JWT validation với Cognito — cách trích token, verify signature, decode claims. "},{"uri":"https://cbthien.github.io/fcj-workshop/vi/categories/best-practices/","title":"Best Practices","tags":[],"description":"","content":""},{"uri":"https://cbthien.github.io/fcj-workshop/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://cbthien.github.io/fcj-workshop/vi/categories/responsible-ai/","title":"Responsible AI","tags":[],"description":"","content":""},{"uri":"https://cbthien.github.io/fcj-workshop/vi/categories/startup/","title":"Startup","tags":[],"description":"","content":""},{"uri":"https://cbthien.github.io/fcj-workshop/vi/categories/sustainability/","title":"Sustainability","tags":[],"description":"","content":""},{"uri":"https://cbthien.github.io/fcj-workshop/vi/categories/aws-for-games-blog/","title":"AWS for Games Blog","tags":[],"description":"","content":""},{"uri":"https://cbthien.github.io/fcj-workshop/vi/categories/aws-for-startups-blog/","title":"AWS for Startups Blog","tags":[],"description":"","content":""},{"uri":"https://cbthien.github.io/fcj-workshop/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]
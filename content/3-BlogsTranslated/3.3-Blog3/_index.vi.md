---
title: "Cách các climate tech startup xây dựng mô hình nền tảng với Amazon SageMaker HyperPod"
date: 2025-06-04
lastmod: 2025-06-04
author: "Ilan Gleiser, Aman Shanbhag, Ankit Anand, Lisbeth Kaufman, and Rohit Talluri"
categories: ["Best Practices", "Responsible AI", "Startup", "Sustainability"]
weight: 3
chapter: false
pre: " <b> 3.3. </b> "
---

by Ilan Gleiser, Aman Shanbhag, Ankit Anand, Lisbeth Kaufman, and Rohit Talluri | vào 04 THÁNG 06 2025 | trong [Best Practices](https://aws.amazon.com/blogs/machine-learning/category/post-types/best-practices/) , [Responsible AI](https://aws.amazon.com/blogs/machine-learning/category/responsible-ai/), [Startup](https://aws.amazon.com/blogs/machine-learning/category/startup/),
[Sustainability](https://aws.amazon.com/blogs/machine-learning/category/sustainability/)

Các climate tech startup là những công ty sử dụng công nghệ và đổi mới để đối mặt với khủng hoảng khí hậu, tập trung chủ yếu vào việc giảm phát thải khí nhà kính hoặc giúp xã hội thích ứng với các tác động của biến đổi khí hậu. Sứ mệnh chung của họ là tạo ra các giải pháp có thể mở rộng, đẩy nhanh quá trình chuyển dịch sang một tương lai bền vững với lượng carbon thấp. Nhu cầu về các giải pháp cho khủng hoảng khí hậu ngày càng trở nên cấp thiết khi các thảm họa thời tiết cực đoan do khí hậu thúc đẩy gia tăng trên toàn cầu. Năm 2024, [các thảm họa khí hậu gây thiệt hại hơn 417 tỷ USD](https://www.ajg.com/gallagherre/-/media/files/gallagher/gallagherre/news-and-insights/2025/natural-catastrophe-and-climate-report-2025.pdf) trên toàn thế giới, và tình hình không hề “giảm nhiệt” trong năm 2025 với [cháy rừng ở LA gây thiệt hại hơn 135 tỷ USD](https://apnews.com/article/california-wildfires-natural-disasters-losses-insurance-recovery-d2f24e44d75503118643151eaee947fb) chỉ trong tháng đầu tiên của năm. Các climate tech startup đang ở tuyến đầu trong việc xây dựng những giải pháp tạo tác động thực sự lên khủng hoảng khí hậu, và họ đang sử dụng [generative AI](https://aws.amazon.com/generative-ai/) để xây dựng nhanh nhất có thể.

Trong bài viết này, chúng tôi trình bày cách các climate tech startup phát triển các foundation model (FMs) dựa trên những bộ dữ liệu môi trường quy mô lớn để giải quyết các bài toán như thu giữ carbon, nhiên liệu âm carbon, thiết kế vật liệu mới để phá hủy vi nhựa, và bảo tồn hệ sinh thái. Các mô hình chuyên biệt này đòi hỏi năng lực tính toán tiên tiến để xử lý và phân tích hiệu quả khối lượng dữ liệu khổng lồ.

[Amazon Web Services](https://aws.amazon.com/) (AWS) cung cấp hạ tầng tính toán thiết yếu để hỗ trợ các nỗ lực này, với tài nguyên mạnh mẽ và có khả năng mở rộng thông qua [Amazon SageMaker HyperPod](https://aws.amazon.com/sagemaker-ai/hyperpod/). SageMaker HyperPod là một dịch vụ hạ tầng được xây dựng chuyên biệt, tự động quản lý các cụm huấn luyện AI quy mô lớn để nhà phát triển có thể hiệu quả xây dựng và huấn luyện các mô hình phức tạp như [large language models](https://aws.amazon.com/what-is/large-language-model/) (LLMs) bằng cách tự động xử lý việc khởi tạo cụm, giám sát và chịu lỗi trên hàng nghìn GPU. Với SageMaker HyperPod, các startup có thể huấn luyện các mô hình AI phức tạp trên những bộ dữ liệu môi trường đa dạng, bao gồm ảnh vệ tinh và số liệu đo đạc khí quyển, với tốc độ và hiệu suất cao hơn. Nền tảng tính toán này cực kỳ quan trọng đối với các startup đang nỗ lực tạo ra những giải pháp không chỉ mang tính đổi mới mà còn có thể mở rộng và tạo tác động thực sự.

Độ phức tạp ngày càng tăng của dữ liệu môi trường đòi hỏi hạ tầng dữ liệu vững chắc và kiến trúc mô hình tinh vi. Việc tích hợp dữ liệu đa phương thức, áp dụng các cơ chế attention chuyên biệt cho dữ liệu không gian–thời gian, và sử dụng reinforcement learning là những yếu tố then chốt để xây dựng các mô hình tập trung vào khí hậu một cách hiệu quả. Cụm GPU được tối ưu hóa và tài nguyên có khả năng mở rộng của SageMaker HyperPod giúp startup tiết kiệm thời gian và chi phí trong khi vẫn đáp ứng các yêu cầu kỹ thuật nâng cao, nghĩa là họ có thể tập trung nhiều hơn cho đổi mới. Khi nhu cầu công nghệ khí hậu tiếp tục tăng, những khả năng này cho phép startup phát triển các giải pháp môi trường mang tính chuyển hóa với Amazon SageMaker HyperPod.

## Xu hướng trong các climate tech startup xây dựng với generative AI

Các climate tech startup đang áp dụng generative AI để [tối ưu hóa vận hành](https://aws.amazon.com/startups/learn/how-climate-tech-startups-use-generative-ai-to-address-the-climate-crisis?lang=en-US#overview). Ví dụ, các startup như [BrainBox AI](https://brainboxai.com/en/) và [Pendulum](https://www.pendulum.global/) đã sử dụng [Amazon Bedrock](https://aws.amazon.com/bedrock/) và tinh chỉnh các LLM hiện có trên [AWS Trainium](https://aws.amazon.com/machine-learning/trainium/) bằng [Amazon SageMaker](https://aws.amazon.com/sagemaker/) để tự động nhập tài liệu và trích xuất dữ liệu, qua đó tăng tốc quá trình onboarding khách hàng mới. Đến giữa năm 2023, chúng tôi chứng kiến làn sóng tiếp theo khi các climate tech startup bắt đầu xây dựng [các trợ lý thông minh tinh vi](https://aws.amazon.com/startups/learn/the-latest-generative-ai-trends-to-address-the-climate-crisis#overview) bằng cách tinh chỉnh các LLM hiện có cho từng trường hợp sử dụng cụ thể. Chẳng hạn, [NET2GRID](https://www.net2grid.com/) đã sử dụng Amazon SageMaker để tinh chỉnh và triển khai các LLM quy mô lớn dựa trên [Llama 7B](https://aws.amazon.com/blogs/machine-learning/llama-2-foundation-models-from-meta-are-now-available-in-amazon-sagemaker-jumpstart/) nhằm xây dựng EnergyAI, một trợ lý cung cấp phản hồi nhanh chóng và cá nhân hóa cho các câu hỏi liên quan đến năng lượng của khách hàng ngành tiện ích.

Trong 6 tháng qua, chúng tôi đã chứng kiến làn sóng các climate tech startup xây dựng các FMs để giải quyết những thách thức cụ thể về khí hậu và môi trường. Không giống các mô hình ngôn ngữ thuần túy, các startup này xây dựng mô hình dựa trên dữ liệu thế giới thực như thời tiết hoặc dữ liệu địa không gian của Trái đất. Trong khi các LLM như Claude của Anthropic hay Nova của Amazon có hàng trăm tỷ tham số, các climate tech startup lại xây dựng những mô hình nhỏ hơn, chỉ vài tỷ tham số. Điều này khiến các mô hình đó nhanh hơn và ít tốn chi phí huấn luyện hơn. Chúng tôi đang thấy một số xu hướng nổi bật về các trường hợp sử dụng hoặc thách thức khí hậu mà startup đang giải quyết bằng cách xây dựng FMs. Dưới đây là các use case hàng đầu theo thứ tự phổ biến:

- **Thời tiết** – Được huấn luyện trên dữ liệu thời tiết lịch sử, các mô hình này cung cấp dự báo thời tiết và khí hậu ngắn hạn và dài hạn với độ chính xác cao ở mức siêu cục bộ, một số tập trung vào các yếu tố thời tiết cụ thể như gió, nhiệt hoặc ánh nắng.  

- **Khám phá vật liệu bền vững** – Được huấn luyện trên dữ liệu khoa học, các mô hình này tạo ra những vật liệu bền vững mới nhằm giải quyết các vấn đề chuyên biệt, chẳng hạn như chất hấp thụ trực tiếp CO₂ trong không khí hiệu quả hơn để giảm chi phí loại bỏ carbon, hoặc những phân tử có khả năng phá hủy vi nhựa trong môi trường.  

- **Hệ sinh thái tự nhiên** – Được huấn luyện trên tổ hợp dữ liệu từ vệ tinh, lidar và cảm biến mặt đất, các mô hình này mang lại hiểu biết sâu sắc về hệ sinh thái tự nhiên, đa dạng sinh học và dự đoán cháy rừng.  

- **Mô hình địa chất** – Được huấn luyện trên dữ liệu địa chất, các mô hình này giúp xác định vị trí tối ưu cho các hoạt động địa nhiệt hoặc khai thác mỏ nhằm giảm lãng phí và tiết kiệm chi phí.  

Để hiểu rõ hơn về các xu hướng này, những phần tiếp theo sẽ phân tích sâu cách các climate startup đang xây dựng foundation model trên AWS.

## Orbital Materials: Foundation models cho khám phá vật liệu bền vững

[Orbital Materials](https://www.orbitalmaterials.com/) đã xây dựng một nền tảng AI độc quyền để thiết kế, tổng hợp và kiểm thử các vật liệu bền vững mới. Việc phát triển vật liệu tiên tiến truyền thống vốn là một quy trình chậm chạp dựa trên thử–sai trong phòng thí nghiệm. Orbital thay thế cách làm này bằng thiết kế dựa trên generative AI, tăng tốc mạnh mẽ quá trình khám phá vật liệu và thương mại hóa công nghệ mới. Họ đã phát triển một mô hình generative AI có tên “Orb”, mô hình này đề xuất các thiết kế vật liệu mới, sau đó đội ngũ sẽ kiểm chứng và hoàn thiện trong phòng lab.

Orb là một diffusion model mà Orbital Materials đã huấn luyện từ đầu bằng SageMaker HyperPod. Sản phẩm đầu tiên mà startup thiết kế với Orb là vật liệu hấp thụ dùng cho thu giữ carbon tại các cơ sở thu giữ trực tiếp từ không khí. Kể từ khi thành lập phòng thí nghiệm vào quý đầu năm 2024, Orbital đã đạt được mức cải thiện hiệu suất vật liệu gấp 10 lần nhờ nền tảng AI của họ—nhanh hơn một bậc so với cách phát triển truyền thống và mở ra những giới hạn mới về hiệu quả loại bỏ carbon. Bằng cách cải thiện hiệu suất vật liệu, công ty có thể giúp giảm chi phí loại bỏ carbon, qua đó mở ra khả năng mở rộng nhanh chóng. Họ chọn sử dụng SageMaker HyperPod vì “thích mô hình một điểm đến (one-stop shop) cho cả kiểm soát và giám sát,” theo lời giải thích của Jonathan Godwin, CEO Orbital Materials. Orbital đã có thể giảm tổng chi phí sở hữu (TCO) cho cụm GPU của mình nhờ các deep health check của Amazon SageMaker HyperPod để kiểm tra sức chịu tải của các instance GPU và thay thế các node bị lỗi. Bên cạnh đó, Orbital có thể sử dụng SageMaker HyperPod để tự động thay thế các node gặp sự cố và khởi động lại việc huấn luyện mô hình từ checkpoint được lưu gần nhất, giúp tiết kiệm thời gian cho đội ngũ Orbital Materials. Tác nhân giám sát (monitoring agent) của SageMaker HyperPod liên tục theo dõi và phát hiện các vấn đề tiềm ẩn, bao gồm hết bộ nhớ, lỗi đĩa, bất thường GPU, deadlock kernel, lỗi container runtime và crash do out-of-memory (OOM). Tùy vào nguyên nhân, tác nhân giám sát sẽ thay thế hoặc khởi động lại node.

Với việc ra mắt SageMaker HyperPod trên [Amazon Elastic Kubernetes Service](https://aws.amazon.com/eks/) (Amazon EKS), Orbital có thể thiết lập một mặt phẳng điều khiển thống nhất bao gồm cả workload dựa trên CPU và các tác vụ tăng tốc bằng GPU trong cùng một cụm Kubernetes. Cách tiếp cận kiến trúc này loại bỏ sự phức tạp truyền thống khi phải quản lý các cụm riêng biệt cho từng loại tài nguyên tính toán khác nhau, qua đó giảm đáng kể chi phí vận hành. Orbital cũng có thể giám sát trạng thái sức khỏe của các node SageMaker HyperPod thông qua [Amazon CloudWatch Container Insights với enhanced observability cho Amazon EKS](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights.html#container-insights-detailed-metrics). Amazon CloudWatch Container Insights thu thập, tổng hợp và tóm tắt các metric và log từ các ứng dụng dạng container và microservices, cung cấp cái nhìn chi tiết về hiệu năng, sức khỏe và trạng thái cho CPU, GPU, Trainium hoặc [Elastic Fabric Adapter](https://aws.amazon.com/hpc/efa/) (EFA) và hệ thống file đến tận cấp độ container.

AWS và Orbital Materials đã thiết lập một quan hệ đối tác sâu rộng cho phép tạo “fly-wheel” tăng trưởng. Hai bên đã ký kết một thỏa thuận hợp tác nhiều năm, trong đó Orbital Materials xây dựng các FMs của mình với SageMaker HyperPod và các dịch vụ AWS khác. Đổi lại, Orbital Materials sử dụng AI để phát triển các công nghệ khử carbon và nâng cao hiệu quả cho trung tâm dữ liệu. Để tiếp tục quay “bánh đà”, Orbital sẽ đưa Orb—mô hình AI mã nguồn mở dẫn đầu thị trường cho mô phỏng vật liệu tiên tiến—ra mắt rộng rãi cho khách hàng AWS thông qua [Amazon SageMaker JumpStart](https://aws.amazon.com/sagemaker/jumpstart/) và [AWS Marketplace](https://aws.amazon.com/marketplace). Đây là mô hình AI dành cho vật liệu đầu tiên xuất hiện trên các nền tảng AWS. Với Orb, các khách hàng AWS đang làm việc với vật liệu và công nghệ tiên tiến như bán dẫn, pin và điện tử có thể truy cập năng lực R&D tăng tốc hàng đầu trên một môi trường đám mây bảo mật và thống nhất.

Lợi thế kiến trúc của SageMaker HyperPod trên Amazon EKS được minh họa trong sơ đồ sau. Sơ đồ cho thấy Orbital có thể thiết lập một mặt phẳng điều khiển thống nhất để quản lý cả workload dựa trên CPU và các tác vụ tăng tốc bằng GPU trong một cụm Kubernetes duy nhất. Kiến trúc hợp lý này loại bỏ sự phức tạp truyền thống của việc quản lý các cụm riêng biệt cho từng loại tài nguyên tính toán, mang lại một mô hình quản lý tài nguyên tích hợp và hiệu quả hơn. Hình minh họa cho thấy cách hạ tầng hợp nhất này cho phép Orbital điều phối mượt mà các nhu cầu tính toán đa dạng thông qua một giao diện điều khiển duy nhất.

![Blog Image](/images/logo-blog/Blog3.1.jpg)

## Hum.AI: Foundation models cho quan sát Trái đất

[Hum.AI](https://hum.ai/) đang xây dựng các generative AI FMs nhằm cung cấp trí tuệ tổng quát về thế giới tự nhiên. Khách hàng có thể sử dụng nền tảng này để theo dõi và dự đoán hệ sinh thái cũng như đa dạng sinh học nhằm hiểu rõ tác động kinh doanh và bảo vệ môi trường tốt hơn. Ví dụ, họ làm việc với các cộng đồng ven biển, những nơi sử dụng nền tảng và insight để phục hồi hệ sinh thái ven biển và cải thiện đa dạng sinh học.

Foundation model của Hum.AI khai thác dữ liệu về thế giới tự nhiên và học cách biểu diễn dữ liệu đó một cách trực quan. Họ đang huấn luyện trên 50 năm dữ liệu lịch sử do vệ tinh thu thập, với khối lượng lên tới hàng nghìn petabyte. Để xử lý khối dữ liệu khổng lồ này, họ đã chọn SageMaker HyperPod vì hạ tầng có khả năng mở rộng. Nhờ kiến trúc mô hình sáng tạo, công ty đã lần đầu tiên đạt được khả năng “nhìn xuyên mặt nước từ không gian”, vượt qua những thách thức vốn có do hiện tượng phản chiếu ánh sáng trên mặt nước.

Kiến trúc FM của Hum.AI sử dụng thiết kế lai giữa variational autoencoder (VAE) và [generative adversarial network](https://aws.amazon.com/what-is/gan/) (GAN), được tối ưu hóa đặc biệt cho phân tích ảnh vệ tinh. Đây là mô hình encoder–decoder, trong đó encoder chuyển đổi dữ liệu vệ tinh vào không gian tiềm ẩn (latent space) đã học, trong khi decoder tái tạo lại hình ảnh (sau khi được xử lý trong không gian tiềm ẩn) và duy trì sự nhất quán giữa các nguồn vệ tinh khác nhau. Mạng discriminator cung cấp cả tín hiệu huấn luyện đối kháng và các metric tái tạo dựa trên đặc trưng đã học. Cách tiếp cận này giúp bảo toàn các chi tiết hệ sinh thái quan trọng vốn dễ bị mất đi với các phương pháp so sánh pixel truyền thống, đặc biệt trong môi trường dưới nước nơi phản chiếu mặt nước thường làm suy giảm khả năng quan sát.

Việc sử dụng SageMaker HyperPod để huấn luyện một mô hình phức tạp như vậy cho phép Hum.AI xử lý hiệu quả bộ [dữ liệu SeeFar được họ tự xây dựng](https://arxiv.org/abs/2406.06776) thông qua huấn luyện phân tán trên nhiều instance GPU. Mô hình đồng thời tối ưu cả mục tiêu VAE lẫn GAN trên nhiều GPU. Kết hợp với tính năng auto-resume của SageMaker HyperPod, hệ thống có thể tự động tiếp tục một phiên huấn luyện từ checkpoint mới nhất, đảm bảo tính liên tục cho quá trình huấn luyện ngay cả khi node gặp sự cố.

Hum.AI cũng sử dụng các tính năng quan sát toàn diện “out-of-the-box” của SageMaker HyperPod thông qua [Amazon Managed Service for Prometheus](https://aws.amazon.com/prometheus/) và [Amazon Managed Service for Grafana](https://aws.amazon.com/grafana/) để theo dõi các metric. Đối với nhu cầu huấn luyện phân tán, họ dùng dashboard để giám sát hiệu năng cụm, metric GPU, lưu lượng mạng và hoạt động lưu trữ. Hạ tầng giám sát toàn diện này cho phép Hum.AI tối ưu hóa quy trình huấn luyện và duy trì mức sử dụng tài nguyên cao trong suốt vòng đời phát triển mô hình.

> *"Quyết định sử dụng SageMaker HyperPod của chúng tôi rất đơn giản; đây là dịch vụ duy nhất ngoài kia cho phép bạn tiếp tục huấn luyện ngay cả khi có lỗi xảy ra. Chúng tôi có thể huấn luyện các mô hình lớn nhanh hơn bằng cách tận dụng các cụm quy mô lớn và khả năng dự phòng (redundancy) mà SageMaker HyperPod cung cấp. Chúng tôi có thể thực thi các thí nghiệm nhanh hơn và lặp mô hình ở tốc độ mà trước đây là bất khả thi. SageMaker HyperPod đã loại bỏ hoàn toàn nỗi lo về những thất bại trong huấn luyện quy mô lớn. Họ đã xây dựng hạ tầng để có thể hot swap GPU nếu có sự cố, giúp tiết kiệm hàng nghìn giờ tiến trình bị mất giữa các checkpoint. Đội ngũ SageMaker HyperPod đã trực tiếp hỗ trợ chúng tôi thiết lập và vận hành các phiên huấn luyện lớn một cách nhanh chóng và dễ dàng."*  
> — Kelly Zheng, CEO Hum.AI

Cách tiếp cận sáng tạo của Hum.AI đối với việc huấn luyện mô hình được minh họa trong hình dưới đây. Sơ đồ cho thấy mô hình của họ đồng thời tối ưu cả mục tiêu VAE và GAN trên nhiều GPU như thế nào. Chiến lược huấn luyện phân tán này được bổ sung bởi tính năng auto-resume của SageMaker HyperPod, tính năng này tự động khởi động lại các phiên huấn luyện từ checkpoint mới nhất. Kết hợp lại, những khả năng này mang đến quá trình huấn luyện liên tục và hiệu quả, ngay cả trong trường hợp có lỗi node. Hình ảnh cung cấp cái nhìn trực quan về quy trình huấn luyện bền vững này, nhấn mạnh sự tích hợp mượt mà giữa kiến trúc mô hình của Hum.AI và hạ tầng hỗ trợ của SageMaker HyperPod.

![Blog Image](/images/logo-blog/Blog3.2.jpg)

## Cách tiết kiệm thời gian và chi phí khi xây dựng với Amazon SageMaker HyperPod

Amazon SageMaker HyperPod loại bỏ phần “nặng nhọc nhưng không tạo khác biệt” (undifferentiated heavy lifting) cho các climate tech startup khi xây dựng FMs, giúp họ tiết kiệm thời gian và chi phí. Để biết thêm chi tiết về cách khả năng chịu lỗi (resiliency) của SageMaker HyperPod giúp giảm chi phí trong quá trình huấn luyện, hãy xem [Reduce ML training costs with Amazon SageMaker HyperPod.](https://aws.amazon.com/blogs/machine-learning/reduce-ml-training-costs-with-amazon-sagemaker-hyperpod/)

Ở lõi, HyperPod cung cấp khả năng kiểm soát hạ tầng sâu, được tối ưu để xử lý các bộ dữ liệu môi trường phức tạp, với quyền truy cập bảo mật vào các instance [Amazon Elastic Compute Cloud](https://aws.amazon.com/ec2/) (Amazon EC2) và tích hợp liền mạch với các công cụ điều phối như Slurm và Amazon EKS. Hạ tầng này đặc biệt mạnh trong việc xử lý các đầu vào môi trường đa phương thức, từ ảnh vệ tinh đến dữ liệu mạng cảm biến, thông qua huấn luyện phân tán trên hàng nghìn bộ tăng tốc (accelerators).

Khả năng quản lý tài nguyên thông minh của SageMaker HyperPod đặc biệt hữu ích cho mô hình khí hậu, nhờ khả năng tự động điều phối độ ưu tiên tác vụ và phân bổ tài nguyên, đồng thời giảm chi phí vận hành lên đến 40%. Điều này rất quan trọng đối với các climate tech startup đang xử lý khối lượng dữ liệu môi trường khổng lồ, vì hệ thống vừa duy trì tiến độ thông qua checkpointing, vừa đảm bảo rằng các workload mô hình khí hậu quan trọng luôn được cấp đủ tài nguyên cần thiết.

Đối với các nhà đổi mới công nghệ khí hậu, thư viện SageMaker HyperPod với hơn 30 [training recipes](https://github.com/aws/sagemaker-hyperpod-recipes) được chọn lọc giúp tăng tốc phát triển, cho phép các đội ngũ bắt đầu huấn luyện mô hình môi trường chỉ trong vài phút thay vì vài tuần. Nền tảng này tích hợp với Amazon EKS, cung cấp khả năng chịu lỗi mạnh mẽ và tính sẵn sàng cao—những yếu tố thiết yếu để duy trì liên tục các tác vụ giám sát và phân tích môi trường.

Các kế hoạch huấn luyện linh hoạt của SageMaker HyperPod đặc biệt có lợi cho những dự án công nghệ khí hậu, cho phép tổ chức chỉ định thời hạn hoàn thành và yêu cầu tài nguyên, đồng thời tự động tối ưu năng lực xử lý cho các workload dữ liệu môi trường phức tạp. Khả năng gợi ý các phương án thay thế giúp tối ưu hóa việc sử dụng tài nguyên cho các tác vụ mô hình khí hậu có cường độ tính toán cao. Với sự hỗ trợ của các bộ tăng tốc AI thế hệ mới như chip AWS Trainium và bộ công cụ giám sát toàn diện, SageMaker HyperPod mang đến cho các climate tech startup một nền tảng bền vững và hiệu quả để phát triển các giải pháp môi trường tinh vi. Hạ tầng này cho phép các tổ chức tập trung vào sứ mệnh cốt lõi là giải quyết các thách thức khí hậu, đồng thời duy trì hiệu quả vận hành và trách nhiệm môi trường.

## Thực hành cho điện toán bền vững

Các công ty công nghệ khí hậu đặc biệt ý thức về tầm quan trọng của những thực hành điện toán bền vững. Một cách tiếp cận then chốt là giám sát cẩn trọng và tối ưu hóa mức tiêu thụ năng lượng trong suốt các quy trình tính toán. Bằng việc áp dụng các chiến lược huấn luyện hiệu quả—chẳng hạn giảm số vòng huấn luyện không cần thiết và sử dụng các thuật toán tiết kiệm năng lượng—các startup có thể giảm đáng kể lượng khí thải carbon.

Bên cạnh đó, tích hợp các nguồn năng lượng tái tạo để vận hành trung tâm dữ liệu cũng đóng vai trò quan trọng trong việc giảm thiểu tác động môi trường. AWS quyết tâm biến đám mây trở thành cách thức sạch nhất và hiệu quả năng lượng nhất để vận hành hạ tầng và hoạt động kinh doanh của khách hàng. Trong nhiều năm qua, chúng tôi đã đạt được những bước tiến rõ rệt. Ví dụ, Amazon là [doanh nghiệp mua năng lượng tái tạo lớn nhất thế giới](https://www.aboutamazon.com/news/sustainability/amazon-renewable-energy-portfolio-january-2024-update) mỗi năm kể từ 2020. Chúng tôi đã đạt [mục tiêu năng lượng tái tạo](https://www.aboutamazon.com/news/sustainability/amazon-renewable-energy-goal) là “match” toàn bộ lượng điện tiêu thụ trên toàn bộ hoạt động—bao gồm cả trung tâm dữ liệu—bằng 100% năng lượng tái tạo, và chúng tôi hoàn thành mục tiêu này sớm hơn 7 năm so với mốc 2030 đã đề ra ban đầu.

Các công ty cũng đang áp dụng nguyên tắc điện toán theo dõi carbon (carbon-aware computing), nghĩa là sắp xếp các tác vụ tính toán trùng với những khoảng thời gian mà cường độ carbon của lưới điện thấp. Cách làm này giúp năng lượng dùng cho tính toán có dấu chân môi trường nhỏ hơn. Việc triển khai những chiến lược như vậy không chỉ phù hợp với các mục tiêu phát triển bền vững rộng hơn mà còn thúc đẩy hiệu quả chi phí và bảo tồn tài nguyên. Khi nhu cầu về năng lực tính toán tiên tiến ngày càng tăng, các climate tech startup đang thể hiện cam kết mạnh mẽ với thực hành bền vững, bảo đảm rằng đổi mới của họ vừa thúc đẩy tiến bộ công nghệ, vừa đóng góp tích cực cho việc bảo vệ môi trường.

## Kết luận

Amazon SageMaker HyperPod đang nổi lên như một công cụ then chốt cho các climate tech startup trong hành trình phát triển các giải pháp sáng tạo nhằm giải quyết những thách thức môi trường cấp bách. Bằng cách cung cấp hạ tầng có khả năng mở rộng, hiệu quả và tiết kiệm chi phí để huấn luyện các kiến trúc mô hình đa phương thức và đa mô hình phức tạp, SageMaker HyperPod cho phép các công ty này xử lý khối lượng dữ liệu môi trường khổng lồ và xây dựng những mô hình dự đoán tinh vi. Từ nỗ lực khám phá vật liệu bền vững của Orbital Materials đến khả năng quan sát Trái đất tiên tiến của Hum.AI, SageMaker HyperPod đang hỗ trợ những bước đột phá mà trước đây khó có thể đạt được. Khi biến đổi khí hậu tiếp tục đặt ra các thách thức cấp bách trên toàn cầu, khả năng tự động quản lý các cụm huấn luyện AI quy mô lớn của SageMaker HyperPod, cùng với các tính năng chịu lỗi và tối ưu chi phí, cho phép những nhà đổi mới công nghệ khí hậu tập trung vào sứ mệnh cốt lõi thay vì lo lắng về hạ tầng. Bằng việc sử dụng SageMaker HyperPod, các climate tech startup không chỉ xây dựng được những mô hình hiệu quả hơn mà còn đang tăng tốc phát triển những công cụ mạnh mẽ mới, đóng góp vào nỗ lực chung trong việc giải quyết khủng hoảng khí hậu toàn cầu.

![Blog Image](/images/logo-blog/Blog3.3.png)
